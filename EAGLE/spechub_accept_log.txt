Warmup done

-------------------step: 1-------------------

x1 1564 x2 1335 a 1335
q[a] 0.1055908203125 q[x1] 0.01532745361328125 q[x2] 0.1055908203125
gtp[x1] 0.0 gtp[x2] 5.960464477539063e-08 gtp[a] 5.960464477539063e-08
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0153, device='cuda:0') acp tensor(0., device='cuda:0') r 0.5050415349143588
pp sum tensor(0.9272, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8218, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(5.9605e-08, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8218, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1056, device='cuda:0', dtype=torch.float16) q[a] 0.1055908203125
pp sum tensor(0.9185, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0970, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(5.9605e-08, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0970, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8218, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.03218407116146638
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9185, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29892 x2 29991 a 29892
q[a] 0.6083984375 q[x1] 0.6083984375 q[x2] 0.257568359375
gtp[x1] 0.043121337890625 gtp[x2] 0.35546875 gtp[a] 0.043121337890625
pp sum tensor(0.7158, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1071, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0431, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0979, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1071, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0979, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4004, device='cuda:0', dtype=torch.float16) acp tensor(0.2445, device='cuda:0', dtype=torch.float16) r 0.8016439243313391
q_ai sum tensor(0.6084, device='cuda:0', dtype=torch.float16) q[a] 0.6083984375
pp sum tensor(0.5811, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4741, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0431, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4741, device='cuda:0', dtype=torch.float16)
pa tensor(0.0431, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4741, device='cuda:0', dtype=torch.float16) acp tensor(0.0909, device='cuda:0', dtype=torch.float16) r 0.3751813907483401
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5381, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 414 x2 12618 a 12618
q[a] 0.39306640625 q[x1] 0.265869140625 q[x2] 0.39306640625
gtp[x1] 0.8857421875 gtp[x2] 0.0009446144104003906 gtp[a] 0.0009446144104003906
px1 tensor(0.8857, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2659, device='cuda:0') acp tensor(3.3315, device='cuda:0') r 0.17907508721486676

-------------------step: 2-------------------

x1 29991 x2 322 a 29991
q[a] 0.63232421875 q[x1] 0.63232421875 q[x2] 0.3603515625
gtp[x1] 0.986328125 gtp[x2] 0.004093170166015625 gtp[a] 0.986328125
pp sum tensor(0.9912, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3584, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3584, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6196, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.17531145674350157
q_ai sum tensor(0.6323, device='cuda:0', dtype=torch.float16) q[a] 0.63232421875
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6274, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6274, device='cuda:0', dtype=torch.float16)
pa tensor(0.9863, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6274, device='cuda:0', dtype=torch.float16) acp tensor(1.5723, device='cuda:0', dtype=torch.float16) r 0.04576869208143852

-------------------step: 3-------------------

x1 29871 x2 319 a 319
q[a] 0.220458984375 q[x1] 0.059326171875 q[x2] 0.220458984375
gtp[x1] 0.01508331298828125 gtp[x2] 0.0017328262329101562 gtp[a] 0.0017328262329101562
px1 tensor(0.0151, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0593, device='cuda:0') acp tensor(0.2542, device='cuda:0') r 0.9257975522601543
pp sum tensor(0.6182, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3975, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0017, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3975, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2205, device='cuda:0', dtype=torch.float16) q[a] 0.220458984375
pp sum tensor(0.5532, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1555, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0017, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1555, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3975, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9942327807170588
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5513, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 10325 x2 626 a 10325
q[a] 0.7099609375 q[x1] 0.7099609375 q[x2] 0.0277557373046875
gtp[x1] 0.94921875 gtp[x2] 0.00054168701171875 gtp[a] 0.94921875
pp sum tensor(0.9492, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2390, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9492, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2390, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0681, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6988026549468757
q_ai sum tensor(0.7100, device='cuda:0', dtype=torch.float16) q[a] 0.7099609375
pp sum tensor(0.9492, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7100, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9492, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7100, device='cuda:0', dtype=torch.float16)
pa tensor(0.9492, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7100, device='cuda:0', dtype=torch.float16) acp tensor(1.3369, device='cuda:0', dtype=torch.float16) r 0.32044707525854266

-------------------step: 2-------------------

x1 2355 x2 750 a 750
q[a] 0.2841796875 q[x1] 0.206298828125 q[x2] 0.2841796875
gtp[x1] 0.0009851455688476562 gtp[x2] 0.61572265625 gtp[a] 0.61572265625
px1 tensor(0.0010, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2063, device='cuda:0') acp tensor(0.0048, device='cuda:0') r 0.053948328588567684
pp sum tensor(0.9546, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6699, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6157, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6699, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2839, device='cuda:0', dtype=torch.float16) q[a] 0.2841796875
pp sum tensor(0.9448, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2744, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6157, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2744, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3413, device='cuda:0', dtype=torch.float16)
pa tensor(0.3413, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6699, device='cuda:0', dtype=torch.float16) acp tensor(0.5093, device='cuda:0', dtype=torch.float16) r 0.5223853727341017
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3293, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 935

-------------------step: 2-------------------

directly accept a 287

-------------------step: 3-------------------

directly accept a 373

-------------------step: 1-------------------

x1 2748 x2 16342 a 16342
q[a] 0.4658203125 q[x1] 0.032440185546875 q[x2] 0.4658203125
gtp[x1] 0.078125 gtp[x2] 0.4638671875 gtp[a] 0.4638671875
px1 tensor(0.0781, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0324, device='cuda:0') acp tensor(2.4083, device='cuda:0') r 0.8636350419631611

-------------------step: 2-------------------

x1 29899 x2 2 a 29899
q[a] 0.99462890625 q[x1] 0.99462890625 q[x2] 0.003787994384765625
gtp[x1] 0.984375 gtp[x2] 0.00010389089584350586 gtp[a] 0.984375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0051, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9844, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0051, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6929, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8656170945199473
q_ai sum tensor(0.9946, device='cuda:0', dtype=torch.float16) q[a] 0.99462890625
pp sum tensor(0.9844, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9795, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9844, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9795, device='cuda:0', dtype=torch.float16)
pa tensor(0.9844, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9795, device='cuda:0', dtype=torch.float16) acp tensor(1.0049, device='cuda:0', dtype=torch.float16) r 0.04325536950431952

-------------------step: 3-------------------

x1 2 x2 262 a 2
q[a] 0.309326171875 q[x1] 0.309326171875 q[x2] 0.09735107421875
gtp[x1] 1.0132789611816406e-05 gtp[x2] 1.0 gtp[a] 1.0132789611816406e-05
pp sum tensor(0.9028, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5933, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.0133e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9028, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5933, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9028, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0436, device='cuda:0', dtype=torch.float16) acp tensor(20.7188, device='cuda:0', dtype=torch.float16) r 0.48505067427224

-------------------step: 1-------------------

directly accept a 29874

-------------------step: 2-------------------

directly accept a 29899

-------------------step: 3-------------------

x1 2 x2 13 a 2
q[a] 0.54150390625 q[x1] 0.54150390625 q[x2] 0.02960205078125
gtp[x1] 1.3649463653564453e-05 gtp[x2] 1.1324882507324219e-06 gtp[a] 1.3649463653564453e-05
pp sum tensor(0.9429, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4014, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.3649e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4014, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0350, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.22788703854814496
q_ai sum tensor(0.5415, device='cuda:0', dtype=torch.float16) q[a] 0.54150390625
pp sum tensor(0.8755, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4741, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(1.3649e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4741, device='cuda:0', dtype=torch.float16)
pa tensor(1.3649e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4741, device='cuda:0', dtype=torch.float16) acp tensor(2.8789e-05, device='cuda:0', dtype=torch.float16) r 0.1890409015338611
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8755, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 361

-------------------step: 2-------------------

directly accept a 5410

-------------------step: 3-------------------

x1 17623 x2 9850 a 17623
q[a] 0.68115234375 q[x1] 0.68115234375 q[x2] 0.05548095703125
gtp[x1] 0.09259033203125 gtp[x2] 8.761882781982422e-06 gtp[a] 0.09259033203125
pp sum tensor(0.8672, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1854, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0926, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1854, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1185, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2955809189197911
q_ai sum tensor(0.6812, device='cuda:0', dtype=torch.float16) q[a] 0.68115234375
pp sum tensor(0.8130, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6265, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0926, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6265, device='cuda:0', dtype=torch.float16)
pa tensor(0.0926, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6265, device='cuda:0', dtype=torch.float16) acp tensor(0.1478, device='cuda:0', dtype=torch.float16) r 0.7414344602522888
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7202, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 304

-------------------step: 2-------------------

x1 278 x2 26901 a 26901
q[a] 0.84619140625 q[x1] 0.08782958984375 q[x2] 0.84619140625
gtp[x1] 0.826171875 gtp[x2] 0.173095703125 gtp[a] 0.173095703125
px1 tensor(0.8262, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0878, device='cuda:0') acp tensor(9.4065, device='cuda:0') r 0.6708317041069725

-------------------step: 3-------------------

x1 2320 x2 14328 a 14328
q[a] 0.31982421875 q[x1] 0.0297393798828125 q[x2] 0.31982421875
gtp[x1] 0.0028171539306640625 gtp[x2] 0.00012576580047607422 gtp[a] 0.00012576580047607422
px1 tensor(0.0028, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0297, device='cuda:0') acp tensor(0.0947, device='cuda:0') r 0.17499929477810905
pp sum tensor(0.7949, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4753, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0001, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4753, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3198, device='cuda:0', dtype=torch.float16) q[a] 0.31982421875
pp sum tensor(0.7275, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2522, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0001, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2522, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4753, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3475243555582108
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7275, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 26901 x2 21881 a 26901
q[a] 0.72314453125 q[x1] 0.72314453125 q[x2] 0.03924560546875
gtp[x1] 0.257080078125 gtp[x2] 0.0085296630859375 gtp[a] 0.257080078125
pp sum tensor(0.7954, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0723, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2571, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0723, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1026, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8169841033739639
q_ai sum tensor(0.7231, device='cuda:0', dtype=torch.float16) q[a] 0.72314453125
pp sum tensor(0.6792, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6064, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.2571, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6064, device='cuda:0', dtype=torch.float16)
pa tensor(0.2571, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6064, device='cuda:0', dtype=torch.float16) acp tensor(0.4238, device='cuda:0', dtype=torch.float16) r 0.799906939281339
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.4221, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 310

-------------------step: 2-------------------

directly accept a 26901

-------------------step: 3-------------------

directly accept a 29875

-------------------step: 1-------------------

x1 322 x2 263 a 322
q[a] 0.986328125 q[x1] 0.986328125 q[x2] 0.0020427703857421875
gtp[x1] 0.98046875 gtp[x2] 0.0034809112548828125 gtp[a] 0.98046875
pp sum tensor(0.9883, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0018, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9805, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0014, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0018, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0014, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1455, device='cuda:0', dtype=torch.float16) acp tensor(0.0099, device='cuda:0', dtype=torch.float16) r 0.9246416926833012
q_ai sum tensor(0.9863, device='cuda:0', dtype=torch.float16) q[a] 0.986328125
pp sum tensor(0.9814, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9795, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9805, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9795, device='cuda:0', dtype=torch.float16)
pa tensor(0.9805, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9795, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.40518615523640833

-------------------step: 2-------------------

x1 306 x2 372 a 306
q[a] 0.8974609375 q[x1] 0.8974609375 q[x2] 0.0660400390625
gtp[x1] 0.204833984375 gtp[x2] 0.228515625 gtp[a] 0.204833984375
pp sum tensor(0.9316, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0341, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2048, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1625, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0341, device='cuda:0', dtype=torch.float16)
px2 tensor(0.1625, device='cuda:0', dtype=torch.float16) qx2 tensor(0.5796, device='cuda:0', dtype=torch.float16) acp tensor(0.2803, device='cuda:0', dtype=torch.float16) r 0.5436973192293167
q_ai sum tensor(0.8975, device='cuda:0', dtype=torch.float16) q[a] 0.8974609375
pp sum tensor(0.7607, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7261, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.2048, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7261, device='cuda:0', dtype=torch.float16)
pa tensor(0.2048, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7261, device='cuda:0', dtype=torch.float16) acp tensor(0.2822, device='cuda:0', dtype=torch.float16) r 0.9374384057145775
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5557, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 592

-------------------step: 2-------------------

directly accept a 2649

-------------------step: 3-------------------

directly accept a 366

-------------------step: 1-------------------

x1 372 x2 306 a 372
q[a] 0.98046875 q[x1] 0.98046875 q[x2] 0.00848388671875
gtp[x1] 0.9990234375 gtp[x2] 0.00017654895782470703 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0183, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0183, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4280, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.21379317568728595
q_ai sum tensor(0.9805, device='cuda:0', dtype=torch.float16) q[a] 0.98046875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9805, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9805, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9805, device='cuda:0', dtype=torch.float16) acp tensor(1.0186, device='cuda:0', dtype=torch.float16) r 0.20982938353156755

-------------------step: 2-------------------

x1 471 x2 29915 a 471
q[a] 0.759765625 q[x1] 0.759765625 q[x2] 0.1890869140625
gtp[x1] 0.94873046875 gtp[x2] 0.0013399124145507812 gtp[a] 0.94873046875
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2372, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9487, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2372, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5981, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.15017946137001248
q_ai sum tensor(0.7598, device='cuda:0', dtype=torch.float16) q[a] 0.759765625
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7593, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9487, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7593, device='cuda:0', dtype=torch.float16)
pa tensor(0.9487, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7593, device='cuda:0', dtype=torch.float16) acp tensor(1.2500, device='cuda:0', dtype=torch.float16) r 0.11945031261816708

-------------------step: 3-------------------

x1 263 x2 599 a 263
q[a] 0.69873046875 q[x1] 0.69873046875 q[x2] 0.0660400390625
gtp[x1] 0.02569580078125 gtp[x2] 1.1146068572998047e-05 gtp[a] 0.02569580078125
pp sum tensor(0.8901, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1912, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0257, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1912, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1533, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7192574768463249
q_ai sum tensor(0.6987, device='cuda:0', dtype=torch.float16) q[a] 0.69873046875
pp sum tensor(0.6782, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4866, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0257, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4866, device='cuda:0', dtype=torch.float16)
pa tensor(0.0257, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4866, device='cuda:0', dtype=torch.float16) acp tensor(0.0528, device='cuda:0', dtype=torch.float16) r 0.8055289400173219
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6523, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 7271 x2 17623 a 7271
q[a] 0.6171875 q[x1] 0.6171875 q[x2] 0.156005859375
gtp[x1] 0.70703125 gtp[x2] 0.1654052734375 gtp[a] 0.70703125
pp sum tensor(0.7363, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1193, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7070, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0094, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1193, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0094, device='cuda:0', dtype=torch.float16) qx2 tensor(0.2517, device='cuda:0', dtype=torch.float16) acp tensor(0.0374, device='cuda:0', dtype=torch.float16) r 0.6986523437044148
q_ai sum tensor(0.6172, device='cuda:0', dtype=torch.float16) q[a] 0.6171875
pp sum tensor(0.7070, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5879, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7070, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5879, device='cuda:0', dtype=torch.float16)
pa tensor(0.7070, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5879, device='cuda:0', dtype=torch.float16) acp tensor(1.2031, device='cuda:0', dtype=torch.float16) r 0.4368760230795644

-------------------step: 2-------------------

x1 25531 x2 304 a 304
q[a] 0.253173828125 q[x1] 0.2098388671875 q[x2] 0.253173828125
gtp[x1] 0.0333251953125 gtp[x2] 0.00269317626953125 gtp[a] 0.00269317626953125
px1 tensor(0.0333, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2098, device='cuda:0') acp tensor(0.1588, device='cuda:0') r 0.5746578634924174
pp sum tensor(0.7607, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5078, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0027, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5078, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2532, device='cuda:0', dtype=torch.float16) q[a] 0.253173828125
pp sum tensor(0.6934, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1854, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0027, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1854, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5078, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.33409513032425586
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6909, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29915 x2 723 a 29915
q[a] 0.430419921875 q[x1] 0.430419921875 q[x2] 0.11859130859375
gtp[x1] 0.447509765625 gtp[x2] 7.665157318115234e-05 gtp[a] 0.447509765625
pp sum tensor(0.9497, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5195, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4475, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5195, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0896, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8793157907638744
q_ai sum tensor(0.4304, device='cuda:0', dtype=torch.float16) q[a] 0.430419921875
pp sum tensor(0.9282, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4087, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4475, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4087, device='cuda:0', dtype=torch.float16)
pa tensor(0.4475, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4087, device='cuda:0', dtype=torch.float16) acp tensor(1.0947, device='cuda:0', dtype=torch.float16) r 0.3068001148072953

-------------------step: 2-------------------

directly accept a 645

-------------------step: 3-------------------

x1 2360 x2 367 a 2360
q[a] 0.9228515625 q[x1] 0.9228515625 q[x2] 0.01551055908203125
gtp[x1] 0.99169921875 gtp[x2] 9.09566879272461e-05 gtp[a] 0.99169921875
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0685, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0685, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1854, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9562454296679848
q_ai sum tensor(0.9224, device='cuda:0', dtype=torch.float16) q[a] 0.9228515625
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9224, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9224, device='cuda:0', dtype=torch.float16)
pa tensor(0.9917, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9224, device='cuda:0', dtype=torch.float16) acp tensor(1.0752, device='cuda:0', dtype=torch.float16) r 0.8348090157107627

-------------------step: 1-------------------

x1 29889 x2 29991 a 29889
q[a] 0.93701171875 q[x1] 0.93701171875 q[x2] 0.06280517578125
gtp[x1] 0.986328125 gtp[x2] 0.013427734375 gtp[a] 0.986328125
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0494, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0494, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9360, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.40868028829361314
q_ai sum tensor(0.9365, device='cuda:0', dtype=torch.float16) q[a] 0.93701171875
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9365, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9365, device='cuda:0', dtype=torch.float16)
pa tensor(0.9863, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9365, device='cuda:0', dtype=torch.float16) acp tensor(1.0527, device='cuda:0', dtype=torch.float16) r 0.3214345800312728

-------------------step: 2-------------------

x1 13 x2 3645 a 13
q[a] 0.494384765625 q[x1] 0.494384765625 q[x2] 0.04254150390625
gtp[x1] 0.02069091796875 gtp[x2] 0.8798828125 gtp[a] 0.02069091796875
pp sum tensor(0.8965, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4019, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0207, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8374, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4019, device='cuda:0', dtype=torch.float16)
px2 tensor(0.8374, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0416, device='cuda:0', dtype=torch.float16) acp tensor(20.1250, device='cuda:0', dtype=torch.float16) r 0.7805143821079097

-------------------step: 3-------------------

x1 13851 x2 278 a 278
q[a] 0.2073974609375 q[x1] 0.00015556812286376953 q[x2] 0.2073974609375
gtp[x1] 2.980232238769531e-07 gtp[x2] 0.28369140625 gtp[a] 0.28369140625
px1 tensor(2.9802e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0002, device='cuda:0') acp tensor(0.0019, device='cuda:0') r 0.32923572413095903
pp sum tensor(0.7988, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5913, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2837, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5913, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2074, device='cuda:0', dtype=torch.float16) q[a] 0.2073974609375
pp sum tensor(0.7725, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1813, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2837, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1813, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1024, device='cuda:0', dtype=torch.float16)
pa tensor(0.1024, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5913, device='cuda:0', dtype=torch.float16) acp tensor(0.1732, device='cuda:0', dtype=torch.float16) r 0.2670641296733035
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.4888, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 271

-------------------step: 2-------------------

x1 2 x2 354 a 354
q[a] 0.626953125 q[x1] 0.12548828125 q[x2] 0.626953125
gtp[x1] 0.0 gtp[x2] 2.4318695068359375e-05 gtp[a] 2.4318695068359375e-05
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.1255, device='cuda:0') acp tensor(0., device='cuda:0') r 0.12108466641270355
pp sum tensor(0.9194, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2925, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.4319e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2925, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6270, device='cuda:0', dtype=torch.float16) q[a] 0.626953125
pp sum tensor(0.7842, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4917, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.4319e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4917, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2925, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.46798739280007706
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7842, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 5086

-------------------step: 2-------------------

x1 367 x2 6575 a 6575
q[a] 0.1767578125 q[x1] 0.11328125 q[x2] 0.1767578125
gtp[x1] 0.081298828125 gtp[x2] 0.10601806640625 gtp[a] 0.10601806640625
px1 tensor(0.0813, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1133, device='cuda:0') acp tensor(0.7177, device='cuda:0') r 0.14069273185190878

-------------------step: 3-------------------

directly accept a 14520

-------------------step: 1-------------------

x1 16375 x2 301 a 16375
q[a] 0.113037109375 q[x1] 0.113037109375 q[x2] 0.09222412109375
gtp[x1] 0.193115234375 gtp[x2] 0.06170654296875 gtp[a] 0.193115234375
pp sum tensor(0.8203, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7075, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1931, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7075, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0118, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6894045675166303
q_ai sum tensor(0.1130, device='cuda:0', dtype=torch.float16) q[a] 0.113037109375
pp sum tensor(0.8120, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1049, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1931, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1049, device='cuda:0', dtype=torch.float16)
pa tensor(0.1931, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1049, device='cuda:0', dtype=torch.float16) acp tensor(1.8418, device='cuda:0', dtype=torch.float16) r 0.07373672781112262

-------------------step: 2-------------------

x1 27482 x2 3534 a 27482
q[a] 0.8994140625 q[x1] 0.8994140625 q[x2] 0.0014505386352539062
gtp[x1] 0.86669921875 gtp[x2] 0.0014085769653320312 gtp[a] 0.86669921875
pp sum tensor(0.9326, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0329, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8667, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0329, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0130, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6059474825505995
q_ai sum tensor(0.8994, device='cuda:0', dtype=torch.float16) q[a] 0.8994140625
pp sum tensor(0.8818, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8491, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8667, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8491, device='cuda:0', dtype=torch.float16)
pa tensor(0.8667, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8491, device='cuda:0', dtype=torch.float16) acp tensor(1.0205, device='cuda:0', dtype=torch.float16) r 0.3156741335741222

-------------------step: 3-------------------

x1 29892 x2 304 a 29892
q[a] 0.982421875 q[x1] 0.982421875 q[x2] 0.0038909912109375
gtp[x1] 0.03857421875 gtp[x2] 0.0003724098205566406 gtp[a] 0.03857421875
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0048, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0386, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0048, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2186, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.28808765567073247
q_ai sum tensor(0.9824, device='cuda:0', dtype=torch.float16) q[a] 0.982421875
pp sum tensor(0.9766, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9717, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0386, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9717, device='cuda:0', dtype=torch.float16)
pa tensor(0.0386, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9717, device='cuda:0', dtype=torch.float16) acp tensor(0.0397, device='cuda:0', dtype=torch.float16) r 0.0905182230358611
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9380, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 19781 x2 306 a 306
q[a] 0.460693359375 q[x1] 0.0533447265625 q[x2] 0.460693359375
gtp[x1] 0.035400390625 gtp[x2] 0.00659942626953125 gtp[a] 0.00659942626953125
px1 tensor(0.0354, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0533, device='cuda:0') acp tensor(0.6636, device='cuda:0') r 0.3977889597192945

-------------------step: 2-------------------

x1 1510 x2 4332 a 4332
q[a] 0.419189453125 q[x1] 0.00911712646484375 q[x2] 0.419189453125
gtp[x1] 0.029510498046875 gtp[x2] 0.0204315185546875 gtp[a] 0.0204315185546875
px1 tensor(0.0295, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0091, device='cuda:0') acp tensor(3.2368, device='cuda:0') r 0.11961950311333347

-------------------step: 3-------------------

x1 4878 x2 29883 a 4878
q[a] 0.630859375 q[x1] 0.630859375 q[x2] 0.1429443359375
gtp[x1] 0.88232421875 gtp[x2] 0.1175537109375 gtp[a] 0.88232421875
pp sum tensor(0.8823, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2512, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8823, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2512, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2443, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8725560846369387
q_ai sum tensor(0.6309, device='cuda:0', dtype=torch.float16) q[a] 0.630859375
pp sum tensor(0.8823, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6309, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8823, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6309, device='cuda:0', dtype=torch.float16)
pa tensor(0.8823, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6309, device='cuda:0', dtype=torch.float16) acp tensor(1.3984, device='cuda:0', dtype=torch.float16) r 0.9013149165956447

-------------------step: 1-------------------

x1 11359 x2 15409 a 11359
q[a] 0.8232421875 q[x1] 0.8232421875 q[x2] 0.028839111328125
gtp[x1] 0.193359375 gtp[x2] 0.0211944580078125 gtp[a] 0.193359375
pp sum tensor(0.8467, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0235, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1934, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0235, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1343, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5125480020988014
q_ai sum tensor(0.8232, device='cuda:0', dtype=torch.float16) q[a] 0.8232421875
pp sum tensor(0.7471, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7231, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1934, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7231, device='cuda:0', dtype=torch.float16)
pa tensor(0.1934, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7231, device='cuda:0', dtype=torch.float16) acp tensor(0.2673, device='cuda:0', dtype=torch.float16) r 0.07991761467206249

-------------------step: 2-------------------

x1 29915 x2 30010 a 29915
q[a] 0.99365234375 q[x1] 0.99365234375 q[x2] 0.005908966064453125
gtp[x1] 0.9697265625 gtp[x2] 0.000335693359375 gtp[a] 0.9697265625
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0059, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9697, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0059, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9258, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1022400175796454
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16) q[a] 0.99365234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9932, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9697, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9932, device='cuda:0', dtype=torch.float16)
pa tensor(0.9697, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9932, device='cuda:0', dtype=torch.float16) acp tensor(0.9766, device='cuda:0', dtype=torch.float16) r 0.012531091130347116

-------------------step: 3-------------------

directly accept a 29879

-------------------step: 1-------------------

x1 4955 x2 902 a 4955
q[a] 0.9580078125 q[x1] 0.9580078125 q[x2] 0.0289306640625
gtp[x1] 0.88037109375 gtp[x2] 0.115478515625 gtp[a] 0.88037109375
pp sum tensor(0.9673, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0092, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8804, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0865, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0092, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0865, device='cuda:0', dtype=torch.float16) qx2 tensor(0.6636, device='cuda:0', dtype=torch.float16) acp tensor(0.1304, device='cuda:0', dtype=torch.float16) r 0.5976254046284263
q_ai sum tensor(0.9580, device='cuda:0', dtype=torch.float16) q[a] 0.9580078125
pp sum tensor(0.8804, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8711, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8804, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8711, device='cuda:0', dtype=torch.float16)
pa tensor(0.8804, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8711, device='cuda:0', dtype=torch.float16) acp tensor(1.0107, device='cuda:0', dtype=torch.float16) r 0.5065644721905939

-------------------step: 2-------------------

x1 322 x2 29892 a 29892
q[a] 0.8369140625 q[x1] 0.15478515625 q[x2] 0.8369140625
gtp[x1] 0.79296875 gtp[x2] 0.2069091796875 gtp[a] 0.2069091796875
px1 tensor(0.7930, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1548, device='cuda:0') acp tensor(5.1230, device='cuda:0') r 0.839548901489798

-------------------step: 3-------------------

x1 5412 x2 325 a 5412
q[a] 0.2376708984375 q[x1] 0.2376708984375 q[x2] 0.08404541015625
gtp[x1] 0.0002655982971191406 gtp[x2] 0.0006732940673828125 gtp[a] 0.0002655982971191406
pp sum tensor(0.8193, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5815, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0003, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5815, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0262, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5834782353165262
q_ai sum tensor(0.2377, device='cuda:0', dtype=torch.float16) q[a] 0.2376708984375
pp sum tensor(0.7646, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1835, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0003, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1835, device='cuda:0', dtype=torch.float16)
pa tensor(0.0003, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1835, device='cuda:0', dtype=torch.float16) acp tensor(0.0014, device='cuda:0', dtype=torch.float16) r 0.243049499604735
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7646, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 2187

-------------------step: 2-------------------

directly accept a 29892

-------------------step: 3-------------------

x1 306 x2 26901 a 306
q[a] 0.7529296875 q[x1] 0.7529296875 q[x2] 0.150634765625
gtp[x1] 0.01214599609375 gtp[x2] 0.75146484375 gtp[a] 0.01214599609375
pp sum tensor(0.8257, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0724, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0121, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6006, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0724, device='cuda:0', dtype=torch.float16)
px2 tensor(0.6006, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4600, device='cuda:0', dtype=torch.float16) acp tensor(1.3057, device='cuda:0', dtype=torch.float16) r 0.20290355817010897

-------------------step: 1-------------------

x1 471 x2 756 a 756
q[a] 0.419189453125 q[x1] 0.0227508544921875 q[x2] 0.419189453125
gtp[x1] 0.0008807182312011719 gtp[x2] 0.75830078125 gtp[a] 0.75830078125
px1 tensor(0.0009, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0228, device='cuda:0') acp tensor(0.0387, device='cuda:0') r 0.528683977707233
pp sum tensor(0.7627, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3435, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7583, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3435, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4192, device='cuda:0', dtype=torch.float16) q[a] 0.419189453125
pp sum tensor(0.7612, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4177, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7583, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4177, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3406, device='cuda:0', dtype=torch.float16)
pa tensor(0.3406, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3435, device='cuda:0', dtype=torch.float16) acp tensor(0.9917, device='cuda:0', dtype=torch.float16) r 0.35506234051900487

-------------------step: 2-------------------

x1 1554 x2 263 a 1554
q[a] 0.483642578125 q[x1] 0.483642578125 q[x2] 0.2320556640625
gtp[x1] 0.759765625 gtp[x2] 0.00768280029296875 gtp[a] 0.759765625
pp sum tensor(0.9619, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4783, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7598, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4783, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2174, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8406344611664229
q_ai sum tensor(0.4836, device='cuda:0', dtype=torch.float16) q[a] 0.483642578125
pp sum tensor(0.9561, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4778, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7598, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4778, device='cuda:0', dtype=torch.float16)
pa tensor(0.7598, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4778, device='cuda:0', dtype=torch.float16) acp tensor(1.5898, device='cuda:0', dtype=torch.float16) r 0.1561047324404402

-------------------step: 3-------------------

x1 19781 x2 363 a 363
q[a] 0.264404296875 q[x1] 0.264404296875 q[x2] 0.264404296875
gtp[x1] 1.9073486328125e-06 gtp[x2] 0.82421875 gtp[a] 0.82421875
px1 tensor(1.9073e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2644, device='cuda:0') acp tensor(7.2138e-06, device='cuda:0') r 0.7027983240790429
pp sum tensor(0.8242, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5601, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8242, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5601, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2644, device='cuda:0', dtype=torch.float16) q[a] 0.264404296875
pp sum tensor(0.8242, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2644, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8242, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2644, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5596, device='cuda:0', dtype=torch.float16)
pa tensor(0.5596, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5601, device='cuda:0', dtype=torch.float16) acp tensor(0.9990, device='cuda:0', dtype=torch.float16) r 0.4459150015278526

-------------------step: 1-------------------

x1 29889 x2 297 a 29889
q[a] 0.9765625 q[x1] 0.9765625 q[x2] 0.0008902549743652344
gtp[x1] 0.994140625 gtp[x2] 1.0907649993896484e-05 gtp[a] 0.994140625
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0201, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9941, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0201, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0369, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.379949263764222
q_ai sum tensor(0.9766, device='cuda:0', dtype=torch.float16) q[a] 0.9765625
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9741, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9941, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9741, device='cuda:0', dtype=torch.float16)
pa tensor(0.9941, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9741, device='cuda:0', dtype=torch.float16) acp tensor(1.0205, device='cuda:0', dtype=torch.float16) r 0.8805420045031065

-------------------step: 2-------------------

x1 13 x2 2803 a 13
q[a] 0.9013671875 q[x1] 0.9013671875 q[x2] 0.0049591064453125
gtp[x1] 0.76953125 gtp[x2] 0.00237274169921875 gtp[a] 0.76953125
pp sum tensor(0.9648, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0630, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7695, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0630, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0455, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6512359814174229
q_ai sum tensor(0.9014, device='cuda:0', dtype=torch.float16) q[a] 0.9013671875
pp sum tensor(0.8408, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7773, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7695, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7773, device='cuda:0', dtype=torch.float16)
pa tensor(0.7695, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7773, device='cuda:0', dtype=torch.float16) acp tensor(0.9897, device='cuda:0', dtype=torch.float16) r 0.43218413391619026

-------------------step: 3-------------------

x1 13 x2 797 a 13
q[a] 1.0 q[x1] 1.0 q[x2] 2.086162567138672e-06
gtp[x1] 0.9990234375 gtp[x2] 0.0004303455352783203 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(2.5630e-06, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0004, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(2.5630e-06, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0004, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0345, device='cuda:0', dtype=torch.float16) acp tensor(0.0124, device='cuda:0', dtype=torch.float16) r 0.3039033702708268
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9990, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.1690506468605819

-------------------step: 1-------------------

x1 310 x2 2462 a 310
q[a] 0.96484375 q[x1] 0.96484375 q[x2] 0.032501220703125
gtp[x1] 0.9931640625 gtp[x2] 0.00029397010803222656 gtp[a] 0.9931640625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0345, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9932, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0345, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8906, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6201223194733001
q_ai sum tensor(0.9648, device='cuda:0', dtype=torch.float16) q[a] 0.96484375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9639, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9932, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9639, device='cuda:0', dtype=torch.float16)
pa tensor(0.9932, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9639, device='cuda:0', dtype=torch.float16) acp tensor(1.0303, device='cuda:0', dtype=torch.float16) r 0.04662136492308466

-------------------step: 2-------------------

x1 278 x2 590 a 278
q[a] 0.98828125 q[x1] 0.98828125 q[x2] 0.01047515869140625
gtp[x1] 0.9677734375 gtp[x2] 0.0321044921875 gtp[a] 0.9677734375
pp sum tensor(0.9893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0011, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9678, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0216, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0011, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0216, device='cuda:0', dtype=torch.float16) qx2 tensor(0.8955, device='cuda:0', dtype=torch.float16) acp tensor(0.0242, device='cuda:0', dtype=torch.float16) r 0.3047782152765115
q_ai sum tensor(0.9883, device='cuda:0', dtype=torch.float16) q[a] 0.98828125
pp sum tensor(0.9678, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9668, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9678, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9668, device='cuda:0', dtype=torch.float16)
pa tensor(0.9678, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9668, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.02483229761543715

-------------------step: 3-------------------

x1 1556 x2 2246 a 1556
q[a] 0.9931640625 q[x1] 0.9931640625 q[x2] 0.0005240440368652344
gtp[x1] 0.1617431640625 gtp[x2] 0.024810791015625 gtp[a] 0.1617431640625
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0039, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1617, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0243, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0039, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0243, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0757, device='cuda:0', dtype=torch.float16) acp tensor(0.3210, device='cuda:0', dtype=torch.float16) r 0.09495867294648541

-------------------step: 1-------------------

x1 304 x2 306 a 306
q[a] 0.53125 q[x1] 0.293212890625 q[x2] 0.53125
gtp[x1] 0.419677734375 gtp[x2] 0.53857421875 gtp[a] 0.53857421875
px1 tensor(0.4197, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2932, device='cuda:0') acp tensor(1.4313, device='cuda:0') r 0.7408009165112909

-------------------step: 2-------------------

x1 6493 x2 7271 a 6493
q[a] 0.755859375 q[x1] 0.755859375 q[x2] 0.0281829833984375
gtp[x1] 0.9697265625 gtp[x2] 0.00032520294189453125 gtp[a] 0.9697265625
pp sum tensor(0.9849, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2289, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9697, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2289, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0874, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.18054707968569805
q_ai sum tensor(0.7559, device='cuda:0', dtype=torch.float16) q[a] 0.755859375
pp sum tensor(0.9775, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7485, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9697, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7485, device='cuda:0', dtype=torch.float16)
pa tensor(0.9697, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7485, device='cuda:0', dtype=torch.float16) acp tensor(1.2959, device='cuda:0', dtype=torch.float16) r 0.5308547272640086

-------------------step: 3-------------------

x1 297 x2 373 a 373
q[a] 0.53173828125 q[x1] 0.1204833984375 q[x2] 0.53173828125
gtp[x1] 0.5478515625 gtp[x2] 0.317138671875 gtp[a] 0.317138671875
px1 tensor(0.5479, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1205, device='cuda:0') acp tensor(4.5471, device='cuda:0') r 0.057716159670205935

-------------------step: 1-------------------

directly accept a 29875

-------------------step: 2-------------------

x1 338 x2 471 a 338
q[a] 0.75439453125 q[x1] 0.75439453125 q[x2] 0.1630859375
gtp[x1] 0.9912109375 gtp[x2] 0.0005311965942382812 gtp[a] 0.9912109375
pp sum tensor(0.9937, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2395, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9912, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2395, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5010, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.10734393032296285
q_ai sum tensor(0.7544, device='cuda:0', dtype=torch.float16) q[a] 0.75439453125
pp sum tensor(0.9937, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7544, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9912, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7544, device='cuda:0', dtype=torch.float16)
pa tensor(0.9912, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7544, device='cuda:0', dtype=torch.float16) acp tensor(1.3135, device='cuda:0', dtype=torch.float16) r 0.01647671826113284

-------------------step: 3-------------------

x1 278 x2 263 a 263
q[a] 0.409423828125 q[x1] 0.244384765625 q[x2] 0.409423828125
gtp[x1] 0.83935546875 gtp[x2] 9.47713851928711e-06 gtp[a] 9.47713851928711e-06
px1 tensor(0.8394, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2444, device='cuda:0') acp tensor(3.4346, device='cuda:0') r 0.43669323768612034

-------------------step: 1-------------------

directly accept a 29880

-------------------step: 2-------------------

x1 3145 x2 361 a 361
q[a] 0.434814453125 q[x1] 0.0019140243530273438 q[x2] 0.434814453125
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0019, device='cuda:0') acp tensor(0., device='cuda:0') r 0.4792897415548155
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5635, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5635, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4348, device='cuda:0', dtype=torch.float16) q[a] 0.434814453125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4348, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4348, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5635, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6909102570260994
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9990, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 4089

-------------------step: 2-------------------

x1 7935 x2 7457 a 7935
q[a] 0.483154296875 q[x1] 0.483154296875 q[x2] 0.09368896484375
gtp[x1] 5.960464477539063e-08 gtp[x2] 1.1324882507324219e-06 gtp[a] 5.960464477539063e-08
pp sum tensor(0.9780, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4949, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(5.9605e-08, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4949, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0876, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.301920876758514
q_ai sum tensor(0.4832, device='cuda:0', dtype=torch.float16) q[a] 0.483154296875
pp sum tensor(0.9624, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4675, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(5.9605e-08, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4675, device='cuda:0', dtype=torch.float16)
pa tensor(5.9605e-08, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4675, device='cuda:0', dtype=torch.float16) acp tensor(1.1921e-07, device='cuda:0', dtype=torch.float16) r 0.1616071121801662
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9624, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 23542 x2 19722 a 19722
q[a] 0.344970703125 q[x1] 0.08258056640625 q[x2] 0.344970703125
gtp[x1] 0.194091796875 gtp[x2] 0.76806640625 gtp[a] 0.76806640625
px1 tensor(0.1941, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0826, device='cuda:0') acp tensor(2.3503, device='cuda:0') r 0.140398323823544

-------------------step: 2-------------------

x1 29892 x2 284 a 29892
q[a] 0.53662109375 q[x1] 0.53662109375 q[x2] 0.05029296875
gtp[x1] 0.1922607421875 gtp[x2] 0.0 gtp[a] 0.1922607421875
pp sum tensor(0.8379, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3015, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1923, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3015, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0582, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.16805020490076994
q_ai sum tensor(0.5366, device='cuda:0', dtype=torch.float16) q[a] 0.53662109375
pp sum tensor(0.6626, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3613, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1923, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3613, device='cuda:0', dtype=torch.float16)
pa tensor(0.1923, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3613, device='cuda:0', dtype=torch.float16) acp tensor(0.5322, device='cuda:0', dtype=torch.float16) r 0.7957204543750185
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.4702, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 910 x2 450 a 910
q[a] 0.358642578125 q[x1] 0.358642578125 q[x2] 0.316650390625
gtp[x1] 0.77783203125 gtp[x2] 0.01446533203125 gtp[a] 0.77783203125
pp sum tensor(0.8022, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4436, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7778, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4436, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1770, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1875139983646128
q_ai sum tensor(0.3586, device='cuda:0', dtype=torch.float16) q[a] 0.358642578125
pp sum tensor(0.7896, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3457, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7778, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3457, device='cuda:0', dtype=torch.float16)
pa tensor(0.7778, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3457, device='cuda:0', dtype=torch.float16) acp tensor(2.2500, device='cuda:0', dtype=torch.float16) r 0.319327274361936

-------------------step: 2-------------------

x1 4595 x2 22879 a 22879
q[a] 0.438720703125 q[x1] 0.00650787353515625 q[x2] 0.438720703125
gtp[x1] 2.384185791015625e-07 gtp[x2] 0.79541015625 gtp[a] 0.79541015625
px1 tensor(2.3842e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0065, device='cuda:0') acp tensor(3.6635e-05, device='cuda:0') r 0.12085845772461545
pp sum tensor(0.9331, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4944, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7954, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4944, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4387, device='cuda:0', dtype=torch.float16) q[a] 0.438720703125
pp sum tensor(0.9019, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4075, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7954, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4075, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3879, device='cuda:0', dtype=torch.float16)
pa tensor(0.3879, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4944, device='cuda:0', dtype=torch.float16) acp tensor(0.7847, device='cuda:0', dtype=torch.float16) r 0.966990311319304
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1063, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 3268 x2 19133 a 3268
q[a] 0.6572265625 q[x1] 0.6572265625 q[x2] 0.0021915435791015625
gtp[x1] 0.99267578125 gtp[x2] 1.1920928955078125e-05 gtp[a] 0.99267578125
pp sum tensor(0.9927, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3350, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9927, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3350, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0042, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2034460301340686
q_ai sum tensor(0.6572, device='cuda:0', dtype=torch.float16) q[a] 0.6572265625
pp sum tensor(0.9927, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6572, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9927, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6572, device='cuda:0', dtype=torch.float16)
pa tensor(0.9927, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6572, device='cuda:0', dtype=torch.float16) acp tensor(1.5107, device='cuda:0', dtype=torch.float16) r 0.21622722622357105

-------------------step: 2-------------------

x1 338 x2 590 a 338
q[a] 0.4052734375 q[x1] 0.4052734375 q[x2] 1.5795230865478516e-05
gtp[x1] 0.9052734375 gtp[x2] 2.384185791015625e-07 gtp[a] 0.9052734375
pp sum tensor(0.9438, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5381, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9053, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5381, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(1.0788e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8300976287731283
q_ai sum tensor(0.4053, device='cuda:0', dtype=torch.float16) q[a] 0.4052734375
pp sum tensor(0.9395, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4011, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9053, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4011, device='cuda:0', dtype=torch.float16)
pa tensor(0.9053, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4011, device='cuda:0', dtype=torch.float16) acp tensor(2.2578, device='cuda:0', dtype=torch.float16) r 0.21253549274955352

-------------------step: 3-------------------

x1 263 x2 385 a 263
q[a] 0.95947265625 q[x1] 0.95947265625 q[x2] 0.01065826416015625
gtp[x1] 0.9697265625 gtp[x2] 0.0016651153564453125 gtp[a] 0.9697265625
pp sum tensor(0.9897, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0304, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9697, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0304, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2527, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6401717072477014
q_ai sum tensor(0.9595, device='cuda:0', dtype=torch.float16) q[a] 0.95947265625
pp sum tensor(0.9722, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9419, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9697, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9419, device='cuda:0', dtype=torch.float16)
pa tensor(0.9697, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9419, device='cuda:0', dtype=torch.float16) acp tensor(1.0293, device='cuda:0', dtype=torch.float16) r 0.9223234012349084

-------------------step: 1-------------------

x1 29899 x2 13 a 29899
q[a] 1.0 q[x1] 1.0 q[x2] 4.76837158203125e-07
gtp[x1] 0.99853515625 gtp[x2] 1.1920928955078125e-07 gtp[a] 0.99853515625
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(2.0623e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(2.0623e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0173, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.28627799661001097
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.6314060223824526

-------------------step: 2-------------------

x1 2 x2 4149 a 4149
q[a] 0.5654296875 q[x1] 0.2548828125 q[x2] 0.5654296875
gtp[x1] 5.364418029785156e-07 gtp[x2] 0.99365234375 gtp[a] 0.99365234375
px1 tensor(5.3644e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2549, device='cuda:0') acp tensor(2.1047e-06, device='cuda:0') r 0.872323390737976
pp sum tensor(0.9937, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4285, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9937, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4285, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5654, device='cuda:0', dtype=torch.float16) q[a] 0.5654296875
pp sum tensor(0.9937, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5654, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9937, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5654, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4282, device='cuda:0', dtype=torch.float16)
pa tensor(0.4282, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4285, device='cuda:0', dtype=torch.float16) acp tensor(0.9995, device='cuda:0', dtype=torch.float16) r 0.8411087753925683

-------------------step: 3-------------------

x1 6493 x2 1098 a 1098
q[a] 0.2052001953125 q[x1] 0.0200042724609375 q[x2] 0.2052001953125
gtp[x1] 4.76837158203125e-07 gtp[x2] 0.0445556640625 gtp[a] 0.0445556640625
px1 tensor(4.7684e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0200, device='cuda:0') acp tensor(2.3837e-05, device='cuda:0') r 0.30620516995384517
pp sum tensor(0.9644, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7588, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0446, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7588, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2052, device='cuda:0', dtype=torch.float16) q[a] 0.2052001953125
pp sum tensor(0.9561, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1967, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0446, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1967, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7588, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.029676522066961586
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9116, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 5019 x2 14332 a 5019
q[a] 0.8291015625 q[x1] 0.8291015625 q[x2] 0.005374908447265625
gtp[x1] 0.93701171875 gtp[x2] 0.0004646778106689453 gtp[a] 0.93701171875
pp sum tensor(0.9414, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1122, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9370, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1122, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0261, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4782982285289087
q_ai sum tensor(0.8291, device='cuda:0', dtype=torch.float16) q[a] 0.8291015625
pp sum tensor(0.9404, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8281, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9370, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8281, device='cuda:0', dtype=torch.float16)
pa tensor(0.9370, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8281, device='cuda:0', dtype=torch.float16) acp tensor(1.1318, device='cuda:0', dtype=torch.float16) r 0.05818638199349502

-------------------step: 2-------------------

x1 3063 x2 1058 a 1058
q[a] 0.84033203125 q[x1] 0.09881591796875 q[x2] 0.84033203125
gtp[x1] 0.00966644287109375 gtp[x2] 0.060150146484375 gtp[a] 0.060150146484375
px1 tensor(0.0097, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0988, device='cuda:0') acp tensor(0.0978, device='cuda:0') r 0.34683494376896273
pp sum tensor(0.9424, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1019, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0602, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1019, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8403, device='cuda:0', dtype=torch.float16) q[a] 0.84033203125
pp sum tensor(0.6948, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5928, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0602, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5928, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1019, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4927108344395955
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6348, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 297

-------------------step: 2-------------------

x1 3902 x2 278 a 278
q[a] 0.396240234375 q[x1] 0.036285400390625 q[x2] 0.396240234375
gtp[x1] 0.000873565673828125 gtp[x2] 0.04998779296875 gtp[a] 0.04998779296875
px1 tensor(0.0009, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0363, device='cuda:0') acp tensor(0.0241, device='cuda:0') r 0.8639522333662825
pp sum tensor(0.8018, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4055, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0500, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4055, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3962, device='cuda:0', dtype=torch.float16) q[a] 0.396240234375
pp sum tensor(0.7832, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3779, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0500, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3779, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4055, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.32954030448371274
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7334, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 3362

-------------------step: 2-------------------

x1 24658 x2 28739 a 24658
q[a] 0.6796875 q[x1] 0.6796875 q[x2] 0.046966552734375
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3193, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3193, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0995, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6754864441996713
q_ai sum tensor(0.6797, device='cuda:0', dtype=torch.float16) q[a] 0.6796875
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6777, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6777, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6777, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8266001382452912
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9971, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 4955 x2 15839 a 4955
q[a] 0.99462890625 q[x1] 0.99462890625 q[x2] 0.00022935867309570312
gtp[x1] 0.91796875 gtp[x2] 1.817941665649414e-05 gtp[a] 0.91796875
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0045, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9180, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0045, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0449, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3298508894180707
q_ai sum tensor(0.9946, device='cuda:0', dtype=torch.float16) q[a] 0.99462890625
pp sum tensor(0.9414, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9365, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9180, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9365, device='cuda:0', dtype=torch.float16)
pa tensor(0.9180, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9365, device='cuda:0', dtype=torch.float16) acp tensor(0.9800, device='cuda:0', dtype=torch.float16) r 0.36756870432332567

-------------------step: 2-------------------

x1 322 x2 29892 a 322
q[a] 0.7431640625 q[x1] 0.7431640625 q[x2] 0.199951171875
gtp[x1] 0.024993896484375 gtp[x2] 0.1846923828125 gtp[a] 0.024993896484375
pp sum tensor(0.7593, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0165, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0250, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0165, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5781, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.786818069544649
q_ai sum tensor(0.7432, device='cuda:0', dtype=torch.float16) q[a] 0.7431640625
pp sum tensor(0.6338, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6182, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0250, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6182, device='cuda:0', dtype=torch.float16)
pa tensor(0.0250, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6182, device='cuda:0', dtype=torch.float16) acp tensor(0.0404, device='cuda:0', dtype=torch.float16) r 0.9877133654020094
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6089, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 450 x2 1763 a 450
q[a] 0.482421875 q[x1] 0.482421875 q[x2] 0.00437164306640625
gtp[x1] 0.337158203125 gtp[x2] 0.0004544258117675781 gtp[a] 0.337158203125
pp sum tensor(0.7451, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2625, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3372, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2625, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0041, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.0431748864327276
q_ai sum tensor(0.4824, device='cuda:0', dtype=torch.float16) q[a] 0.482421875
pp sum tensor(0.6875, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4248, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.3372, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4248, device='cuda:0', dtype=torch.float16)
pa tensor(0.3372, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4248, device='cuda:0', dtype=torch.float16) acp tensor(0.7935, device='cuda:0', dtype=torch.float16) r 0.6290139712919506

-------------------step: 2-------------------

x1 11126 x2 3268 a 3268
q[a] 0.311279296875 q[x1] 0.0037689208984375 q[x2] 0.311279296875
gtp[x1] 0.00023651123046875 gtp[x2] 0.001964569091796875 gtp[a] 0.001964569091796875
px1 tensor(0.0002, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0038, device='cuda:0') acp tensor(0.0628, device='cuda:0') r 0.9490647461277287
pp sum tensor(0.8076, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4963, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0020, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4963, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3110, device='cuda:0', dtype=torch.float16) q[a] 0.311279296875
pp sum tensor(0.7324, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2363, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0020, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2363, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4963, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.31228239808213676
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7305, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 310 x2 373 a 310
q[a] 0.7607421875 q[x1] 0.7607421875 q[x2] 0.06005859375
gtp[x1] 6.401538848876953e-05 gtp[x2] 0.99951171875 gtp[a] 6.401538848876953e-05
pp sum tensor(0.9395, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1788, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(6.4015e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9395, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1788, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9395, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1909, device='cuda:0', dtype=torch.float16) acp tensor(4.9219, device='cuda:0', dtype=torch.float16) r 0.6261243013903142

-------------------step: 2-------------------

x1 278 x2 1749 a 278
q[a] 0.9921875 q[x1] 0.9921875 q[x2] 0.0002846717834472656
gtp[x1] 5.781650543212891e-06 gtp[x2] 0.0 gtp[a] 5.781650543212891e-06
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0076, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(5.7817e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0076, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0363, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3823832389168992
q_ai sum tensor(0.9922, device='cuda:0', dtype=torch.float16) q[a] 0.9921875
pp sum tensor(0.9819, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9746, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(5.7817e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9746, device='cuda:0', dtype=torch.float16)
pa tensor(5.7817e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9746, device='cuda:0', dtype=torch.float16) acp tensor(5.9605e-06, device='cuda:0', dtype=torch.float16) r 0.7647482887020479
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9819, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29880

-------------------step: 2-------------------

x1 29892 x2 379 a 29892
q[a] 0.1680908203125 q[x1] 0.1680908203125 q[x2] 0.01491546630859375
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
pp sum tensor(0.9312, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7632, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7632, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0030, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.308393550384342
q_ai sum tensor(0.1680, device='cuda:0', dtype=torch.float16) q[a] 0.1680908203125
pp sum tensor(0.9170, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1541, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1541, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1541, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2778892647801653
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9170, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 4089

-------------------step: 2-------------------

x1 491 x2 393 a 393
q[a] 0.440185546875 q[x1] 0.14404296875 q[x2] 0.440185546875
gtp[x1] 0.0011577606201171875 gtp[x2] 4.559755325317383e-05 gtp[a] 4.559755325317383e-05
px1 tensor(0.0012, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1440, device='cuda:0') acp tensor(0.0080, device='cuda:0') r 0.8390096239846782
pp sum tensor(0.8921, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4524, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(4.5598e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4524, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4402, device='cuda:0', dtype=torch.float16) q[a] 0.440185546875
pp sum tensor(0.8765, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4241, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(4.5598e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4241, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4524, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.656301598771971
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8765, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 5846 x2 3979 a 5846
q[a] 0.63720703125 q[x1] 0.63720703125 q[x2] 0.0312347412109375
gtp[x1] 0.9990234375 gtp[x2] 1.138448715209961e-05 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3621, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3621, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0548, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.685605982397053
q_ai sum tensor(0.6372, device='cuda:0', dtype=torch.float16) q[a] 0.63720703125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6372, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6372, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6372, device='cuda:0', dtype=torch.float16) acp tensor(1.5674, device='cuda:0', dtype=torch.float16) r 0.8072320180844865

-------------------step: 2-------------------

directly accept a 29871

-------------------step: 3-------------------

x1 30221 x2 29896 a 29896
q[a] 0.263427734375 q[x1] 0.0010395050048828125 q[x2] 0.263427734375
gtp[x1] 0.0 gtp[x2] 2.110004425048828e-05 gtp[a] 2.110004425048828e-05
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0010, device='cuda:0') acp tensor(0., device='cuda:0') r 0.2337810938780367
pp sum tensor(0.9912, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7275, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.1100e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7275, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2634, device='cuda:0', dtype=torch.float16) q[a] 0.263427734375
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2603, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.1100e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2603, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7275, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7786764981445629
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9878, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 29892 x2 386 a 29892
q[a] 0.994140625 q[x1] 0.994140625 q[x2] 0.004901885986328125
gtp[x1] 0.98583984375 gtp[x2] 0.01406097412109375 gtp[a] 0.98583984375
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9858, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0092, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0092, device='cuda:0', dtype=torch.float16) qx2 tensor(0.8608, device='cuda:0', dtype=torch.float16) acp tensor(0.0106, device='cuda:0', dtype=torch.float16) r 0.5843205866706018
q_ai sum tensor(0.9946, device='cuda:0', dtype=torch.float16) q[a] 0.994140625
pp sum tensor(0.9858, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9854, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9858, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9854, device='cuda:0', dtype=torch.float16)
pa tensor(0.9858, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9854, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.08189472680149978

-------------------step: 2-------------------

directly accept a 29871

-------------------step: 3-------------------

x1 29955 x2 29906 a 29906
q[a] 0.279541015625 q[x1] 0.2391357421875 q[x2] 0.279541015625
gtp[x1] 0.0 gtp[x2] 2.980232238769531e-07 gtp[a] 2.980232238769531e-07
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.2391, device='cuda:0') acp tensor(0., device='cuda:0') r 0.2715720421858455
pp sum tensor(0.8193, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5400, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.9802e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5400, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2793, device='cuda:0', dtype=torch.float16) q[a] 0.279541015625
pp sum tensor(0.7495, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2094, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.9802e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2094, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5400, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6448375667526727
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7495, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 29929

-------------------step: 2-------------------

x1 29945 x2 29929 a 29929
q[a] 0.3125 q[x1] 0.0953369140625 q[x2] 0.3125
gtp[x1] 5.960464477539063e-08 gtp[x2] 1.1324882507324219e-06 gtp[a] 1.1324882507324219e-06
px1 tensor(5.9605e-08, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0953, device='cuda:0') acp tensor(6.2520e-07, device='cuda:0') r 0.18532704055288673
pp sum tensor(0.7603, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4478, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.1325e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4478, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3125, device='cuda:0', dtype=torch.float16) q[a] 0.3125
pp sum tensor(0.6514, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2036, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.1325e-06, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2036, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4478, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5227592210110256
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6514, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29896

-------------------step: 2-------------------

x1 29892 x2 16478 a 29892
q[a] 0.7392578125 q[x1] 0.7392578125 q[x2] 1.0728836059570312e-06
gtp[x1] 0.9287109375 gtp[x2] 0.0 gtp[a] 0.9287109375
pp sum tensor(0.9453, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2058, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9287, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2058, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(3.0398e-06, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.367223872906554
q_ai sum tensor(0.7393, device='cuda:0', dtype=torch.float16) q[a] 0.7392578125
pp sum tensor(0.9287, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7227, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9287, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7227, device='cuda:0', dtype=torch.float16)
pa tensor(0.9287, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7227, device='cuda:0', dtype=torch.float16) acp tensor(1.2852, device='cuda:0', dtype=torch.float16) r 0.86858848110959

-------------------step: 3-------------------

x1 322 x2 10902 a 322
q[a] 0.396484375 q[x1] 0.396484375 q[x2] 0.07220458984375
gtp[x1] 5.5789947509765625e-05 gtp[x2] 0.031982421875 gtp[a] 5.5789947509765625e-05
pp sum tensor(0.8755, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4788, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(5.5790e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4788, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0474, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5015807010526724
q_ai sum tensor(0.3965, device='cuda:0', dtype=torch.float16) q[a] 0.396484375
pp sum tensor(0.8389, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3601, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(5.5790e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3601, device='cuda:0', dtype=torch.float16)
pa tensor(5.5790e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3601, device='cuda:0', dtype=torch.float16) acp tensor(0.0002, device='cuda:0', dtype=torch.float16) r 0.9860776275854031
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8389, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 263

-------------------step: 2-------------------

x1 7282 x2 4655 a 7282
q[a] 0.310546875 q[x1] 0.310546875 q[x2] 0.1585693359375
gtp[x1] 0.028289794921875 gtp[x2] 0.01715087890625 gtp[a] 0.028289794921875
pp sum tensor(0.8760, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5649, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0283, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5649, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0714, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7716132013062514
q_ai sum tensor(0.3105, device='cuda:0', dtype=torch.float16) q[a] 0.310546875
pp sum tensor(0.8359, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2703, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0283, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2703, device='cuda:0', dtype=torch.float16)
pa tensor(0.0283, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2703, device='cuda:0', dtype=torch.float16) acp tensor(0.1047, device='cuda:0', dtype=torch.float16) r 0.6010490620926918
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8076, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 440

-------------------step: 2-------------------

directly accept a 7288

-------------------step: 3-------------------

x1 3256 x2 1741 a 3256
q[a] 0.73583984375 q[x1] 0.73583984375 q[x2] 0.0865478515625
gtp[x1] 0.99365234375 gtp[x2] 0.003814697265625 gtp[a] 0.99365234375
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2588, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9937, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2588, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2415, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6867095239489519
q_ai sum tensor(0.7358, device='cuda:0', dtype=torch.float16) q[a] 0.73583984375
pp sum tensor(0.9937, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7344, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9937, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7344, device='cuda:0', dtype=torch.float16)
pa tensor(0.9937, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7344, device='cuda:0', dtype=torch.float16) acp tensor(1.3535, device='cuda:0', dtype=torch.float16) r 0.8060621111817412

-------------------step: 1-------------------

x1 3082 x2 6813 a 3082
q[a] 0.89013671875 q[x1] 0.89013671875 q[x2] 0.07080078125
gtp[x1] 0.60498046875 gtp[x2] 0.00704193115234375 gtp[a] 0.60498046875
pp sum tensor(0.9595, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0693, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6050, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0693, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5732, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.06655626191986375
q_ai sum tensor(0.8901, device='cuda:0', dtype=torch.float16) q[a] 0.89013671875
pp sum tensor(0.7705, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7012, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.6050, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7012, device='cuda:0', dtype=torch.float16)
pa tensor(0.6050, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7012, device='cuda:0', dtype=torch.float16) acp tensor(0.8628, device='cuda:0', dtype=torch.float16) r 0.8978380395833653
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1656, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 29889

-------------------step: 2-------------------

x1 450 x2 3645 a 3645
q[a] 0.138427734375 q[x1] 0.07177734375 q[x2] 0.138427734375
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0718, device='cuda:0') acp tensor(0., device='cuda:0') r 0.6876010156450307
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8613, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8613, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1383, device='cuda:0', dtype=torch.float16) q[a] 0.138427734375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1382, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1382, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8613, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.09165134948025011
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9995, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29889 x2 1696 a 29889
q[a] 0.99853515625 q[x1] 0.99853515625 q[x2] 0.0011873245239257812
gtp[x1] 0.9912109375 gtp[x2] 3.5762786865234375e-07 gtp[a] 0.9912109375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0013, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9912, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0013, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8848, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.42775465430323845
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16) q[a] 0.99853515625
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9966, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9912, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9966, device='cuda:0', dtype=torch.float16)
pa tensor(0.9912, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9966, device='cuda:0', dtype=torch.float16) acp tensor(0.9946, device='cuda:0', dtype=torch.float16) r 0.858486119746918

-------------------step: 2-------------------

x1 6726 x2 450 a 450
q[a] 0.14306640625 q[x1] 0.0008306503295898438 q[x2] 0.14306640625
gtp[x1] 0.0 gtp[x2] 2.980232238769531e-07 gtp[a] 2.980232238769531e-07
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0008, device='cuda:0') acp tensor(0., device='cuda:0') r 0.0726441393860836
pp sum tensor(0.9937, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8501, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.9802e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8501, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1429, device='cuda:0', dtype=torch.float16) q[a] 0.14306640625
pp sum tensor(0.9922, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1420, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.9802e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1420, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8501, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.27765666586077276
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9922, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29892 x2 322 a 29892
q[a] 0.382080078125 q[x1] 0.382080078125 q[x2] 0.306884765625
gtp[x1] 0.64306640625 gtp[x2] 0.33349609375 gtp[a] 0.64306640625
pp sum tensor(0.6895, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3071, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6431, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0266, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3071, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0266, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1897, device='cuda:0', dtype=torch.float16) acp tensor(0.1403, device='cuda:0', dtype=torch.float16) r 0.604454015352804
q_ai sum tensor(0.3821, device='cuda:0', dtype=torch.float16) q[a] 0.382080078125
pp sum tensor(0.6616, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3540, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.6431, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3540, device='cuda:0', dtype=torch.float16)
pa tensor(0.6431, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3540, device='cuda:0', dtype=torch.float16) acp tensor(1.8164, device='cuda:0', dtype=torch.float16) r 0.5404475914882654

-------------------step: 2-------------------

directly accept a 322

-------------------step: 3-------------------

x1 5331 x2 372 a 372
q[a] 0.5927734375 q[x1] 0.019500732421875 q[x2] 0.5927734375
gtp[x1] 0.0 gtp[x2] 0.004791259765625 gtp[a] 0.004791259765625
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0195, device='cuda:0') acp tensor(0., device='cuda:0') r 0.26523961278147723
pp sum tensor(0.9697, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3774, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0048, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3774, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5928, device='cuda:0', dtype=torch.float16) q[a] 0.5927734375
pp sum tensor(0.9321, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5547, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0048, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5547, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3774, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7243564014845366
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9272, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 6282 x2 3268 a 3268
q[a] 0.48193359375 q[x1] 0.0672607421875 q[x2] 0.48193359375
gtp[x1] 0.00010800361633300781 gtp[x2] 0.06341552734375 gtp[a] 0.06341552734375
px1 tensor(0.0001, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0673, device='cuda:0') acp tensor(0.0016, device='cuda:0') r 0.08733136844551193
pp sum tensor(0.7905, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3083, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0634, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3083, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4819, device='cuda:0', dtype=torch.float16) q[a] 0.48193359375
pp sum tensor(0.6099, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3018, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0634, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3018, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3083, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9341984419033753
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5469, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 9020

-------------------step: 2-------------------

x1 338 x2 313 a 338
q[a] 0.849609375 q[x1] 0.849609375 q[x2] 1.245737075805664e-05
gtp[x1] 0.1800537109375 gtp[x2] 1.049041748046875e-05 gtp[a] 0.1800537109375
pp sum tensor(0.9561, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1061, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1801, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1061, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(7.0155e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.31972031719481775
q_ai sum tensor(0.8496, device='cuda:0', dtype=torch.float16) q[a] 0.849609375
pp sum tensor(0.7695, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6631, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1801, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6631, device='cuda:0', dtype=torch.float16)
pa tensor(0.1801, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6631, device='cuda:0', dtype=torch.float16) acp tensor(0.2715, device='cuda:0', dtype=torch.float16) r 0.46935991667343535
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5894, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 408 x2 304 a 304
q[a] 0.61865234375 q[x1] 0.381103515625 q[x2] 0.61865234375
gtp[x1] 0.99755859375 gtp[x2] 0.002471923828125 gtp[a] 0.002471923828125
px1 tensor(0.9976, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3811, device='cuda:0') acp tensor(2.6176, device='cuda:0') r 0.9813722695626429

-------------------step: 2-------------------

directly accept a 263

-------------------step: 3-------------------

x1 3268 x2 13988 a 13988
q[a] 0.1385498046875 q[x1] 0.0029430389404296875 q[x2] 0.1385498046875
gtp[x1] 2.2649765014648438e-06 gtp[x2] 0.04803466796875 gtp[a] 0.04803466796875
px1 tensor(2.2650e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0029, device='cuda:0') acp tensor(0.0008, device='cuda:0') r 0.08629946437140756
pp sum tensor(0.8384, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6997, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0480, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6997, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1385, device='cuda:0', dtype=torch.float16) q[a] 0.1385498046875
pp sum tensor(0.8140, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1141, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0480, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1141, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6997, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.007828037501906304
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7661, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 495

-------------------step: 2-------------------

x1 292 x2 2 a 292
q[a] 0.806640625 q[x1] 0.806640625 q[x2] 0.12176513671875
gtp[x1] 3.933906555175781e-06 gtp[x2] 9.357929229736328e-06 gtp[a] 3.933906555175781e-06
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1870, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(3.9339e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1870, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5083, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4291437783250993
q_ai sum tensor(0.8066, device='cuda:0', dtype=torch.float16) q[a] 0.806640625
pp sum tensor(0.9702, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7827, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(3.9339e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7827, device='cuda:0', dtype=torch.float16)
pa tensor(3.9339e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7827, device='cuda:0', dtype=torch.float16) acp tensor(5.0068e-06, device='cuda:0', dtype=torch.float16) r 0.04483276088654975
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9702, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 4995

-------------------step: 2-------------------

directly accept a 310

-------------------step: 3-------------------

x1 278 x2 310 a 278
q[a] 0.98095703125 q[x1] 0.98095703125 q[x2] 2.765655517578125e-05
gtp[x1] 0.90087890625 gtp[x2] 1.3709068298339844e-06 gtp[a] 0.90087890625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0180, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9009, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0180, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0014, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3473467384444262
q_ai sum tensor(0.9810, device='cuda:0', dtype=torch.float16) q[a] 0.98095703125
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9736, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9009, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9736, device='cuda:0', dtype=torch.float16)
pa tensor(0.9009, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9736, device='cuda:0', dtype=torch.float16) acp tensor(0.9253, device='cuda:0', dtype=torch.float16) r 0.999503220641272
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.0909, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 2462 x2 26285 a 2462
q[a] 0.73486328125 q[x1] 0.73486328125 q[x2] 0.0017242431640625
gtp[x1] 0.1279296875 gtp[x2] 7.748603820800781e-07 gtp[a] 0.1279296875
pp sum tensor(0.9463, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2115, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1279, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2115, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0048, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.05258081129739245
q_ai sum tensor(0.7349, device='cuda:0', dtype=torch.float16) q[a] 0.73486328125
pp sum tensor(0.8027, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5913, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1279, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5913, device='cuda:0', dtype=torch.float16)
pa tensor(0.1279, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5913, device='cuda:0', dtype=torch.float16) acp tensor(0.2163, device='cuda:0', dtype=torch.float16) r 0.4861260141870296
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6748, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 22279

-------------------step: 2-------------------

directly accept a 2462

-------------------step: 3-------------------

x1 29889 x2 1550 a 29889
q[a] 0.9912109375 q[x1] 0.9912109375 q[x2] 0.0004336833953857422
gtp[x1] 0.99609375 gtp[x2] 0.00033926963806152344 gtp[a] 0.99609375
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0047, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0047, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0493, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2722174829378977
q_ai sum tensor(0.9912, device='cuda:0', dtype=torch.float16) q[a] 0.9912109375
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9912, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9912, device='cuda:0', dtype=torch.float16)
pa tensor(0.9961, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9912, device='cuda:0', dtype=torch.float16) acp tensor(1.0049, device='cuda:0', dtype=torch.float16) r 0.8520450106648744

-------------------step: 1-------------------

x1 9758 x2 2626 a 2626
q[a] 0.487548828125 q[x1] 0.00011968612670898438 q[x2] 0.487548828125
gtp[x1] 1.341104507446289e-05 gtp[x2] 0.03680419921875 gtp[a] 0.03680419921875
px1 tensor(1.3411e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0001, device='cuda:0') acp tensor(0.1121, device='cuda:0') r 0.05166435734278407

-------------------step: 2-------------------

x1 338 x2 29892 a 338
q[a] 0.2685546875 q[x1] 0.2685546875 q[x2] 0.1219482421875
gtp[x1] 0.010894775390625 gtp[x2] 0.0004496574401855469 gtp[a] 0.010894775390625
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7173, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0109, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7173, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0448, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5566482424931012
q_ai sum tensor(0.2683, device='cuda:0', dtype=torch.float16) q[a] 0.2685546875
pp sum tensor(0.9854, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2673, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0109, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2673, device='cuda:0', dtype=torch.float16)
pa tensor(0.0109, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2673, device='cuda:0', dtype=torch.float16) acp tensor(0.0407, device='cuda:0', dtype=torch.float16) r 0.007989910373675913

-------------------step: 3-------------------

x1 263 x2 29874 a 263
q[a] 0.87890625 q[x1] 0.87890625 q[x2] 0.00012624263763427734
gtp[x1] 0.0157318115234375 gtp[x2] 1.7881393432617188e-07 gtp[a] 0.0157318115234375
pp sum tensor(0.9351, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0565, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0157, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0565, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0009, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4309033502641405
q_ai sum tensor(0.8789, device='cuda:0', dtype=torch.float16) q[a] 0.87890625
pp sum tensor(0.7588, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7021, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0157, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7021, device='cuda:0', dtype=torch.float16)
pa tensor(0.0157, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7021, device='cuda:0', dtype=torch.float16) acp tensor(0.0224, device='cuda:0', dtype=torch.float16) r 0.9598612501997392
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7427, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 491 x2 411 a 411
q[a] 0.53662109375 q[x1] 0.430908203125 q[x2] 0.53662109375
gtp[x1] 0.92333984375 gtp[x2] 0.0745849609375 gtp[a] 0.0745849609375
px1 tensor(0.9233, device='cuda:0', dtype=torch.float16) qx1 tensor(0.4309, device='cuda:0') acp tensor(2.1428, device='cuda:0') r 0.14834119423716385

-------------------step: 2-------------------

x1 278 x2 263 a 278
q[a] 0.498291015625 q[x1] 0.498291015625 q[x2] 0.329345703125
gtp[x1] 0.72900390625 gtp[x2] 0.248046875 gtp[a] 0.72900390625
pp sum tensor(0.7417, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2430, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7290, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2430, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3271, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.09221137876947061
q_ai sum tensor(0.4983, device='cuda:0', dtype=torch.float16) q[a] 0.498291015625
pp sum tensor(0.7344, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4912, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7290, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4912, device='cuda:0', dtype=torch.float16)
pa tensor(0.7290, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4912, device='cuda:0', dtype=torch.float16) acp tensor(1.4844, device='cuda:0', dtype=torch.float16) r 0.4253507534174099

-------------------step: 3-------------------

x1 17676 x2 17818 a 17676
q[a] 0.1534423828125 q[x1] 0.1534423828125 q[x2] 0.00012159347534179688
gtp[x1] 0.61083984375 gtp[x2] 5.781650543212891e-06 gtp[a] 0.61083984375
pp sum tensor(0.9233, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7700, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6108, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7700, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(2.1994e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6763484613314729
q_ai sum tensor(0.1533, device='cuda:0', dtype=torch.float16) q[a] 0.1534423828125
pp sum tensor(0.9155, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1456, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.6108, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1456, device='cuda:0', dtype=torch.float16)
pa tensor(0.6108, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1456, device='cuda:0', dtype=torch.float16) acp tensor(4.1953, device='cuda:0', dtype=torch.float16) r 0.8981576432808519

-------------------step: 1-------------------

x1 3515 x2 19722 a 19722
q[a] 0.1192626953125 q[x1] 5.78761100769043e-05 q[x2] 0.1192626953125
gtp[x1] 0.0 gtp[x2] 0.9765625 gtp[a] 0.9765625
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(5.7876e-05, device='cuda:0') acp tensor(0., device='cuda:0') r 0.5497470193689344
pp sum tensor(0.9766, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8574, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9766, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8574, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1193, device='cuda:0', dtype=torch.float16) q[a] 0.1192626953125
pp sum tensor(0.9766, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1192, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9766, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1192, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8574, device='cuda:0', dtype=torch.float16)
pa tensor(0.8574, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8574, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.836058559591647

-------------------step: 2-------------------

x1 2 x2 297 a 297
q[a] 0.233154296875 q[x1] 0.005031585693359375 q[x2] 0.233154296875
gtp[x1] 1.3470649719238281e-05 gtp[x2] 7.49826431274414e-05 gtp[a] 7.49826431274414e-05
px1 tensor(1.3471e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0050, device='cuda:0') acp tensor(0.0027, device='cuda:0') r 0.721639951031783
pp sum tensor(0.7505, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5166, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(7.4983e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5166, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2330, device='cuda:0', dtype=torch.float16) q[a] 0.233154296875
pp sum tensor(0.6812, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1643, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(7.4983e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1643, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5166, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5355064543010031
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6812, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 607 x2 988 a 607
q[a] 0.814453125 q[x1] 0.814453125 q[x2] 0.12890625
gtp[x1] 0.5615234375 gtp[x2] 0.0069580078125 gtp[a] 0.5615234375
pp sum tensor(0.9736, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1589, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.5615, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1589, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5659, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7558425731621634
q_ai sum tensor(0.8145, device='cuda:0', dtype=torch.float16) q[a] 0.814453125
pp sum tensor(0.8989, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7397, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.5615, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7397, device='cuda:0', dtype=torch.float16)
pa tensor(0.5615, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7397, device='cuda:0', dtype=torch.float16) acp tensor(0.7593, device='cuda:0', dtype=torch.float16) r 0.9129531232404484
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3374, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 1047 x2 13849 a 13849
q[a] 0.1181640625 q[x1] 0.0023784637451171875 q[x2] 0.1181640625
gtp[x1] 0.01401519775390625 gtp[x2] 0.004657745361328125 gtp[a] 0.004657745361328125
px1 tensor(0.0140, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0024, device='cuda:0') acp tensor(5.8925, device='cuda:0') r 0.8517667839565378

-------------------step: 2-------------------

directly accept a 495

-------------------step: 3-------------------

x1 292 x2 29899 a 29899
q[a] 0.4755859375 q[x1] 0.1937255859375 q[x2] 0.4755859375
gtp[x1] 4.202127456665039e-05 gtp[x2] 0.0013275146484375 gtp[a] 0.0013275146484375
px1 tensor(4.2021e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1937, device='cuda:0') acp tensor(0.0002, device='cuda:0') r 0.9968266770445805
pp sum tensor(0.9624, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4863, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0013, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4863, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4756, device='cuda:0', dtype=torch.float16) q[a] 0.4755859375
pp sum tensor(0.9482, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4617, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0013, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4617, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4863, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5884845236299102
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9468, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 380 x2 9560 a 9560
q[a] 0.1304931640625 q[x1] 0.055694580078125 q[x2] 0.1304931640625
gtp[x1] 0.001476287841796875 gtp[x2] 0.08062744140625 gtp[a] 0.08062744140625
px1 tensor(0.0015, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0557, device='cuda:0') acp tensor(0.0265, device='cuda:0') r 0.9001234204707997
pp sum tensor(0.7378, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6074, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0806, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6074, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1304, device='cuda:0', dtype=torch.float16) q[a] 0.1304931640625
pp sum tensor(0.7148, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1072, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0806, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1072, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6074, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8505022742960255
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6343, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 569 x2 20657 a 569
q[a] 0.64013671875 q[x1] 0.64013671875 q[x2] 0.1036376953125
gtp[x1] 0.00039196014404296875 gtp[x2] 1.7881393432617188e-07 gtp[a] 0.00039196014404296875
pp sum tensor(0.8701, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2300, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0004, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2300, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1842, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6699305589606097
q_ai sum tensor(0.6401, device='cuda:0', dtype=torch.float16) q[a] 0.64013671875
pp sum tensor(0.6392, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4092, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0004, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4092, device='cuda:0', dtype=torch.float16)
pa tensor(0.0004, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4092, device='cuda:0', dtype=torch.float16) acp tensor(0.0010, device='cuda:0', dtype=torch.float16) r 0.6961852051650174
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6387, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 7751 x2 260 a 260
q[a] 0.248779296875 q[x1] 0.0027008056640625 q[x2] 0.248779296875
gtp[x1] 8.881092071533203e-06 gtp[x2] 0.060150146484375 gtp[a] 0.060150146484375
px1 tensor(8.8811e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0027, device='cuda:0') acp tensor(0.0033, device='cuda:0') r 0.6051388571545462
pp sum tensor(0.9106, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6616, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0602, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6616, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2488, device='cuda:0', dtype=torch.float16) q[a] 0.248779296875
pp sum tensor(0.9087, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2462, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0602, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2462, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6616, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7819857071206854
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8481, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29892 x2 393 a 29892
q[a] 0.37890625 q[x1] 0.37890625 q[x2] 0.373046875
gtp[x1] 0.0163116455078125 gtp[x2] 0.76171875 gtp[a] 0.0163116455078125
pp sum tensor(0.4507, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0718, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0163, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3887, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0718, device='cuda:0', dtype=torch.float16)
px2 tensor(0.3887, device='cuda:0', dtype=torch.float16) qx2 tensor(0.2275, device='cuda:0', dtype=torch.float16) acp tensor(1.7080, device='cuda:0', dtype=torch.float16) r 0.6737779781306895

-------------------step: 2-------------------

x1 4207 x2 19781 a 19781
q[a] 0.135009765625 q[x1] 0.0762939453125 q[x2] 0.135009765625
gtp[x1] 0.1419677734375 gtp[x2] 0.0131072998046875 gtp[a] 0.0131072998046875
px1 tensor(0.1420, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0763, device='cuda:0') acp tensor(1.8608, device='cuda:0') r 0.05979853551772352

-------------------step: 3-------------------

directly accept a 943

-------------------step: 1-------------------

x1 3303 x2 12080 a 12080
q[a] 0.32861328125 q[x1] 0.000629425048828125 q[x2] 0.32861328125
gtp[x1] 2.8967857360839844e-05 gtp[x2] 0.060302734375 gtp[a] 0.060302734375
px1 tensor(2.8968e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0006, device='cuda:0') acp tensor(0.0460, device='cuda:0') r 0.35703430804512626
pp sum tensor(0.6890, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3601, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0603, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3601, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3284, device='cuda:0', dtype=torch.float16) q[a] 0.32861328125
pp sum tensor(0.5879, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2275, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0603, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2275, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3601, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2131748921054505
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5273, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29896 x2 29947 a 29896
q[a] 0.80419921875 q[x1] 0.80419921875 q[x2] 0.008392333984375
gtp[x1] 0.9990234375 gtp[x2] 4.947185516357422e-06 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1948, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1948, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0345, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5851554948367836
q_ai sum tensor(0.8042, device='cuda:0', dtype=torch.float16) q[a] 0.80419921875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8042, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8042, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8042, device='cuda:0', dtype=torch.float16) acp tensor(1.2422, device='cuda:0', dtype=torch.float16) r 0.07167182774955427

-------------------step: 2-------------------

x1 29945 x2 29906 a 29906
q[a] 0.18310546875 q[x1] 0.1119384765625 q[x2] 0.18310546875
gtp[x1] 3.5762786865234375e-07 gtp[x2] 1.3113021850585938e-06 gtp[a] 1.3113021850585938e-06
px1 tensor(3.5763e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1119, device='cuda:0') acp tensor(3.1949e-06, device='cuda:0') r 0.630533182043563
pp sum tensor(0.9155, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7319, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.3113e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7319, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1831, device='cuda:0', dtype=torch.float16) q[a] 0.18310546875
pp sum tensor(0.8965, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1641, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.3113e-06, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1641, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7319, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.042264267577419856
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8965, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29947 x2 29896 a 29947
q[a] 0.57666015625 q[x1] 0.57666015625 q[x2] 0.349853515625
gtp[x1] 1.1920928955078125e-07 gtp[x2] 1.0 gtp[a] 1.1920928955078125e-07
pp sum tensor(0.6504, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0734, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.1921e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6504, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0734, device='cuda:0', dtype=torch.float16)
px2 tensor(0.6504, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4768, device='cuda:0', dtype=torch.float16) acp tensor(1.3643, device='cuda:0', dtype=torch.float16) r 0.4153302318631106

-------------------step: 2-------------------

x1 29947 x2 29906 a 29947
q[a] 0.46630859375 q[x1] 0.46630859375 q[x2] 0.346435546875
gtp[x1] 1.8358230590820312e-05 gtp[x2] 1.823902130126953e-05 gtp[a] 1.8358230590820312e-05
pp sum tensor(0.9653, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4988, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.8358e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4988, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3027, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5293899127774656
q_ai sum tensor(0.4663, device='cuda:0', dtype=torch.float16) q[a] 0.46630859375
pp sum tensor(0.9351, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4358, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(1.8358e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4358, device='cuda:0', dtype=torch.float16)
pa tensor(1.8358e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4358, device='cuda:0', dtype=torch.float16) acp tensor(4.2140e-05, device='cuda:0', dtype=torch.float16) r 0.4987711942257992
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9351, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29955 x2 29906 a 29906
q[a] 0.304443359375 q[x1] 0.0673828125 q[x2] 0.304443359375
gtp[x1] 1.0 gtp[x2] 7.092952728271484e-06 gtp[a] 7.092952728271484e-06
px1 tensor(1., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0674, device='cuda:0') acp tensor(14.8406, device='cuda:0') r 0.07647764541558844

-------------------step: 2-------------------

x1 2305 x2 13936 a 13936
q[a] 0.2301025390625 q[x1] 0.06591796875 q[x2] 0.2301025390625
gtp[x1] 0.00036644935607910156 gtp[x2] 0.004161834716796875 gtp[a] 0.004161834716796875
px1 tensor(0.0004, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0659, device='cuda:0') acp tensor(0.0056, device='cuda:0') r 0.6899038373767541
pp sum tensor(0.8657, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6353, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0042, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6353, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2301, device='cuda:0', dtype=torch.float16) q[a] 0.2301025390625
pp sum tensor(0.8525, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2170, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0042, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2170, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6353, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5111773998331609
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8481, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 943

-------------------step: 2-------------------

x1 1058 x2 322 a 1058
q[a] 0.97998046875 q[x1] 0.97998046875 q[x2] 0.00615692138671875
gtp[x1] 0.06640625 gtp[x2] 0.93115234375 gtp[a] 0.06640625
pp sum tensor(0.9927, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0129, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0664, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9248, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0129, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9248, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3044, device='cuda:0', dtype=torch.float16) acp tensor(3.0371, device='cuda:0', dtype=torch.float16) r 0.2501120004422146

-------------------step: 3-------------------

x1 3578 x2 26824 a 26824
q[a] 0.1807861328125 q[x1] 3.17692756652832e-05 q[x2] 0.1807861328125
gtp[x1] 0.0 gtp[x2] 2.980232238769531e-07 gtp[a] 2.980232238769531e-07
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(3.1769e-05, device='cuda:0') acp tensor(0., device='cuda:0') r 0.16989099809608632
pp sum tensor(0.9902, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8096, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.9802e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8096, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1807, device='cuda:0', dtype=torch.float16) q[a] 0.1807861328125
pp sum tensor(0.9897, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1803, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.9802e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1803, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8096, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5242338794657868
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9897, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 5727 x2 328 a 328
q[a] 0.09716796875 q[x1] 0.0210113525390625 q[x2] 0.09716796875
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0210, device='cuda:0') acp tensor(0., device='cuda:0') r 0.04569032204018486
pp sum tensor(0.9814, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8843, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8843, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0971, device='cuda:0', dtype=torch.float16) q[a] 0.09716796875
pp sum tensor(0.9795, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0952, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0952, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8843, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9591763296309428
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9795, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 1058 x2 5069 a 1058
q[a] 0.994140625 q[x1] 0.994140625 q[x2] 0.0003578662872314453
gtp[x1] 0.99169921875 gtp[x2] 0.0002510547637939453 gtp[a] 0.99169921875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0044, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0044, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0624, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8073097133470797
q_ai sum tensor(0.9941, device='cuda:0', dtype=torch.float16) q[a] 0.994140625
pp sum tensor(0.9946, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9902, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9902, device='cuda:0', dtype=torch.float16)
pa tensor(0.9917, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9902, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.8003690121900215

-------------------step: 2-------------------

x1 892 x2 526 a 892
q[a] 0.7890625 q[x1] 0.7890625 q[x2] 0.0291900634765625
gtp[x1] 0.0210723876953125 gtp[x2] 1.633167266845703e-05 gtp[a] 0.0210723876953125
pp sum tensor(0.9214, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1323, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0211, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1323, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1093, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.28499225858067856
q_ai sum tensor(0.7891, device='cuda:0', dtype=torch.float16) q[a] 0.7890625
pp sum tensor(0.7168, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5845, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0211, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5845, device='cuda:0', dtype=torch.float16)
pa tensor(0.0211, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5845, device='cuda:0', dtype=torch.float16) acp tensor(0.0360, device='cuda:0', dtype=torch.float16) r 0.811903855137278
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6953, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 1009

-------------------step: 2-------------------

directly accept a 12080

-------------------step: 3-------------------

x1 373 x2 297 a 373
q[a] 0.94384765625 q[x1] 0.94384765625 q[x2] 0.028961181640625
gtp[x1] 0.470703125 gtp[x2] 0.071044921875 gtp[a] 0.470703125
pp sum tensor(0.9580, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0137, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4707, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0421, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0137, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0421, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4890, device='cuda:0', dtype=torch.float16) acp tensor(0.0861, device='cuda:0', dtype=torch.float16) r 0.8425198502969593
q_ai sum tensor(0.9438, device='cuda:0', dtype=torch.float16) q[a] 0.94384765625
pp sum tensor(0.8638, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8496, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4707, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8496, device='cuda:0', dtype=torch.float16)
pa tensor(0.4707, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8496, device='cuda:0', dtype=torch.float16) acp tensor(0.5542, device='cuda:0', dtype=torch.float16) r 0.7052583335557235
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3931, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 278 x2 393 a 278
q[a] 0.970703125 q[x1] 0.970703125 q[x2] 0.028411865234375
gtp[x1] 0.99609375 gtp[x2] 0.0037059783935546875 gtp[a] 0.99609375
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0257, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0257, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9341, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7755878729128056
q_ai sum tensor(0.9702, device='cuda:0', dtype=torch.float16) q[a] 0.970703125
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9702, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9702, device='cuda:0', dtype=torch.float16)
pa tensor(0.9961, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9702, device='cuda:0', dtype=torch.float16) acp tensor(1.0264, device='cuda:0', dtype=torch.float16) r 0.6756826974344341

-------------------step: 2-------------------

x1 2462 x2 8957 a 2462
q[a] 0.243408203125 q[x1] 0.243408203125 q[x2] 0.003871917724609375
gtp[x1] 4.172325134277344e-07 gtp[x2] 1.0192394256591797e-05 gtp[a] 4.172325134277344e-07
pp sum tensor(0.9580, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7144, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(4.1723e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7144, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0012, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.44585779247087864
q_ai sum tensor(0.2434, device='cuda:0', dtype=torch.float16) q[a] 0.243408203125
pp sum tensor(0.9453, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2305, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(4.1723e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2305, device='cuda:0', dtype=torch.float16)
pa tensor(4.1723e-07, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2305, device='cuda:0', dtype=torch.float16) acp tensor(1.7881e-06, device='cuda:0', dtype=torch.float16) r 0.5800903898123738
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9453, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29889

-------------------step: 2-------------------

x1 13 x2 450 a 13
q[a] 0.7587890625 q[x1] 0.7587890625 q[x2] 0.1278076171875
gtp[x1] 0.77490234375 gtp[x2] 0.058837890625 gtp[a] 0.77490234375
pp sum tensor(0.8579, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0991, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7749, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0991, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4021, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8985412342133391
q_ai sum tensor(0.7588, device='cuda:0', dtype=torch.float16) q[a] 0.7587890625
pp sum tensor(0.7817, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6831, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7749, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6831, device='cuda:0', dtype=torch.float16)
pa tensor(0.7749, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6831, device='cuda:0', dtype=torch.float16) acp tensor(1.1348, device='cuda:0', dtype=torch.float16) r 0.26816029888423754

-------------------step: 3-------------------

directly accept a 13

-------------------step: 1-------------------

x1 263 x2 1906 a 1906
q[a] 0.41552734375 q[x1] 0.10919189453125 q[x2] 0.41552734375
gtp[x1] 0.64453125 gtp[x2] 0.294921875 gtp[a] 0.294921875
px1 tensor(0.6445, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1092, device='cuda:0') acp tensor(5.9027, device='cuda:0') r 0.887026342128894

-------------------step: 2-------------------

x1 2090 x2 6493 a 6493
q[a] 0.1744384765625 q[x1] 0.0123443603515625 q[x2] 0.1744384765625
gtp[x1] 0.004619598388671875 gtp[x2] 2.4437904357910156e-06 gtp[a] 2.4437904357910156e-06
px1 tensor(0.0046, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0123, device='cuda:0') acp tensor(0.3742, device='cuda:0') r 0.47328984271489527
pp sum tensor(0.8042, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6294, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.4438e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6294, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1743, device='cuda:0', dtype=torch.float16) q[a] 0.1744384765625
pp sum tensor(0.7739, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1443, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.4438e-06, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1443, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6294, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5229491027243968
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7739, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 5198 x2 16375 a 5198
q[a] 0.341064453125 q[x1] 0.341064453125 q[x2] 0.06304931640625
gtp[x1] 0.01390838623046875 gtp[x2] 0.4462890625 gtp[a] 0.01390838623046875
pp sum tensor(0.8267, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4854, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0139, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3833, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4854, device='cuda:0', dtype=torch.float16)
px2 tensor(0.3833, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0327, device='cuda:0', dtype=torch.float16) acp tensor(11.7422, device='cuda:0', dtype=torch.float16) r 0.17773041734523698

-------------------step: 2-------------------

x1 2625 x2 7271 a 7271
q[a] 0.51220703125 q[x1] 0.004230499267578125 q[x2] 0.51220703125
gtp[x1] 4.798173904418945e-05 gtp[x2] 0.99267578125 gtp[a] 0.99267578125
px1 tensor(4.7982e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0042, device='cuda:0') acp tensor(0.0113, device='cuda:0') r 0.23353050440430667
pp sum tensor(0.9927, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4802, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9927, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4802, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5122, device='cuda:0', dtype=torch.float16) q[a] 0.51220703125
pp sum tensor(0.9927, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5122, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9927, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5122, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4805, device='cuda:0', dtype=torch.float16)
pa tensor(0.4805, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4802, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.15387128126814542

-------------------step: 3-------------------

directly accept a 29892

-------------------step: 1-------------------

x1 772 x2 278 a 278
q[a] 0.79248046875 q[x1] 3.993511199951172e-06 q[x2] 0.79248046875
gtp[x1] 0.0 gtp[x2] 0.982421875 gtp[a] 0.982421875
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(3.9935e-06, device='cuda:0') acp tensor(0., device='cuda:0') r 0.20139848997419496
pp sum tensor(0.9834, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1913, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9824, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1913, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7925, device='cuda:0', dtype=torch.float16) q[a] 0.79248046875
pp sum tensor(0.9834, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7925, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9824, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7925, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1899, device='cuda:0', dtype=torch.float16)
pa tensor(0.1899, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1913, device='cuda:0', dtype=torch.float16) acp tensor(0.9932, device='cuda:0', dtype=torch.float16) r 0.241356783973104

-------------------step: 2-------------------

x1 7906 x2 4272 a 7906
q[a] 0.303955078125 q[x1] 0.303955078125 q[x2] 0.03253173828125
gtp[x1] 0.060150146484375 gtp[x2] 0.0071258544921875 gtp[a] 0.060150146484375
pp sum tensor(0.7896, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4854, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0602, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4854, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0142, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4365807734202941
q_ai sum tensor(0.3037, device='cuda:0', dtype=torch.float16) q[a] 0.303955078125
pp sum tensor(0.7676, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2822, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0602, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2822, device='cuda:0', dtype=torch.float16)
pa tensor(0.0602, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2822, device='cuda:0', dtype=torch.float16) acp tensor(0.2131, device='cuda:0', dtype=torch.float16) r 0.4081371114687091
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7075, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 265 x2 446 a 446
q[a] 0.162841796875 q[x1] 0.00911712646484375 q[x2] 0.162841796875
gtp[x1] 0.0 gtp[x2] 2.384185791015625e-07 gtp[a] 2.384185791015625e-07
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0091, device='cuda:0') acp tensor(0., device='cuda:0') r 0.636846651782043
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8359, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.3842e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8359, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1628, device='cuda:0', dtype=torch.float16) q[a] 0.162841796875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1627, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.3842e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1627, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8359, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8033620012019487
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9985, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 21528 x2 1794 a 1794
q[a] 0.180908203125 q[x1] 0.050262451171875 q[x2] 0.180908203125
gtp[x1] 1.7881393432617188e-07 gtp[x2] 4.172325134277344e-07 gtp[a] 4.172325134277344e-07
px1 tensor(1.7881e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0503, device='cuda:0') acp tensor(3.5576e-06, device='cuda:0') r 0.28350466560451804
pp sum tensor(0.9907, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8096, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(4.1723e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8096, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1809, device='cuda:0', dtype=torch.float16) q[a] 0.180908203125
pp sum tensor(0.9888, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1790, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(4.1723e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1790, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8096, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9612096048727476
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9888, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 17939 x2 6838 a 6838
q[a] 0.07513427734375 q[x1] 0.004512786865234375 q[x2] 0.07513427734375
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0045, device='cuda:0') acp tensor(0., device='cuda:0') r 0.6416950248708871
pp sum tensor(0.9946, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9194, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.9194, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0751, device='cuda:0', dtype=torch.float16) q[a] 0.07513427734375
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0746, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0746, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.9194, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1312680796249881
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9941, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29892 x2 29889 a 29889
q[a] 0.62060546875 q[x1] 0.2978515625 q[x2] 0.62060546875
gtp[x1] 0.5283203125 gtp[x2] 0.28271484375 gtp[a] 0.28271484375
px1 tensor(0.5283, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2979, device='cuda:0') acp tensor(1.7738, device='cuda:0') r 0.658940373165508

-------------------step: 2-------------------

x1 263 x2 607 a 263
q[a] 0.7705078125 q[x1] 0.7705078125 q[x2] 0.142578125
gtp[x1] 0.003261566162109375 gtp[x2] 0.1080322265625 gtp[a] 0.003261566162109375
pp sum tensor(0.8647, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0941, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0033, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0941, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4785, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7085688440951793
q_ai sum tensor(0.7705, device='cuda:0', dtype=torch.float16) q[a] 0.7705078125
pp sum tensor(0.7827, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6890, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0033, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6890, device='cuda:0', dtype=torch.float16)
pa tensor(0.0033, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6890, device='cuda:0', dtype=torch.float16) acp tensor(0.0047, device='cuda:0', dtype=torch.float16) r 0.28735372850859187
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7793, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 22879 x2 4642 a 4642
q[a] 0.59375 q[x1] 0.14208984375 q[x2] 0.59375
gtp[x1] 0.00018322467803955078 gtp[x2] 0.0162353515625 gtp[a] 0.0162353515625
px1 tensor(0.0002, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1421, device='cuda:0') acp tensor(0.0013, device='cuda:0') r 0.832157210992987
pp sum tensor(0.9634, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3691, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0162, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3691, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5938, device='cuda:0', dtype=torch.float16) q[a] 0.59375
pp sum tensor(0.9438, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5737, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0162, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5737, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3691, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7871922398753327
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9277, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 2058 x2 15150 a 15150
q[a] 0.0936279296875 q[x1] 0.00881195068359375 q[x2] 0.0936279296875
gtp[x1] 2.759695053100586e-05 gtp[x2] 0.492431640625 gtp[a] 0.492431640625
px1 tensor(2.7597e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0088, device='cuda:0') acp tensor(0.0031, device='cuda:0') r 0.2829356291880899
pp sum tensor(0.8838, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7905, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4924, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7905, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0936, device='cuda:0', dtype=torch.float16) q[a] 0.0936279296875
pp sum tensor(0.8730, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0831, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4924, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0831, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4094, device='cuda:0', dtype=torch.float16)
pa tensor(0.4094, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7905, device='cuda:0', dtype=torch.float16) acp tensor(0.5181, device='cuda:0', dtype=torch.float16) r 0.635497146150464
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3809, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 15150 x2 29871 a 15150
q[a] 0.1934814453125 q[x1] 0.1934814453125 q[x2] 0.011444091796875
gtp[x1] 0.73486328125 gtp[x2] 6.556510925292969e-07 gtp[a] 0.73486328125
pp sum tensor(0.9907, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7974, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7349, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7974, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0028, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5349281684238792
q_ai sum tensor(0.1934, device='cuda:0', dtype=torch.float16) q[a] 0.1934814453125
pp sum tensor(0.9902, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1927, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7349, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1927, device='cuda:0', dtype=torch.float16)
pa tensor(0.7349, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1927, device='cuda:0', dtype=torch.float16) acp tensor(3.8125, device='cuda:0', dtype=torch.float16) r 0.36649757118236337

-------------------step: 2-------------------

x1 24369 x2 15150 a 24369
q[a] 0.2001953125 q[x1] 0.2001953125 q[x2] 0.0042877197265625
gtp[x1] 0.98095703125 gtp[x2] 4.5299530029296875e-06 gtp[a] 0.98095703125
pp sum tensor(0.9814, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7812, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9810, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7812, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0011, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9068311244438818
q_ai sum tensor(0.2001, device='cuda:0', dtype=torch.float16) q[a] 0.2001953125
pp sum tensor(0.9814, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1998, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9810, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1998, device='cuda:0', dtype=torch.float16)
pa tensor(0.9810, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1998, device='cuda:0', dtype=torch.float16) acp tensor(4.9102, device='cuda:0', dtype=torch.float16) r 0.4912129354124726

-------------------step: 3-------------------

x1 297 x2 373 a 297
q[a] 0.9619140625 q[x1] 0.9619140625 q[x2] 0.02484130859375
gtp[x1] 0.708984375 gtp[x2] 0.00038313865661621094 gtp[a] 0.708984375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0359, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7090, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0359, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6289, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.31798370168759815
q_ai sum tensor(0.9619, device='cuda:0', dtype=torch.float16) q[a] 0.9619140625
pp sum tensor(0.9937, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9575, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7090, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9575, device='cuda:0', dtype=torch.float16)
pa tensor(0.7090, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9575, device='cuda:0', dtype=torch.float16) acp tensor(0.7402, device='cuda:0', dtype=torch.float16) r 0.2934823882489789

-------------------step: 1-------------------

x1 3082 x2 3303 a 3303
q[a] 0.51025390625 q[x1] 0.050140380859375 q[x2] 0.51025390625
gtp[x1] 2.110004425048828e-05 gtp[x2] 0.9833984375 gtp[a] 0.9833984375
px1 tensor(2.1100e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0501, device='cuda:0') acp tensor(0.0004, device='cuda:0') r 0.8867713541541498
pp sum tensor(0.9834, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4729, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9834, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4729, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5103, device='cuda:0', dtype=torch.float16) q[a] 0.51025390625
pp sum tensor(0.9834, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5103, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9834, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5103, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4731, device='cuda:0', dtype=torch.float16)
pa tensor(0.4731, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4729, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.19633725518623257

-------------------step: 2-------------------

directly accept a 3900

-------------------step: 3-------------------

x1 29889 x2 450 a 29889
q[a] 0.966796875 q[x1] 0.966796875 q[x2] 0.00014841556549072266
gtp[x1] 0.83251953125 gtp[x2] 5.960464477539063e-08 gtp[a] 0.83251953125
pp sum tensor(0.9902, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0233, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8325, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0233, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0043, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3751768500251449
q_ai sum tensor(0.9668, device='cuda:0', dtype=torch.float16) q[a] 0.966796875
pp sum tensor(0.9414, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9180, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8325, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9180, device='cuda:0', dtype=torch.float16)
pa tensor(0.8325, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9180, device='cuda:0', dtype=torch.float16) acp tensor(0.9067, device='cuda:0', dtype=torch.float16) r 0.6618126517536594

-------------------step: 1-------------------

x1 301 x2 19133 a 19133
q[a] 0.3623046875 q[x1] 0.0035228729248046875 q[x2] 0.3623046875
gtp[x1] 1.9431114196777344e-05 gtp[x2] 0.006084442138671875 gtp[a] 0.006084442138671875
px1 tensor(1.9431e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0035, device='cuda:0') acp tensor(0.0055, device='cuda:0') r 0.5941867628501956
pp sum tensor(0.6992, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3367, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0061, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3367, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3625, device='cuda:0', dtype=torch.float16) q[a] 0.3623046875
pp sum tensor(0.6187, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2822, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0061, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2822, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3367, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.33622714902866435
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6128, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 27389

-------------------step: 2-------------------

x1 2058 x2 24369 a 24369
q[a] 0.4658203125 q[x1] 0.006195068359375 q[x2] 0.4658203125
gtp[x1] 6.687641143798828e-05 gtp[x2] 0.435302734375 gtp[a] 0.435302734375
px1 tensor(6.6876e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0062, device='cuda:0') acp tensor(0.0108, device='cuda:0') r 0.9426800847333703
pp sum tensor(0.8257, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3601, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4353, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3601, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4658, device='cuda:0', dtype=torch.float16) q[a] 0.4658203125
pp sum tensor(0.7417, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3816, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4353, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3816, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0537, device='cuda:0', dtype=torch.float16)
pa tensor(0.0537, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3601, device='cuda:0', dtype=torch.float16) acp tensor(0.1492, device='cuda:0', dtype=torch.float16) r 0.0017509702604576738

-------------------step: 3-------------------

x1 471 x2 322 a 471
q[a] 0.53857421875 q[x1] 0.53857421875 q[x2] 0.00986480712890625
gtp[x1] 0.8369140625 gtp[x2] 1.895427703857422e-05 gtp[a] 0.8369140625
pp sum tensor(0.8901, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3513, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8369, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3513, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0115, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8359466775595766
q_ai sum tensor(0.5386, device='cuda:0', dtype=torch.float16) q[a] 0.53857421875
pp sum tensor(0.8882, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5366, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8369, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5366, device='cuda:0', dtype=torch.float16)
pa tensor(0.8369, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5366, device='cuda:0', dtype=torch.float16) acp tensor(1.5596, device='cuda:0', dtype=torch.float16) r 0.9148722856082504

-------------------step: 1-------------------

x1 2186 x2 3271 a 3271
q[a] 0.42041015625 q[x1] 0.04644775390625 q[x2] 0.42041015625
gtp[x1] 3.3855438232421875e-05 gtp[x2] 0.0019235610961914062 gtp[a] 0.0019235610961914062
px1 tensor(3.3855e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0464, device='cuda:0') acp tensor(0.0007, device='cuda:0') r 0.21684212862233632
pp sum tensor(0.9380, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5176, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0019, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5176, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4204, device='cuda:0', dtype=torch.float16) q[a] 0.42041015625
pp sum tensor(0.9243, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4070, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0019, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4070, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5176, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6249417445302713
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9224, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 25488 x2 11757 a 25488
q[a] 0.8623046875 q[x1] 0.8623046875 q[x2] 0.0021209716796875
gtp[x1] 0.998046875 gtp[x2] 2.276897430419922e-05 gtp[a] 0.998046875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1360, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1360, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0133, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.07949860458270908
q_ai sum tensor(0.8623, device='cuda:0', dtype=torch.float16) q[a] 0.8623046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8618, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8618, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8618, device='cuda:0', dtype=torch.float16) acp tensor(1.1582, device='cuda:0', dtype=torch.float16) r 0.3304140784153139

-------------------step: 2-------------------

directly accept a 310

-------------------step: 3-------------------

x1 278 x2 450 a 278
q[a] 0.85546875 q[x1] 0.85546875 q[x2] 0.0021381378173828125
gtp[x1] 0.92578125 gtp[x2] 6.616115570068359e-06 gtp[a] 0.92578125
pp sum tensor(0.9268, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0715, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9258, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0715, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0127, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.11051382830212064
q_ai sum tensor(0.8555, device='cuda:0', dtype=torch.float16) q[a] 0.85546875
pp sum tensor(0.9268, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8555, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9258, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8555, device='cuda:0', dtype=torch.float16)
pa tensor(0.9258, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8555, device='cuda:0', dtype=torch.float16) acp tensor(1.0820, device='cuda:0', dtype=torch.float16) r 0.8340913580845659

-------------------step: 1-------------------

directly accept a 713

-------------------step: 2-------------------

x1 25552 x2 4088 a 25552
q[a] 0.293212890625 q[x1] 0.293212890625 q[x2] 0.1763916015625
gtp[x1] 0.884765625 gtp[x2] 0.0018463134765625 gtp[a] 0.884765625
pp sum tensor(0.9722, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6792, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8848, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6792, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0731, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4780491570277582
q_ai sum tensor(0.2930, device='cuda:0', dtype=torch.float16) q[a] 0.293212890625
pp sum tensor(0.9702, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2910, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8848, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2910, device='cuda:0', dtype=torch.float16)
pa tensor(0.8848, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2910, device='cuda:0', dtype=torch.float16) acp tensor(3.0410, device='cuda:0', dtype=torch.float16) r 0.7108936160889912

-------------------step: 3-------------------

x1 322 x2 310 a 310
q[a] 0.59130859375 q[x1] 0.275146484375 q[x2] 0.59130859375
gtp[x1] 6.920099258422852e-05 gtp[x2] 3.5762786865234375e-07 gtp[a] 3.5762786865234375e-07
px1 tensor(6.9201e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2751, device='cuda:0') acp tensor(0.0003, device='cuda:0') r 0.7890939564237349
pp sum tensor(0.9907, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3992, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(3.5763e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3992, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5913, device='cuda:0', dtype=torch.float16) q[a] 0.59130859375
pp sum tensor(0.9775, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5781, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(3.5763e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5781, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3992, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9311479508435236
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9775, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 363 x2 515 a 515
q[a] 0.3642578125 q[x1] 0.0972900390625 q[x2] 0.3642578125
gtp[x1] 0.00803375244140625 gtp[x2] 0.75830078125 gtp[a] 0.75830078125
px1 tensor(0.0080, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0973, device='cuda:0') acp tensor(0.0826, device='cuda:0') r 0.4202198080544929
pp sum tensor(0.7793, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4148, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7583, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4148, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3643, device='cuda:0', dtype=torch.float16) q[a] 0.3642578125
pp sum tensor(0.7764, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3613, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7583, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3613, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3970, device='cuda:0', dtype=torch.float16)
pa tensor(0.3970, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4148, device='cuda:0', dtype=torch.float16) acp tensor(0.9570, device='cuda:0', dtype=torch.float16) r 0.4097814211338703

-------------------step: 2-------------------

x1 15150 x2 26901 a 26901
q[a] 0.68408203125 q[x1] 0.0021266937255859375 q[x2] 0.68408203125
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0021, device='cuda:0') acp tensor(0., device='cuda:0') r 0.436260462903149
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3147, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3147, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6841, device='cuda:0', dtype=torch.float16) q[a] 0.68408203125
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6821, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6821, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3147, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5372709484704913
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9966, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29896

-------------------step: 2-------------------

x1 29929 x2 29941 a 29929
q[a] 0.99560546875 q[x1] 0.99560546875 q[x2] 0.00017464160919189453
gtp[x1] 3.159046173095703e-06 gtp[x2] 0.0 gtp[a] 3.159046173095703e-06
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(3.1590e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0401, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3977689368952443
q_ai sum tensor(0.9956, device='cuda:0', dtype=torch.float16) q[a] 0.99560546875
pp sum tensor(0.1943, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1934, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(3.1590e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1934, device='cuda:0', dtype=torch.float16)
pa tensor(3.1590e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1934, device='cuda:0', dtype=torch.float16) acp tensor(1.6332e-05, device='cuda:0', dtype=torch.float16) r 0.7739664451384286
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1943, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29929 x2 29946 a 29929
q[a] 0.89599609375 q[x1] 0.89599609375 q[x2] 0.02685546875
gtp[x1] 7.516145706176758e-05 gtp[x2] 0.99609375 gtp[a] 7.516145706176758e-05
pp sum tensor(0.9692, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0731, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(7.5161e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9692, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0731, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9692, device='cuda:0', dtype=torch.float16) qx2 tensor(0.2321, device='cuda:0', dtype=torch.float16) acp tensor(4.1758, device='cuda:0', dtype=torch.float16) r 0.705048180245207

-------------------step: 2-------------------

x1 304 x2 2745 a 304
q[a] 0.984375 q[x1] 0.984375 q[x2] 0.01319122314453125
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0157, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0157, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8237, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2818202637467726
q_ai sum tensor(0.9844, device='cuda:0', dtype=torch.float16) q[a] 0.984375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9834, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9834, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9834, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9513199506607024
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9995, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 322 x2 304 a 322
q[a] 0.489013671875 q[x1] 0.489013671875 q[x2] 0.336181640625
gtp[x1] 9.5367431640625e-07 gtp[x2] 0.84619140625 gtp[a] 9.5367431640625e-07
pp sum tensor(0.5190, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0299, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(9.5367e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5098, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0299, device='cuda:0', dtype=torch.float16)
px2 tensor(0.5098, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3218, device='cuda:0', dtype=torch.float16) acp tensor(1.5840, device='cuda:0', dtype=torch.float16) r 0.9990999167079054

-------------------step: 2-------------------

x1 278 x2 967 a 278
q[a] 1.0 q[x1] 1.0 q[x2] 2.014636993408203e-05
gtp[x1] 5.662441253662109e-06 gtp[x2] 0.0 gtp[a] 5.662441253662109e-06
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0002, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(5.6624e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0002, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1196, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5846551300088298
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9824, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9824, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(5.6624e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9824, device='cuda:0', dtype=torch.float16)
pa tensor(5.6624e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9824, device='cuda:0', dtype=torch.float16) acp tensor(5.7817e-06, device='cuda:0', dtype=torch.float16) r 0.8464840910223018
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9824, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29896

-------------------step: 2-------------------

x1 29929 x2 29947 a 29929
q[a] 1.0 q[x1] 1.0 q[x2] 1.0132789611816406e-05
gtp[x1] 0.103759765625 gtp[x2] 0.89599609375 gtp[a] 0.103759765625
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(5.7220e-06, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1038, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8960, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(5.7220e-06, device='cuda:0', dtype=torch.float16)
px2 tensor(0.8960, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3406, device='cuda:0', dtype=torch.float16) acp tensor(2.6309, device='cuda:0', dtype=torch.float16) r 0.1905028358650548

-------------------step: 3-------------------

directly accept a 29929

-------------------step: 1-------------------

x1 29892 x2 29889 a 29889
q[a] 0.951171875 q[x1] 0.048095703125 q[x2] 0.951171875
gtp[x1] 0.373291015625 gtp[x2] 0.17626953125 gtp[a] 0.17626953125
px1 tensor(0.3733, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0481, device='cuda:0') acp tensor(7.7614, device='cuda:0') r 0.3764707075974667

-------------------step: 2-------------------

x1 322 x2 278 a 322
q[a] 0.931640625 q[x1] 0.931640625 q[x2] 0.033416748046875
gtp[x1] 0.99853515625 gtp[x2] 3.635883331298828e-06 gtp[a] 0.99853515625
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0667, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0667, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4570, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7156747178481467
q_ai sum tensor(0.9316, device='cuda:0', dtype=torch.float16) q[a] 0.931640625
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9316, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9316, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9316, device='cuda:0', dtype=torch.float16) acp tensor(1.0723, device='cuda:0', dtype=torch.float16) r 0.0851445930699799

-------------------step: 3-------------------

x1 19700 x2 372 a 372
q[a] 0.54541015625 q[x1] 0.03076171875 q[x2] 0.54541015625
gtp[x1] 0.0073699951171875 gtp[x2] 0.244140625 gtp[a] 0.244140625
px1 tensor(0.0074, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0308, device='cuda:0') acp tensor(0.2396, device='cuda:0') r 0.19532715684074342

-------------------step: 1-------------------

x1 263 x2 385 a 263
q[a] 0.97216796875 q[x1] 0.97216796875 q[x2] 0.0267333984375
gtp[x1] 0.95751953125 gtp[x2] 0.042083740234375 gtp[a] 0.95751953125
pp sum tensor(0.9727, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9575, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0154, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0154, device='cuda:0', dtype=torch.float16) qx2 tensor(0.9351, device='cuda:0', dtype=torch.float16) acp tensor(0.0164, device='cuda:0', dtype=torch.float16) r 0.9645967004527483
q_ai sum tensor(0.9722, device='cuda:0', dtype=torch.float16) q[a] 0.97216796875
pp sum tensor(0.9575, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9570, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9575, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9570, device='cuda:0', dtype=torch.float16)
pa tensor(0.9575, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9570, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.25357513643848517

-------------------step: 2-------------------

x1 380 x2 6282 a 6282
q[a] 0.2156982421875 q[x1] 0.03631591796875 q[x2] 0.2156982421875
gtp[x1] 0.002597808837890625 gtp[x2] 3.7550926208496094e-06 gtp[a] 3.7550926208496094e-06
px1 tensor(0.0026, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0363, device='cuda:0') acp tensor(0.0715, device='cuda:0') r 0.5284455809093251
pp sum tensor(0.8755, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6592, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(3.7551e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6592, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2157, device='cuda:0', dtype=torch.float16) q[a] 0.2156982421875
pp sum tensor(0.8564, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1964, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(3.7551e-06, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1964, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6592, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.899677551588906
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8564, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 262

-------------------step: 2-------------------

directly accept a 1218

-------------------step: 3-------------------

x1 3447 x2 15839 a 15839
q[a] 0.21240234375 q[x1] 0.00948333740234375 q[x2] 0.21240234375
gtp[x1] 8.940696716308594e-07 gtp[x2] 0.002666473388671875 gtp[a] 0.002666473388671875
px1 tensor(8.9407e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0095, device='cuda:0') acp tensor(9.4278e-05, device='cuda:0') r 0.9434526945903629
pp sum tensor(0.8740, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6611, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0027, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6611, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2124, device='cuda:0', dtype=torch.float16) q[a] 0.21240234375
pp sum tensor(0.8525, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1913, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0027, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1913, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6611, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.32601230619516974
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8501, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 964 x2 472 a 964
q[a] 0.91162109375 q[x1] 0.91162109375 q[x2] 0.0592041015625
gtp[x1] 0.96728515625 gtp[x2] 0.0283203125 gtp[a] 0.96728515625
pp sum tensor(0.9697, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0584, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9673, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0584, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6108, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1810801531242514
q_ai sum tensor(0.9116, device='cuda:0', dtype=torch.float16) q[a] 0.91162109375
pp sum tensor(0.9673, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9087, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9673, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9087, device='cuda:0', dtype=torch.float16)
pa tensor(0.9673, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9087, device='cuda:0', dtype=torch.float16) acp tensor(1.0645, device='cuda:0', dtype=torch.float16) r 0.06217243175164666

-------------------step: 2-------------------

x1 278 x2 22879 a 278
q[a] 0.8349609375 q[x1] 0.8349609375 q[x2] 0.00399017333984375
gtp[x1] 0.39599609375 gtp[x2] 1.7881393432617188e-07 gtp[a] 0.39599609375
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1626, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3960, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1626, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0202, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8861362571714179
q_ai sum tensor(0.8350, device='cuda:0', dtype=torch.float16) q[a] 0.8349609375
pp sum tensor(0.9873, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8247, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.3960, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8247, device='cuda:0', dtype=torch.float16)
pa tensor(0.3960, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8247, device='cuda:0', dtype=torch.float16) acp tensor(0.4802, device='cuda:0', dtype=torch.float16) r 0.9771655162132277
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5913, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29875 x2 713 a 29875
q[a] 0.97412109375 q[x1] 0.97412109375 q[x2] 0.0255584716796875
gtp[x1] 0.8974609375 gtp[x2] 0.102294921875 gtp[a] 0.8974609375
pp sum tensor(0.9741, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0004, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8975, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0767, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0004, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0767, device='cuda:0', dtype=torch.float16) qx2 tensor(0.9561, device='cuda:0', dtype=torch.float16) acp tensor(0.0803, device='cuda:0', dtype=torch.float16) r 0.32427196858909446
q_ai sum tensor(0.9741, device='cuda:0', dtype=torch.float16) q[a] 0.97412109375
pp sum tensor(0.8975, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8975, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8975, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8975, device='cuda:0', dtype=torch.float16)
pa tensor(0.8975, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8975, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.7204590879806201

-------------------step: 2-------------------

directly accept a 29915

-------------------step: 3-------------------

directly accept a 29879

-------------------step: 1-------------------

x1 322 x2 408 a 322
q[a] 0.68994140625 q[x1] 0.68994140625 q[x2] 0.0672607421875
gtp[x1] 0.81396484375 gtp[x2] 0.0084991455078125 gtp[a] 0.81396484375
pp sum tensor(0.8149, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1251, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8140, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1251, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1497, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8382924253511009
q_ai sum tensor(0.6899, device='cuda:0', dtype=torch.float16) q[a] 0.68994140625
pp sum tensor(0.8140, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6890, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8140, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6890, device='cuda:0', dtype=torch.float16)
pa tensor(0.8140, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6890, device='cuda:0', dtype=torch.float16) acp tensor(1.1816, device='cuda:0', dtype=torch.float16) r 0.9808129208418732

-------------------step: 2-------------------

x1 278 x2 9257 a 9257
q[a] 0.2841796875 q[x1] 0.02191162109375 q[x2] 0.2841796875
gtp[x1] 0.1824951171875 gtp[x2] 0.42431640625 gtp[a] 0.42431640625
px1 tensor(0.1825, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0219, device='cuda:0') acp tensor(8.3287, device='cuda:0') r 0.4078416489691612

-------------------step: 3-------------------

x1 8261 x2 21117 a 8261
q[a] 0.454833984375 q[x1] 0.454833984375 q[x2] 0.0018157958984375
gtp[x1] 0.0003139972686767578 gtp[x2] 0.0004978179931640625 gtp[a] 0.0003139972686767578
pp sum tensor(0.9053, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4509, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0003, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4509, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0015, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7084620426254115
q_ai sum tensor(0.4548, device='cuda:0', dtype=torch.float16) q[a] 0.454833984375
pp sum tensor(0.8530, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4026, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0003, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4026, device='cuda:0', dtype=torch.float16)
pa tensor(0.0003, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4026, device='cuda:0', dtype=torch.float16) acp tensor(0.0008, device='cuda:0', dtype=torch.float16) r 0.12998389626196516
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8525, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 310

-------------------step: 2-------------------

x1 278 x2 26901 a 278
q[a] 0.76416015625 q[x1] 0.76416015625 q[x2] 0.044830322265625
gtp[x1] 0.0885009765625 gtp[x2] 0.00279998779296875 gtp[a] 0.0885009765625
pp sum tensor(0.9438, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1798, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0885, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1798, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1454, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8004521398220908
q_ai sum tensor(0.7642, device='cuda:0', dtype=torch.float16) q[a] 0.76416015625
pp sum tensor(0.7749, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5952, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0885, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5952, device='cuda:0', dtype=torch.float16)
pa tensor(0.0885, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5952, device='cuda:0', dtype=torch.float16) acp tensor(0.1487, device='cuda:0', dtype=torch.float16) r 0.7847613313969812
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6865, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 15150 x2 4642 a 4642
q[a] 0.41064453125 q[x1] 0.273681640625 q[x2] 0.41064453125
gtp[x1] 0.1578369140625 gtp[x2] 0.509765625 gtp[a] 0.509765625
px1 tensor(0.1578, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2737, device='cuda:0') acp tensor(0.5767, device='cuda:0') r 0.20276486868360977

-------------------step: 2-------------------

x1 20251 x2 24060 a 20251
q[a] 0.5703125 q[x1] 0.5703125 q[x2] 0.01406097412109375
gtp[x1] 0.0423583984375 gtp[x2] 0.01291656494140625 gtp[a] 0.0423583984375
pp sum tensor(0.8872, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3167, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0424, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3167, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0187, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7410406394947658
q_ai sum tensor(0.5703, device='cuda:0', dtype=torch.float16) q[a] 0.5703125
pp sum tensor(0.7598, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4429, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0424, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4429, device='cuda:0', dtype=torch.float16)
pa tensor(0.0424, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4429, device='cuda:0', dtype=torch.float16) acp tensor(0.0956, device='cuda:0', dtype=torch.float16) r 0.3442623542085177
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7178, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29889

-------------------step: 2-------------------

x1 739 x2 13 a 13
q[a] 0.654296875 q[x1] 0.076904296875 q[x2] 0.654296875
gtp[x1] 0.0034046173095703125 gtp[x2] 0.452880859375 gtp[a] 0.452880859375
px1 tensor(0.0034, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0769, device='cuda:0') acp tensor(0.0443, device='cuda:0') r 0.6205994914608303
pp sum tensor(0.7939, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1399, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4529, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1399, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6543, device='cuda:0', dtype=torch.float16) q[a] 0.654296875
pp sum tensor(0.7192, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5791, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4529, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5791, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1399, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8447218645620601
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.2661, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29915

-------------------step: 2-------------------

directly accept a 29873

-------------------step: 3-------------------

x1 925 x2 3052 a 3052
q[a] 0.5703125 q[x1] 0.0070648193359375 q[x2] 0.5703125
gtp[x1] 6.794929504394531e-06 gtp[x2] 0.7880859375 gtp[a] 0.7880859375
px1 tensor(6.7949e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0071, device='cuda:0') acp tensor(0.0010, device='cuda:0') r 0.24564911256743938
pp sum tensor(0.7886, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2183, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7881, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2183, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5703, device='cuda:0', dtype=torch.float16) q[a] 0.5703125
pp sum tensor(0.7881, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5698, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7881, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5698, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2183, device='cuda:0', dtype=torch.float16)
pa tensor(0.2183, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2183, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.7724388183537642

-------------------step: 1-------------------

x1 15130 x2 8825 a 8825
q[a] 0.62744140625 q[x1] 0.2152099609375 q[x2] 0.62744140625
gtp[x1] 0.36279296875 gtp[x2] 0.36572265625 gtp[a] 0.36572265625
px1 tensor(0.3628, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2152, device='cuda:0') acp tensor(1.6858, device='cuda:0') r 0.6206158391419744

-------------------step: 2-------------------

directly accept a 304

-------------------step: 3-------------------

x1 1074 x2 6493 a 6493
q[a] 0.282958984375 q[x1] 0.1217041015625 q[x2] 0.282958984375
gtp[x1] 0.02764892578125 gtp[x2] 0.004657745361328125 gtp[a] 0.004657745361328125
px1 tensor(0.0276, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1217, device='cuda:0') acp tensor(0.2272, device='cuda:0') r 0.6564953845863039
pp sum tensor(0.7637, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4810, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0047, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4810, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2830, device='cuda:0', dtype=torch.float16) q[a] 0.282958984375
pp sum tensor(0.6958, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2152, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0047, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2152, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4810, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7503476054627146
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6914, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 263 x2 297 a 263
q[a] 0.96240234375 q[x1] 0.96240234375 q[x2] 0.0277252197265625
gtp[x1] 0.998046875 gtp[x2] 4.750490188598633e-05 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0360, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0360, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7065, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9045178921009696
q_ai sum tensor(0.9619, device='cuda:0', dtype=torch.float16) q[a] 0.96240234375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9619, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9619, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9619, device='cuda:0', dtype=torch.float16) acp tensor(1.0371, device='cuda:0', dtype=torch.float16) r 0.18979508768142728

-------------------step: 2-------------------

x1 6282 x2 2078 a 6282
q[a] 0.9091796875 q[x1] 0.9091796875 q[x2] 0.0003402233123779297
gtp[x1] 0.1915283203125 gtp[x2] 4.172325134277344e-07 gtp[a] 0.1915283203125
pp sum tensor(0.9644, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0554, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1915, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0554, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0034, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5331304393109422
q_ai sum tensor(0.9092, device='cuda:0', dtype=torch.float16) q[a] 0.9091796875
pp sum tensor(0.6216, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5664, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1915, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5664, device='cuda:0', dtype=torch.float16)
pa tensor(0.1915, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5664, device='cuda:0', dtype=torch.float16) acp tensor(0.3381, device='cuda:0', dtype=torch.float16) r 0.12545955228688765

-------------------step: 3-------------------

x1 310 x2 304 a 310
q[a] 0.970703125 q[x1] 0.970703125 q[x2] 0.014739990234375
gtp[x1] 0.93896484375 gtp[x2] 0.00028228759765625 gtp[a] 0.93896484375
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0256, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9390, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0256, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4878, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.43014820292686984
q_ai sum tensor(0.9707, device='cuda:0', dtype=torch.float16) q[a] 0.970703125
pp sum tensor(0.9414, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9155, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9390, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9155, device='cuda:0', dtype=torch.float16)
pa tensor(0.9390, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9155, device='cuda:0', dtype=torch.float16) acp tensor(1.0254, device='cuda:0', dtype=torch.float16) r 0.38671969357638325

-------------------step: 1-------------------

x1 24369 x2 15150 a 24369
q[a] 0.59326171875 q[x1] 0.59326171875 q[x2] 0.04229736328125
gtp[x1] 0.99609375 gtp[x2] 0.00010597705841064453 gtp[a] 0.99609375
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4028, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4028, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0617, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9919531891622422
q_ai sum tensor(0.5933, device='cuda:0', dtype=torch.float16) q[a] 0.59326171875
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5933, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5933, device='cuda:0', dtype=torch.float16)
pa tensor(0.9961, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5933, device='cuda:0', dtype=torch.float16) acp tensor(1.6787, device='cuda:0', dtype=torch.float16) r 0.1654386684600282

-------------------step: 2-------------------

x1 29892 x2 322 a 322
q[a] 0.71240234375 q[x1] 0.258056640625 q[x2] 0.71240234375
gtp[x1] 0.2252197265625 gtp[x2] 0.76220703125 gtp[a] 0.76220703125
px1 tensor(0.2252, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2581, device='cuda:0') acp tensor(0.8728, device='cuda:0') r 0.09342110884641541

-------------------step: 3-------------------

x1 322 x2 3704 a 322
q[a] 0.453369140625 q[x1] 0.453369140625 q[x2] 0.046295166015625
gtp[x1] 0.0484619140625 gtp[x2] 0.00855255126953125 gtp[a] 0.0484619140625
pp sum tensor(0.6426, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1895, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0485, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1895, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0384, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3778924053746199
q_ai sum tensor(0.4534, device='cuda:0', dtype=torch.float16) q[a] 0.453369140625
pp sum tensor(0.4082, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2189, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0485, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2189, device='cuda:0', dtype=torch.float16)
pa tensor(0.0485, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2189, device='cuda:0', dtype=torch.float16) acp tensor(0.2214, device='cuda:0', dtype=torch.float16) r 0.053736383801046506

-------------------step: 1-------------------

x1 1048 x2 901 a 1048
q[a] 0.98974609375 q[x1] 0.98974609375 q[x2] 0.0068817138671875
gtp[x1] 0.94677734375 gtp[x2] 0.004741668701171875 gtp[a] 0.94677734375
pp sum tensor(0.9932, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0036, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9468, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0036, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6650, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.18229949928637346
q_ai sum tensor(0.9897, device='cuda:0', dtype=torch.float16) q[a] 0.98974609375
pp sum tensor(0.9473, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9438, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9468, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9438, device='cuda:0', dtype=torch.float16)
pa tensor(0.9468, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9438, device='cuda:0', dtype=torch.float16) acp tensor(1.0029, device='cuda:0', dtype=torch.float16) r 0.01653940477560989

-------------------step: 2-------------------

x1 278 x2 967 a 278
q[a] 0.97705078125 q[x1] 0.97705078125 q[x2] 0.011199951171875
gtp[x1] 0.70068359375 gtp[x2] 0.296630859375 gtp[a] 0.70068359375
pp sum tensor(0.9868, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0096, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7007, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2854, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0096, device='cuda:0', dtype=torch.float16)
px2 tensor(0.2854, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4810, device='cuda:0', dtype=torch.float16) acp tensor(0.5933, device='cuda:0', dtype=torch.float16) r 0.6418432636340718
q_ai sum tensor(0.9771, device='cuda:0', dtype=torch.float16) q[a] 0.97705078125
pp sum tensor(0.7007, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6909, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7007, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6909, device='cuda:0', dtype=torch.float16)
pa tensor(0.7007, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6909, device='cuda:0', dtype=torch.float16) acp tensor(1.0137, device='cuda:0', dtype=torch.float16) r 0.98965045603715

-------------------step: 3-------------------

x1 2106 x2 8261 a 8261
q[a] 0.26806640625 q[x1] 0.00522613525390625 q[x2] 0.26806640625
gtp[x1] 0.0022563934326171875 gtp[x2] 0.334716796875 gtp[a] 0.334716796875
px1 tensor(0.0023, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0052, device='cuda:0') acp tensor(0.4318, device='cuda:0') r 0.4215829254915301

-------------------step: 1-------------------

directly accept a 29879

-------------------step: 2-------------------

x1 8261 x2 20844 a 8261
q[a] 0.76806640625 q[x1] 0.76806640625 q[x2] 0.00021183490753173828
gtp[x1] 0.71044921875 gtp[x2] 3.2186508178710938e-06 gtp[a] 0.71044921875
pp sum tensor(0.9268, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1588, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7104, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1588, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0007, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5304256177713325
q_ai sum tensor(0.7681, device='cuda:0', dtype=torch.float16) q[a] 0.76806640625
pp sum tensor(0.8721, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7134, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7104, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7134, device='cuda:0', dtype=torch.float16)
pa tensor(0.7104, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7134, device='cuda:0', dtype=torch.float16) acp tensor(0.9961, device='cuda:0', dtype=torch.float16) r 0.00023440671552543701

-------------------step: 3-------------------

x1 4955 x2 902 a 4955
q[a] 0.994140625 q[x1] 0.994140625 q[x2] 0.0027065277099609375
gtp[x1] 0.41259765625 gtp[x2] 0.01116943359375 gtp[a] 0.41259765625
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0002, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4126, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0085, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0002, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0085, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4436, device='cuda:0', dtype=torch.float16) acp tensor(0.0191, device='cuda:0', dtype=torch.float16) r 0.5440154121820721
q_ai sum tensor(0.9941, device='cuda:0', dtype=torch.float16) q[a] 0.994140625
pp sum tensor(0.7856, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7852, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4126, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7852, device='cuda:0', dtype=torch.float16)
pa tensor(0.4126, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7852, device='cuda:0', dtype=torch.float16) acp tensor(0.5254, device='cuda:0', dtype=torch.float16) r 0.6150055743743359
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3730, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 322 x2 408 a 322
q[a] 0.8505859375 q[x1] 0.8505859375 q[x2] 0.014190673828125
gtp[x1] 0.0750732421875 gtp[x2] 0.00018906593322753906 gtp[a] 0.0750732421875
pp sum tensor(0.8921, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0417, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0751, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0417, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0810, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.945679905523996
q_ai sum tensor(0.8506, device='cuda:0', dtype=torch.float16) q[a] 0.8505859375
pp sum tensor(0.3196, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2778, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0751, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2778, device='cuda:0', dtype=torch.float16)
pa tensor(0.0751, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2778, device='cuda:0', dtype=torch.float16) acp tensor(0.2703, device='cuda:0', dtype=torch.float16) r 0.8052822312449633
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.2444, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 278 x2 3082 a 278
q[a] 0.88232421875 q[x1] 0.88232421875 q[x2] 0.00013446807861328125
gtp[x1] 0.01439666748046875 gtp[x2] 5.960464477539063e-08 gtp[a] 0.01439666748046875
pp sum tensor(0.9922, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1099, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0144, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1099, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0010, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.895751638112201
q_ai sum tensor(0.8823, device='cuda:0', dtype=torch.float16) q[a] 0.88232421875
pp sum tensor(0.9858, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8760, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0144, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8760, device='cuda:0', dtype=torch.float16)
pa tensor(0.0144, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8760, device='cuda:0', dtype=torch.float16) acp tensor(0.0164, device='cuda:0', dtype=torch.float16) r 0.6095877459530459
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9717, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 519

-------------------step: 2-------------------

x1 322 x2 1410 a 1410
q[a] 0.45458984375 q[x1] 0.327392578125 q[x2] 0.45458984375
gtp[x1] 0.14111328125 gtp[x2] 0.837890625 gtp[a] 0.837890625
px1 tensor(0.1411, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3274, device='cuda:0') acp tensor(0.4310, device='cuda:0') r 0.17874342641331842

-------------------step: 3-------------------

x1 7134 x2 1871 a 7134
q[a] 0.46484375 q[x1] 0.46484375 q[x2] 0.053802490234375
gtp[x1] 2.485513687133789e-05 gtp[x2] 0.00041675567626953125 gtp[a] 2.485513687133789e-05
pp sum tensor(0.7646, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2993, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(2.4855e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2993, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0467, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6181608698177858
q_ai sum tensor(0.4648, device='cuda:0', dtype=torch.float16) q[a] 0.46484375
pp sum tensor(0.5850, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2854, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(2.4855e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2854, device='cuda:0', dtype=torch.float16)
pa tensor(2.4855e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2854, device='cuda:0', dtype=torch.float16) acp tensor(8.7082e-05, device='cuda:0', dtype=torch.float16) r 0.031090180260174738
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5850, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 403

-------------------step: 2-------------------

x1 1410 x2 6282 a 1410
q[a] 0.923828125 q[x1] 0.923828125 q[x2] 0.04058837890625
gtp[x1] 0.9794921875 gtp[x2] 0.0119476318359375 gtp[a] 0.9794921875
pp sum tensor(0.9844, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0604, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9795, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0604, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4917, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5195746430325047
q_ai sum tensor(0.9238, device='cuda:0', dtype=torch.float16) q[a] 0.923828125
pp sum tensor(0.9795, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9189, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9795, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9189, device='cuda:0', dtype=torch.float16)
pa tensor(0.9795, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9189, device='cuda:0', dtype=torch.float16) acp tensor(1.0654, device='cuda:0', dtype=torch.float16) r 0.23496880554661748

-------------------step: 3-------------------

directly accept a 2247

-------------------step: 1-------------------

x1 13 x2 450 a 13
q[a] 0.998046875 q[x1] 0.998046875 q[x2] 0.00023365020751953125
gtp[x1] 0.99853515625 gtp[x2] 8.606910705566406e-05 gtp[a] 0.99853515625
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0011, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0011, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1070, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9178704139972975
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16) q[a] 0.998046875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9980, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.5476502437535529

-------------------step: 2-------------------

directly accept a 13

-------------------step: 3-------------------

x1 855 x2 2744 a 2744
q[a] 0.26123046875 q[x1] 0.0009565353393554688 q[x2] 0.26123046875
gtp[x1] 4.953145980834961e-05 gtp[x2] 0.3408203125 gtp[a] 0.3408203125
px1 tensor(4.9531e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0010, device='cuda:0') acp tensor(0.0518, device='cuda:0') r 0.28490234022982086
pp sum tensor(0.7749, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5137, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3408, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5137, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2612, device='cuda:0', dtype=torch.float16) q[a] 0.26123046875
pp sum tensor(0.7432, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2296, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3408, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2296, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1112, device='cuda:0', dtype=torch.float16)
pa tensor(0.1112, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5137, device='cuda:0', dtype=torch.float16) acp tensor(0.2166, device='cuda:0', dtype=torch.float16) r 0.27507235280052167
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.4023, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 1790 x2 565 a 565
q[a] 0.1380615234375 q[x1] 0.005786895751953125 q[x2] 0.1380615234375
gtp[x1] 8.106231689453125e-06 gtp[x2] 0.021270751953125 gtp[a] 0.021270751953125
px1 tensor(8.1062e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0058, device='cuda:0') acp tensor(0.0014, device='cuda:0') r 0.7585389202895345
pp sum tensor(0.6958, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5581, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0213, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5581, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1379, device='cuda:0', dtype=torch.float16) q[a] 0.1380615234375
pp sum tensor(0.6602, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1024, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0213, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1024, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5581, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8998444898597634
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6387, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29875 x2 2 a 29875
q[a] 1.0 q[x1] 1.0 q[x2] 3.516674041748047e-06
gtp[x1] 0.9990234375 gtp[x2] 7.152557373046875e-06 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(3.5763e-07, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(3.6359e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(3.5763e-07, device='cuda:0', dtype=torch.float16)
px2 tensor(3.6359e-06, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1705, device='cuda:0', dtype=torch.float16) acp tensor(2.1338e-05, device='cuda:0', dtype=torch.float16) r 0.34846929922778114
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9990, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.375559034079031

-------------------step: 2-------------------

x1 3508 x2 29915 a 29915
q[a] 0.65478515625 q[x1] 0.10357666015625 q[x2] 0.65478515625
gtp[x1] 0.420166015625 gtp[x2] 0.05096435546875 gtp[a] 0.05096435546875
px1 tensor(0.4202, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1036, device='cuda:0') acp tensor(4.0566, device='cuda:0') r 0.9466492331783085

-------------------step: 3-------------------

directly accept a 29915

-------------------step: 1-------------------

x1 599 x2 925 a 925
q[a] 0.591796875 q[x1] 0.331787109375 q[x2] 0.591796875
gtp[x1] 0.330322265625 gtp[x2] 0.6669921875 gtp[a] 0.6669921875
px1 tensor(0.3303, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3318, device='cuda:0') acp tensor(0.9956, device='cuda:0') r 0.746754950066343

-------------------step: 2-------------------

x1 1048 x2 2712 a 1048
q[a] 0.9345703125 q[x1] 0.9345703125 q[x2] 0.0004930496215820312
gtp[x1] 0.7197265625 gtp[x2] 4.76837158203125e-07 gtp[a] 0.7197265625
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0616, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7197, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0616, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0070, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7172399529891066
q_ai sum tensor(0.9346, device='cuda:0', dtype=torch.float16) q[a] 0.9345703125
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9321, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7197, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9321, device='cuda:0', dtype=torch.float16)
pa tensor(0.7197, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9321, device='cuda:0', dtype=torch.float16) acp tensor(0.7720, device='cuda:0', dtype=torch.float16) r 0.8562297195845368
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.2744, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29892 x2 322 a 322
q[a] 0.9140625 q[x1] 0.057525634765625 q[x2] 0.9140625
gtp[x1] 0.0004649162292480469 gtp[x2] 0.998046875 gtp[a] 0.998046875
px1 tensor(0.0005, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0575, device='cuda:0') acp tensor(0.0081, device='cuda:0') r 0.4406501061543553
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0845, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9980, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0845, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9141, device='cuda:0', dtype=torch.float16) q[a] 0.9140625
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9141, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9980, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9141, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0840, device='cuda:0', dtype=torch.float16)
pa tensor(0.0840, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.0845, device='cuda:0', dtype=torch.float16) acp tensor(0.9937, device='cuda:0', dtype=torch.float16) r 0.7165098562793395

-------------------step: 2-------------------

x1 9257 x2 22586 a 9257
q[a] 0.316650390625 q[x1] 0.316650390625 q[x2] 0.0208892822265625
gtp[x1] 0.16552734375 gtp[x2] 0.08856201171875 gtp[a] 0.16552734375
pp sum tensor(0.8887, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5718, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1655, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0677, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5718, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0677, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0097, device='cuda:0', dtype=torch.float16) acp tensor(6.9961, device='cuda:0', dtype=torch.float16) r 0.8373489555284461

-------------------step: 3-------------------

x1 29892 x2 448 a 29892
q[a] 0.85107421875 q[x1] 0.85107421875 q[x2] 0.1016845703125
gtp[x1] 0.12017822265625 gtp[x2] 0.2176513671875 gtp[a] 0.12017822265625
pp sum tensor(0.8521, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0012, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1202, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1160, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0012, device='cuda:0', dtype=torch.float16)
px2 tensor(0.1160, device='cuda:0', dtype=torch.float16) qx2 tensor(0.5815, device='cuda:0', dtype=torch.float16) acp tensor(0.1995, device='cuda:0', dtype=torch.float16) r 0.45088769805325835
q_ai sum tensor(0.8511, device='cuda:0', dtype=torch.float16) q[a] 0.85107421875
pp sum tensor(0.4893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4880, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1202, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4880, device='cuda:0', dtype=torch.float16)
pa tensor(0.1202, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4880, device='cuda:0', dtype=torch.float16) acp tensor(0.2462, device='cuda:0', dtype=torch.float16) r 0.7508634294791291
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3691, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 450 x2 1670 a 1670
q[a] 0.350830078125 q[x1] 0.244873046875 q[x2] 0.350830078125
gtp[x1] 0.5693359375 gtp[x2] 0.1053466796875 gtp[a] 0.1053466796875
px1 tensor(0.5693, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2449, device='cuda:0') acp tensor(2.3250, device='cuda:0') r 0.7472783289125257

-------------------step: 2-------------------

x1 9560 x2 26901 a 26901
q[a] 0.3779296875 q[x1] 0.0401611328125 q[x2] 0.3779296875
gtp[x1] 0.0024547576904296875 gtp[x2] 0.00417327880859375 gtp[a] 0.00417327880859375
px1 tensor(0.0025, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0402, device='cuda:0') acp tensor(0.0611, device='cuda:0') r 0.1928432205351649
pp sum tensor(0.9258, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5483, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0042, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5483, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3779, device='cuda:0', dtype=torch.float16) q[a] 0.3779296875
pp sum tensor(0.8867, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3386, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0042, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3386, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5483, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8717682736524316
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8823, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 3528 x2 29915 a 29915
q[a] 0.521484375 q[x1] 0.03204345703125 q[x2] 0.521484375
gtp[x1] 0.0005426406860351562 gtp[x2] 0.220703125 gtp[a] 0.220703125
px1 tensor(0.0005, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0320, device='cuda:0') acp tensor(0.0169, device='cuda:0') r 0.6079721724080689
pp sum tensor(0.6421, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1210, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2207, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1210, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5215, device='cuda:0', dtype=torch.float16) q[a] 0.521484375
pp sum tensor(0.3120, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1915, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2207, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1915, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0292, device='cuda:0', dtype=torch.float16)
pa tensor(0.0292, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1210, device='cuda:0', dtype=torch.float16) acp tensor(0.2412, device='cuda:0', dtype=torch.float16) r 0.1216064537295305

-------------------step: 2-------------------

directly accept a 29879

-------------------step: 3-------------------

x1 5613 x2 26901 a 5613
q[a] 0.498046875 q[x1] 0.498046875 q[x2] 0.00978851318359375
gtp[x1] 0.407958984375 gtp[x2] 3.981590270996094e-05 gtp[a] 0.407958984375
pp sum tensor(0.6699, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1715, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4080, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1715, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0097, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5285236945741917
q_ai sum tensor(0.4980, device='cuda:0', dtype=torch.float16) q[a] 0.498046875
pp sum tensor(0.5322, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3606, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4080, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3606, device='cuda:0', dtype=torch.float16)
pa tensor(0.4080, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3606, device='cuda:0', dtype=torch.float16) acp tensor(1.1309, device='cuda:0', dtype=torch.float16) r 0.5806113375921326

-------------------step: 1-------------------

x1 338 x2 29892 a 338
q[a] 0.97412109375 q[x1] 0.97412109375 q[x2] 0.0079193115234375
gtp[x1] 0.97509765625 gtp[x2] 0.0002980232238769531 gtp[a] 0.97509765625
pp sum tensor(0.9893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0150, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9751, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0150, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3008, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5735542638658994
q_ai sum tensor(0.9741, device='cuda:0', dtype=torch.float16) q[a] 0.97412109375
pp sum tensor(0.9771, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9619, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9751, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9619, device='cuda:0', dtype=torch.float16)
pa tensor(0.9751, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9619, device='cuda:0', dtype=torch.float16) acp tensor(1.0137, device='cuda:0', dtype=torch.float16) r 0.8500967740491683

-------------------step: 2-------------------

x1 925 x2 263 a 263
q[a] 0.5234375 q[x1] 0.1622314453125 q[x2] 0.5234375
gtp[x1] 0.0030269622802734375 gtp[x2] 0.0172882080078125 gtp[a] 0.0172882080078125
px1 tensor(0.0030, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1622, device='cuda:0') acp tensor(0.0187, device='cuda:0') r 0.21575596764314553
pp sum tensor(0.8022, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2788, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0173, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2788, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5234, device='cuda:0', dtype=torch.float16) q[a] 0.5234375
pp sum tensor(0.7251, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4465, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0173, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4465, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2788, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.27603824401055577
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7080, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 380 x2 2078 a 2078
q[a] 0.413330078125 q[x1] 0.07012939453125 q[x2] 0.413330078125
gtp[x1] 0.348388671875 gtp[x2] 0.60205078125 gtp[a] 0.60205078125
px1 tensor(0.3484, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0701, device='cuda:0') acp tensor(4.9678, device='cuda:0') r 0.46157828169904713

-------------------step: 2-------------------

x1 27389 x2 348 a 27389
q[a] 0.9990234375 q[x1] 0.9990234375 q[x2] 0.00017249584197998047
gtp[x1] 0.98974609375 gtp[x2] 9.5367431640625e-07 gtp[a] 0.98974609375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0005, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9897, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0005, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1549, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6145479593182863
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16) q[a] 0.9990234375
pp sum tensor(0.9897, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9897, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9897, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9897, device='cuda:0', dtype=torch.float16)
pa tensor(0.9897, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9897, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.4487554905625809

-------------------step: 3-------------------

x1 29889 x2 29892 a 29889
q[a] 0.794921875 q[x1] 0.794921875 q[x2] 0.1339111328125
gtp[x1] 0.34814453125 gtp[x2] 0.650390625 gtp[a] 0.34814453125
pp sum tensor(0.8647, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0696, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3481, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5166, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0696, device='cuda:0', dtype=torch.float16)
px2 tensor(0.5166, device='cuda:0', dtype=torch.float16) qx2 tensor(0.5195, device='cuda:0', dtype=torch.float16) acp tensor(0.9941, device='cuda:0', dtype=torch.float16) r 0.28394966420889856

-------------------step: 1-------------------

x1 17202 x2 2078 a 2078
q[a] 0.1451416015625 q[x1] 0.00042700767517089844 q[x2] 0.1451416015625
gtp[x1] 3.802776336669922e-05 gtp[x2] 0.0838623046875 gtp[a] 0.0838623046875
px1 tensor(3.8028e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0004, device='cuda:0') acp tensor(0.0891, device='cuda:0') r 0.9164020657543582
pp sum tensor(0.6655, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5205, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0839, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5205, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1451, device='cuda:0', dtype=torch.float16) q[a] 0.1451416015625
pp sum tensor(0.6406, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1203, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0839, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1203, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5205, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4183945767126501
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5571, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 310 x2 270 a 310
q[a] 0.546875 q[x1] 0.546875 q[x2] 0.01265716552734375
gtp[x1] 0.857421875 gtp[x2] 0.0 gtp[a] 0.857421875
pp sum tensor(0.9834, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4368, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8574, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4368, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0153, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.012708996482871715
q_ai sum tensor(0.5469, device='cuda:0', dtype=torch.float16) q[a] 0.546875
pp sum tensor(0.9658, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5288, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8574, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5288, device='cuda:0', dtype=torch.float16)
pa tensor(0.8574, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5288, device='cuda:0', dtype=torch.float16) acp tensor(1.6211, device='cuda:0', dtype=torch.float16) r 0.9882298922573968

-------------------step: 2-------------------

x1 10901 x2 367 a 10901
q[a] 0.426513671875 q[x1] 0.426513671875 q[x2] 0.1290283203125
gtp[x1] 0.002269744873046875 gtp[x2] 0.0037708282470703125 gtp[a] 0.002269744873046875
pp sum tensor(0.8286, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4016, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0023, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4016, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0960, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9118204472275224
q_ai sum tensor(0.4265, device='cuda:0', dtype=torch.float16) q[a] 0.426513671875
pp sum tensor(0.7749, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3723, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0023, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3723, device='cuda:0', dtype=torch.float16)
pa tensor(0.0023, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3723, device='cuda:0', dtype=torch.float16) acp tensor(0.0061, device='cuda:0', dtype=torch.float16) r 0.20244031388243533
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7725, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 391

-------------------step: 2-------------------

directly accept a 457

-------------------step: 3-------------------

x1 367 x2 11982 a 367
q[a] 0.83056640625 q[x1] 0.83056640625 q[x2] 0.09033203125
gtp[x1] 0.89453125 gtp[x2] 0.032073974609375 gtp[a] 0.89453125
pp sum tensor(0.9082, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0775, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8945, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0775, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4424, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.05784432243612425
q_ai sum tensor(0.8306, device='cuda:0', dtype=torch.float16) q[a] 0.83056640625
pp sum tensor(0.8945, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8169, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8945, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8169, device='cuda:0', dtype=torch.float16)
pa tensor(0.8945, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8169, device='cuda:0', dtype=torch.float16) acp tensor(1.0947, device='cuda:0', dtype=torch.float16) r 0.6619704187113998

-------------------step: 1-------------------

x1 322 x2 29892 a 322
q[a] 0.86083984375 q[x1] 0.86083984375 q[x2] 0.1060791015625
gtp[x1] 0.437744140625 gtp[x2] 0.55322265625 gtp[a] 0.437744140625
pp sum tensor(0.8862, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0250, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4377, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4473, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0250, device='cuda:0', dtype=torch.float16)
px2 tensor(0.4473, device='cuda:0', dtype=torch.float16) qx2 tensor(0.6567, device='cuda:0', dtype=torch.float16) acp tensor(0.6812, device='cuda:0', dtype=torch.float16) r 0.5523914973127734

-------------------step: 2-------------------

x1 11982 x2 10901 a 11982
q[a] 0.31689453125 q[x1] 0.31689453125 q[x2] 0.1998291015625
gtp[x1] 3.039836883544922e-06 gtp[x2] 0.2010498046875 gtp[a] 3.039836883544922e-06
pp sum tensor(0.7163, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3992, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(3.0398e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0012, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3992, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0012, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0927, device='cuda:0', dtype=torch.float16) acp tensor(0.0132, device='cuda:0', dtype=torch.float16) r 0.5376477259501151
q_ai sum tensor(0.3169, device='cuda:0', dtype=torch.float16) q[a] 0.31689453125
pp sum tensor(0.6938, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2944, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(3.0398e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2944, device='cuda:0', dtype=torch.float16)
pa tensor(3.0398e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2944, device='cuda:0', dtype=torch.float16) acp tensor(1.0312e-05, device='cuda:0', dtype=torch.float16) r 0.5905233283767212
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6938, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 1878

-------------------step: 2-------------------

x1 17251 x2 4094 a 4094
q[a] 0.30029296875 q[x1] 0.27783203125 q[x2] 0.30029296875
gtp[x1] 0.71875 gtp[x2] 0.0007090568542480469 gtp[a] 0.0007090568542480469
px1 tensor(0.7188, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2778, device='cuda:0') acp tensor(2.5870, device='cuda:0') r 0.5193043824629906

-------------------step: 3-------------------

x1 4235 x2 1454 a 1454
q[a] 0.75048828125 q[x1] 0.002140045166015625 q[x2] 0.75048828125
gtp[x1] 0.0 gtp[x2] 0.9990234375 gtp[a] 0.9990234375
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0021, device='cuda:0') acp tensor(0., device='cuda:0') r 0.20770172569270817
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2489, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2489, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7505, device='cuda:0', dtype=torch.float16) q[a] 0.75048828125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7505, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7505, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2485, device='cuda:0', dtype=torch.float16)
pa tensor(0.2485, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2489, device='cuda:0', dtype=torch.float16) acp tensor(0.9985, device='cuda:0', dtype=torch.float16) r 0.33167823771318994

-------------------step: 1-------------------

x1 29892 x2 322 a 29892
q[a] 0.97265625 q[x1] 0.97265625 q[x2] 0.02716064453125
gtp[x1] 0.986328125 gtp[x2] 0.013214111328125 gtp[a] 0.986328125
pp sum tensor(0.9868, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0141, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0141, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9658, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5043085621745033
q_ai sum tensor(0.9722, device='cuda:0', dtype=torch.float16) q[a] 0.97265625
pp sum tensor(0.9868, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9722, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9722, device='cuda:0', dtype=torch.float16)
pa tensor(0.9863, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9722, device='cuda:0', dtype=torch.float16) acp tensor(1.0146, device='cuda:0', dtype=torch.float16) r 0.30687796781632537

-------------------step: 2-------------------

x1 322 x2 10901 a 322
q[a] 1.0 q[x1] 1.0 q[x2] 3.170967102050781e-05
gtp[x1] 0.9990234375 gtp[x2] 2.6881694793701172e-05 gtp[a] 0.9990234375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(1.6212e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(1.6212e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4453, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9316803736968952
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9995, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9995, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9995, device='cuda:0', dtype=torch.float16) acp tensor(0.9995, device='cuda:0', dtype=torch.float16) r 0.2693287432586907

-------------------step: 3-------------------

x1 19372 x2 10901 a 10901
q[a] 0.491943359375 q[x1] 0.02301025390625 q[x2] 0.491943359375
gtp[x1] 0.39794921875 gtp[x2] 0.10711669921875 gtp[a] 0.10711669921875
px1 tensor(0.3979, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0230, device='cuda:0') acp tensor(17.2944, device='cuda:0') r 0.854874239501155

-------------------step: 1-------------------

x1 1700 x2 4094 a 1700
q[a] 0.5224609375 q[x1] 0.5224609375 q[x2] 0.169677734375
gtp[x1] 0.6953125 gtp[x2] 0.2724609375 gtp[a] 0.6953125
pp sum tensor(0.7983, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2756, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6953, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1028, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2756, device='cuda:0', dtype=torch.float16)
px2 tensor(0.1028, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1857, device='cuda:0', dtype=torch.float16) acp tensor(0.5537, device='cuda:0', dtype=torch.float16) r 0.44514805190009665

-------------------step: 2-------------------

directly accept a 12559

-------------------step: 3-------------------

x1 29889 x2 29892 a 29889
q[a] 0.91796875 q[x1] 0.91796875 q[x2] 0.0098876953125
gtp[x1] 0.9599609375 gtp[x2] 0.0006504058837890625 gtp[a] 0.9599609375
pp sum tensor(0.9756, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0571, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9600, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0571, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1110, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7034599625231587
q_ai sum tensor(0.9180, device='cuda:0', dtype=torch.float16) q[a] 0.91796875
pp sum tensor(0.9702, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9131, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9600, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9131, device='cuda:0', dtype=torch.float16)
pa tensor(0.9600, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9131, device='cuda:0', dtype=torch.float16) acp tensor(1.0518, device='cuda:0', dtype=torch.float16) r 0.4821142695965973

-------------------step: 1-------------------

x1 310 x2 1818 a 310
q[a] 0.970703125 q[x1] 0.970703125 q[x2] 0.01070404052734375
gtp[x1] 0.97900390625 gtp[x2] 0.01251983642578125 gtp[a] 0.97900390625
pp sum tensor(0.9839, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0131, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9790, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0018, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0131, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0018, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3562, device='cuda:0', dtype=torch.float16) acp tensor(0.0051, device='cuda:0', dtype=torch.float16) r 0.09387540839206865
q_ai sum tensor(0.9707, device='cuda:0', dtype=torch.float16) q[a] 0.970703125
pp sum tensor(0.9805, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9678, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9790, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9678, device='cuda:0', dtype=torch.float16)
pa tensor(0.9790, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9678, device='cuda:0', dtype=torch.float16) acp tensor(1.0117, device='cuda:0', dtype=torch.float16) r 0.03969515371087118

-------------------step: 2-------------------

x1 278 x2 590 a 278
q[a] 0.982421875 q[x1] 0.982421875 q[x2] 0.01690673828125
gtp[x1] 0.7548828125 gtp[x2] 0.2449951171875 gtp[a] 0.7548828125
pp sum tensor(0.9829, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0006, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7549, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2280, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0006, device='cuda:0', dtype=torch.float16)
px2 tensor(0.2280, device='cuda:0', dtype=torch.float16) qx2 tensor(0.9463, device='cuda:0', dtype=torch.float16) acp tensor(0.2410, device='cuda:0', dtype=torch.float16) r 0.967865421647874
q_ai sum tensor(0.9824, device='cuda:0', dtype=torch.float16) q[a] 0.982421875
pp sum tensor(0.7549, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7544, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7549, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7544, device='cuda:0', dtype=torch.float16)
pa tensor(0.7549, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7544, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.20242520605816716

-------------------step: 3-------------------

x1 1556 x2 2246 a 1556
q[a] 0.939453125 q[x1] 0.939453125 q[x2] 0.0224456787109375
gtp[x1] 0.33447265625 gtp[x2] 0.2646484375 gtp[a] 0.33447265625
pp sum tensor(0.9443, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0049, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3345, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2422, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0049, device='cuda:0', dtype=torch.float16)
px2 tensor(0.2422, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3486, device='cuda:0', dtype=torch.float16) acp tensor(0.6948, device='cuda:0', dtype=torch.float16) r 0.28078678257304046

-------------------step: 1-------------------

directly accept a 14520

-------------------step: 2-------------------

x1 373 x2 297 a 297
q[a] 0.322265625 q[x1] 0.29345703125 q[x2] 0.322265625
gtp[x1] 0.00971221923828125 gtp[x2] 0.07635498046875 gtp[a] 0.07635498046875
px1 tensor(0.0097, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2935, device='cuda:0') acp tensor(0.0331, device='cuda:0') r 0.7723969221431556
pp sum tensor(0.7705, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4480, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0764, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4480, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3223, device='cuda:0', dtype=torch.float16) q[a] 0.322265625
pp sum tensor(0.6714, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2231, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0764, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2231, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4480, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.43309909079721143
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5947, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 6493 x2 1423 a 6493
q[a] 0.982421875 q[x1] 0.982421875 q[x2] 0.0016870498657226562
gtp[x1] 0.97998046875 gtp[x2] 0.0135498046875 gtp[a] 0.97998046875
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0114, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9800, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0119, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0114, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0119, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0955, device='cuda:0', dtype=torch.float16) acp tensor(0.1243, device='cuda:0', dtype=torch.float16) r 0.7899799887760999
q_ai sum tensor(0.9824, device='cuda:0', dtype=torch.float16) q[a] 0.982421875
pp sum tensor(0.9810, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9697, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9800, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9697, device='cuda:0', dtype=torch.float16)
pa tensor(0.9800, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9697, device='cuda:0', dtype=torch.float16) acp tensor(1.0107, device='cuda:0', dtype=torch.float16) r 0.36861390997215404

-------------------step: 2-------------------

x1 338 x2 297 a 338
q[a] 0.791015625 q[x1] 0.791015625 q[x2] 0.03997802734375
gtp[x1] 0.85791015625 gtp[x2] 0.1357421875 gtp[a] 0.85791015625
pp sum tensor(0.9551, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1644, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8579, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0958, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1644, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0958, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1514, device='cuda:0', dtype=torch.float16) acp tensor(0.6328, device='cuda:0', dtype=torch.float16) r 0.31787705515636666

-------------------step: 3-------------------

x1 22552 x2 26901 a 26901
q[a] 0.82275390625 q[x1] 0.0023651123046875 q[x2] 0.82275390625
gtp[x1] 5.91278076171875e-05 gtp[x2] 0.9990234375 gtp[a] 0.9990234375
px1 tensor(5.9128e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0024, device='cuda:0') acp tensor(0.0250, device='cuda:0') r 0.5955828064735441
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1763, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1763, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8228, device='cuda:0', dtype=torch.float16) q[a] 0.82275390625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8228, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8228, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1763, device='cuda:0', dtype=torch.float16)
pa tensor(0.1763, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1763, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.11005415006460906

-------------------step: 1-------------------

directly accept a 338

-------------------step: 2-------------------

x1 278 x2 319 a 278
q[a] 0.7900390625 q[x1] 0.7900390625 q[x2] 0.0013885498046875
gtp[x1] 0.004245758056640625 gtp[x2] 1.3649463653564453e-05 gtp[a] 0.004245758056640625
pp sum tensor(0.9507, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1606, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0042, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1606, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0052, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9825167849875902
q_ai sum tensor(0.7900, device='cuda:0', dtype=torch.float16) q[a] 0.7900390625
pp sum tensor(0.8462, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6855, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0042, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6855, device='cuda:0', dtype=torch.float16)
pa tensor(0.0042, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6855, device='cuda:0', dtype=torch.float16) acp tensor(0.0062, device='cuda:0', dtype=torch.float16) r 0.8754790044819772
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8423, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29915 x2 638 a 638
q[a] 0.4755859375 q[x1] 0.29296875 q[x2] 0.4755859375
gtp[x1] 0.0 gtp[x2] 0.96630859375 gtp[a] 0.96630859375
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.2930, device='cuda:0') acp tensor(0., device='cuda:0') r 0.5073853223353407
pp sum tensor(0.9824, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5063, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9663, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5063, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4756, device='cuda:0', dtype=torch.float16) q[a] 0.4755859375
pp sum tensor(0.9810, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4739, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9663, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4739, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4924, device='cuda:0', dtype=torch.float16)
pa tensor(0.4924, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5063, device='cuda:0', dtype=torch.float16) acp tensor(0.9727, device='cuda:0', dtype=torch.float16) r 0.2697905671750642

-------------------step: 2-------------------

x1 6241 x2 3357 a 3357
q[a] 0.1964111328125 q[x1] 0.0034313201904296875 q[x2] 0.1964111328125
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0034, device='cuda:0') acp tensor(0., device='cuda:0') r 0.09682231088634674
pp sum tensor(0.9888, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7925, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7925, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1963, device='cuda:0', dtype=torch.float16) q[a] 0.1964111328125
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1937, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1937, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7925, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7721055227185719
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9863, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 26901 x2 17594 a 17594
q[a] 0.8779296875 q[x1] 0.01910400390625 q[x2] 0.8779296875
gtp[x1] 0.0 gtp[x2] 0.99853515625 gtp[a] 0.99853515625
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0191, device='cuda:0') acp tensor(0., device='cuda:0') r 0.47126808957590705
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1205, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9985, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1205, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8779, device='cuda:0', dtype=torch.float16) q[a] 0.8779296875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8779, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9985, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8779, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1206, device='cuda:0', dtype=torch.float16)
pa tensor(0.1206, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1205, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.812382227058677

-------------------step: 2-------------------

x1 29892 x2 29889 a 29892
q[a] 0.85546875 q[x1] 0.85546875 q[x2] 0.061004638671875
gtp[x1] 0.8583984375 gtp[x2] 0.11798095703125 gtp[a] 0.8583984375
pp sum tensor(0.9214, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0660, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8584, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0570, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0660, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0570, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3611, device='cuda:0', dtype=torch.float16) acp tensor(0.1578, device='cuda:0', dtype=torch.float16) r 0.5414904324546457
q_ai sum tensor(0.8555, device='cuda:0', dtype=torch.float16) q[a] 0.85546875
pp sum tensor(0.8584, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7925, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8584, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7925, device='cuda:0', dtype=torch.float16)
pa tensor(0.8584, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7925, device='cuda:0', dtype=torch.float16) acp tensor(1.0830, device='cuda:0', dtype=torch.float16) r 0.4474827976794318

-------------------step: 3-------------------

x1 607 x2 5982 a 5982
q[a] 0.23681640625 q[x1] 0.1297607421875 q[x2] 0.23681640625
gtp[x1] 0.1165771484375 gtp[x2] 0.359130859375 gtp[a] 0.359130859375
px1 tensor(0.1166, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1298, device='cuda:0') acp tensor(0.8984, device='cuda:0') r 0.9618550155393641
pp sum tensor(0.6157, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3787, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3591, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3787, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2367, device='cuda:0', dtype=torch.float16) q[a] 0.23681640625
pp sum tensor(0.5503, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1711, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3591, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1711, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1880, device='cuda:0', dtype=torch.float16)
pa tensor(0.1880, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3787, device='cuda:0', dtype=torch.float16) acp tensor(0.4963, device='cuda:0', dtype=torch.float16) r 0.67015939178615
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1909, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 9560 x2 10901 a 10901
q[a] 0.1558837890625 q[x1] 0.007701873779296875 q[x2] 0.1558837890625
gtp[x1] 1.4483928680419922e-05 gtp[x2] 0.0029201507568359375 gtp[a] 0.0029201507568359375
px1 tensor(1.4484e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0077, device='cuda:0') acp tensor(0.0019, device='cuda:0') r 0.7288247475668674
pp sum tensor(0.9482, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7925, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0029, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7925, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1559, device='cuda:0', dtype=torch.float16) q[a] 0.1558837890625
pp sum tensor(0.9395, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1472, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0029, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1472, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7925, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8099226181973418
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9365, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 10901 x2 2821 a 10901
q[a] 0.64697265625 q[x1] 0.64697265625 q[x2] 0.061126708984375
gtp[x1] 0.496826171875 gtp[x2] 0.0523681640625 gtp[a] 0.496826171875
pp sum tensor(0.7056, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0585, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4968, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0585, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1120, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.00822635547038475
q_ai sum tensor(0.6470, device='cuda:0', dtype=torch.float16) q[a] 0.64697265625
pp sum tensor(0.6245, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5664, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4968, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5664, device='cuda:0', dtype=torch.float16)
pa tensor(0.4968, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5664, device='cuda:0', dtype=torch.float16) acp tensor(0.8770, device='cuda:0', dtype=torch.float16) r 0.860655161582421

-------------------step: 2-------------------

directly accept a 11195

-------------------step: 3-------------------

x1 367 x2 7254 a 7254
q[a] 0.1456298828125 q[x1] 0.1065673828125 q[x2] 0.1456298828125
gtp[x1] 0.0 gtp[x2] 0.0033969879150390625 gtp[a] 0.0033969879150390625
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.1066, device='cuda:0') acp tensor(0., device='cuda:0') r 0.8813677294068174
pp sum tensor(0.8657, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7197, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0034, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7197, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1456, device='cuda:0', dtype=torch.float16) q[a] 0.1456298828125
pp sum tensor(0.8428, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1227, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0034, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1227, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7197, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6167885701687958
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8394, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 8551 x2 2821 a 8551
q[a] 0.9931640625 q[x1] 0.9931640625 q[x2] 0.005634307861328125
gtp[x1] 0.99853515625 gtp[x2] 0.0011873245239257812 gtp[a] 0.99853515625
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0054, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0054, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8159, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5212594102246225
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16) q[a] 0.9931640625
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9937, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9937, device='cuda:0', dtype=torch.float16) acp tensor(1.0049, device='cuda:0', dtype=torch.float16) r 0.9045711570717633

-------------------step: 2-------------------

x1 19922 x2 20037 a 19922
q[a] 0.95458984375 q[x1] 0.95458984375 q[x2] 0.0021381378173828125
gtp[x1] 0.8994140625 gtp[x2] 0.00011998414993286133 gtp[a] 0.8994140625
pp sum tensor(0.9683, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0137, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8994, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0137, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0451, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2598865793420432
q_ai sum tensor(0.9546, device='cuda:0', dtype=torch.float16) q[a] 0.95458984375
pp sum tensor(0.8994, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8857, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8994, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8857, device='cuda:0', dtype=torch.float16)
pa tensor(0.8994, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8857, device='cuda:0', dtype=torch.float16) acp tensor(1.0156, device='cuda:0', dtype=torch.float16) r 0.9753762359529693

-------------------step: 3-------------------

x1 322 x2 29892 a 322
q[a] 0.99462890625 q[x1] 0.99462890625 q[x2] 0.0038776397705078125
gtp[x1] 0.7548828125 gtp[x2] 0.2449951171875 gtp[a] 0.7548828125
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0014, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7549, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2411, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0014, device='cuda:0', dtype=torch.float16)
px2 tensor(0.2411, device='cuda:0', dtype=torch.float16) qx2 tensor(0.7056, device='cuda:0', dtype=torch.float16) acp tensor(0.3418, device='cuda:0', dtype=torch.float16) r 0.7721416037809169
q_ai sum tensor(0.9946, device='cuda:0', dtype=torch.float16) q[a] 0.99462890625
pp sum tensor(0.7549, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7534, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7549, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7534, device='cuda:0', dtype=torch.float16)
pa tensor(0.7549, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7534, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.8070143931016188

-------------------step: 1-------------------

x1 1652 x2 4796 a 4796
q[a] 0.72900390625 q[x1] 0.0006494522094726562 q[x2] 0.72900390625
gtp[x1] 8.344650268554688e-07 gtp[x2] 0.343017578125 gtp[a] 0.343017578125
px1 tensor(8.3447e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0006, device='cuda:0') acp tensor(0.0013, device='cuda:0') r 0.16553628796897168
pp sum tensor(0.9126, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1827, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3430, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1827, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7290, device='cuda:0', dtype=torch.float16) q[a] 0.72900390625
pp sum tensor(0.7725, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5889, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3430, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5889, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1827, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7826420487555628
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.4292, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 4796 x2 22843 a 4796
q[a] 0.66552734375 q[x1] 0.66552734375 q[x2] 0.1395263671875
gtp[x1] 0.58984375 gtp[x2] 0.07501220703125 gtp[a] 0.58984375
pp sum tensor(0.7793, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1136, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.5898, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1136, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2778, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3189523403690533
q_ai sum tensor(0.6655, device='cuda:0', dtype=torch.float16) q[a] 0.66552734375
pp sum tensor(0.6768, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5635, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.5898, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5635, device='cuda:0', dtype=torch.float16)
pa tensor(0.5898, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5635, device='cuda:0', dtype=torch.float16) acp tensor(1.0469, device='cuda:0', dtype=torch.float16) r 0.2995640016784612

-------------------step: 2-------------------

x1 11982 x2 6575 a 11982
q[a] 0.98779296875 q[x1] 0.98779296875 q[x2] 0.00013709068298339844
gtp[x1] 0.87890625 gtp[x2] 2.980232238769531e-07 gtp[a] 0.87890625
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0066, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8789, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0066, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0111, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7364200673509281
q_ai sum tensor(0.9878, device='cuda:0', dtype=torch.float16) q[a] 0.98779296875
pp sum tensor(0.8789, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8726, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8789, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8726, device='cuda:0', dtype=torch.float16)
pa tensor(0.8789, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8726, device='cuda:0', dtype=torch.float16) acp tensor(1.0068, device='cuda:0', dtype=torch.float16) r 0.24151531490151246

-------------------step: 3-------------------

x1 29889 x2 29891 a 29889
q[a] 0.6455078125 q[x1] 0.6455078125 q[x2] 0.1429443359375
gtp[x1] 0.9765625 gtp[x2] 0.001514434814453125 gtp[a] 0.9765625
pp sum tensor(0.9810, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3352, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9766, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3352, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2603, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4610697419854428
q_ai sum tensor(0.6455, device='cuda:0', dtype=torch.float16) q[a] 0.6455078125
pp sum tensor(0.9771, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6411, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9766, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6411, device='cuda:0', dtype=torch.float16)
pa tensor(0.9766, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6411, device='cuda:0', dtype=torch.float16) acp tensor(1.5234, device='cuda:0', dtype=torch.float16) r 0.7294690786450768

-------------------step: 1-------------------

x1 263 x2 297 a 263
q[a] 0.9970703125 q[x1] 0.9970703125 q[x2] 0.00045371055603027344
gtp[x1] 0.97998046875 gtp[x2] 0.00482940673828125 gtp[a] 0.97998046875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0013, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9800, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0044, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0013, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0044, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1584, device='cuda:0', dtype=torch.float16) acp tensor(0.0276, device='cuda:0', dtype=torch.float16) r 0.6996725228881631
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16) q[a] 0.9970703125
pp sum tensor(0.9800, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9785, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9800, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9785, device='cuda:0', dtype=torch.float16)
pa tensor(0.9800, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9785, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.6085801330183591

-------------------step: 2-------------------

x1 2462 x2 380 a 380
q[a] 0.23046875 q[x1] 0.07421875 q[x2] 0.23046875
gtp[x1] 0.0031261444091796875 gtp[x2] 0.6748046875 gtp[a] 0.6748046875
px1 tensor(0.0031, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0742, device='cuda:0') acp tensor(0.0421, device='cuda:0') r 0.24526650432583041
pp sum tensor(0.7773, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5469, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6748, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5469, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2305, device='cuda:0', dtype=torch.float16) q[a] 0.23046875
pp sum tensor(0.7588, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2118, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6748, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2118, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4629, device='cuda:0', dtype=torch.float16)
pa tensor(0.4629, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5469, device='cuda:0', dtype=torch.float16) acp tensor(0.8462, device='cuda:0', dtype=torch.float16) r 0.5785389452241677

-------------------step: 3-------------------

directly accept a 1245

-------------------step: 1-------------------

x1 278 x2 2874 a 278
q[a] 0.9560546875 q[x1] 0.9560546875 q[x2] 2.980232238769531e-07
gtp[x1] 0.99853515625 gtp[x2] 0.0 gtp[a] 0.99853515625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0426, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0426, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(6.5565e-06, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2953867653940535
q_ai sum tensor(0.9561, device='cuda:0', dtype=torch.float16) q[a] 0.9560546875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9561, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9561, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9561, device='cuda:0', dtype=torch.float16) acp tensor(1.0439, device='cuda:0', dtype=torch.float16) r 0.9957361700415638

-------------------step: 2-------------------

x1 25695 x2 19055 a 25695
q[a] 0.55517578125 q[x1] 0.55517578125 q[x2] 0.135986328125
gtp[x1] 0.9345703125 gtp[x2] 0.023773193359375 gtp[a] 0.9345703125
pp sum tensor(0.9531, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3979, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9346, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3979, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1697, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.548143439031629
q_ai sum tensor(0.5552, device='cuda:0', dtype=torch.float16) q[a] 0.55517578125
pp sum tensor(0.9453, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5469, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9346, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5469, device='cuda:0', dtype=torch.float16)
pa tensor(0.9346, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5469, device='cuda:0', dtype=torch.float16) acp tensor(1.7090, device='cuda:0', dtype=torch.float16) r 0.4547359017167292

-------------------step: 3-------------------

x1 29892 x2 2975 a 29892
q[a] 0.61376953125 q[x1] 0.61376953125 q[x2] 0.03955078125
gtp[x1] 0.66748046875 gtp[x2] 0.00027441978454589844 gtp[a] 0.66748046875
pp sum tensor(0.7319, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1183, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6675, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1183, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0629, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.746537846260181
q_ai sum tensor(0.6138, device='cuda:0', dtype=torch.float16) q[a] 0.61376953125
pp sum tensor(0.6685, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5503, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.6675, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5503, device='cuda:0', dtype=torch.float16)
pa tensor(0.6675, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5503, device='cuda:0', dtype=torch.float16) acp tensor(1.2129, device='cuda:0', dtype=torch.float16) r 0.10543662427102518

-------------------step: 1-------------------

x1 528 x2 263 a 263
q[a] 0.5947265625 q[x1] 0.0035648345947265625 q[x2] 0.5947265625
gtp[x1] 5.960464477539063e-08 gtp[x2] 0.98193359375 gtp[a] 0.98193359375
px1 tensor(5.9605e-08, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0036, device='cuda:0') acp tensor(1.6720e-05, device='cuda:0') r 0.9959267927917939
pp sum tensor(0.9897, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3948, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9819, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3948, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5947, device='cuda:0', dtype=torch.float16) q[a] 0.5947265625
pp sum tensor(0.9883, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5933, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9819, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5933, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3887, device='cuda:0', dtype=torch.float16)
pa tensor(0.3887, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3948, device='cuda:0', dtype=torch.float16) acp tensor(0.9844, device='cuda:0', dtype=torch.float16) r 0.27070784830259553

-------------------step: 2-------------------

x1 6575 x2 25695 a 6575
q[a] 0.40869140625 q[x1] 0.40869140625 q[x2] 0.0278167724609375
gtp[x1] 0.0006856918334960938 gtp[x2] 0.004299163818359375 gtp[a] 0.0006856918334960938
pp sum tensor(0.9126, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5039, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0007, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5039, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0192, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9610423909098444
q_ai sum tensor(0.4087, device='cuda:0', dtype=torch.float16) q[a] 0.40869140625
pp sum tensor(0.8696, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3660, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0007, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3660, device='cuda:0', dtype=torch.float16)
pa tensor(0.0007, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3660, device='cuda:0', dtype=torch.float16) acp tensor(0.0019, device='cuda:0', dtype=torch.float16) r 0.8752325187275279
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8691, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 2202 x2 305 a 2202
q[a] 0.481689453125 q[x1] 0.481689453125 q[x2] 0.1885986328125
gtp[x1] 0.96533203125 gtp[x2] 1.3113021850585938e-06 gtp[a] 0.96533203125
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5146, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9653, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5146, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1753, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9319367034400919
q_ai sum tensor(0.4817, device='cuda:0', dtype=torch.float16) q[a] 0.481689453125
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4790, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9653, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4790, device='cuda:0', dtype=torch.float16)
pa tensor(0.9653, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4790, device='cuda:0', dtype=torch.float16) acp tensor(2.0156, device='cuda:0', dtype=torch.float16) r 0.6361791823281153

-------------------step: 2-------------------

x1 289 x2 3748 a 289
q[a] 0.552734375 q[x1] 0.552734375 q[x2] 0.00018548965454101562
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4448, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4448, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0002, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9762034238242879
q_ai sum tensor(0.5527, device='cuda:0', dtype=torch.float16) q[a] 0.552734375
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5498, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5498, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5498, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8650634747382948
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9951, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 5807 x2 13748 a 5807
q[a] 0.49462890625 q[x1] 0.49462890625 q[x2] 0.037567138671875
gtp[x1] 1.1920928955078125e-07 gtp[x2] 1.9788742065429688e-05 gtp[a] 1.1920928955078125e-07
pp sum tensor(0.9697, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4749, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.1921e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4749, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0368, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8410405079261443
q_ai sum tensor(0.4946, device='cuda:0', dtype=torch.float16) q[a] 0.49462890625
pp sum tensor(0.9497, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4744, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(1.1921e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4744, device='cuda:0', dtype=torch.float16)
pa tensor(1.1921e-07, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4744, device='cuda:0', dtype=torch.float16) acp tensor(2.3842e-07, device='cuda:0', dtype=torch.float16) r 0.9157525444805317
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9497, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29892 x2 515 a 29892
q[a] 0.70703125 q[x1] 0.70703125 q[x2] 0.1705322265625
gtp[x1] 0.0244140625 gtp[x2] 0.94482421875 gtp[a] 0.0244140625
pp sum tensor(0.7988, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0920, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0244, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7744, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0920, device='cuda:0', dtype=torch.float16)
px2 tensor(0.7744, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4116, device='cuda:0', dtype=torch.float16) acp tensor(1.8818, device='cuda:0', dtype=torch.float16) r 0.8065649365531313

-------------------step: 2-------------------

x1 263 x2 278 a 278
q[a] 0.796875 q[x1] 0.0814208984375 q[x2] 0.796875
gtp[x1] 0.666015625 gtp[x2] 0.005584716796875 gtp[a] 0.005584716796875
px1 tensor(0.6660, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0814, device='cuda:0') acp tensor(8.1799, device='cuda:0') r 0.04376232186709017

-------------------step: 3-------------------

x1 289 x2 1887 a 1887
q[a] 0.1986083984375 q[x1] 0.12335205078125 q[x2] 0.1986083984375
gtp[x1] 0.00032067298889160156 gtp[x2] 0.47314453125 gtp[a] 0.47314453125
px1 tensor(0.0003, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1234, device='cuda:0') acp tensor(0.0026, device='cuda:0') r 0.8439663448992983
pp sum tensor(0.8701, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6714, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4731, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6714, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1985, device='cuda:0', dtype=torch.float16) q[a] 0.1986083984375
pp sum tensor(0.8418, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1699, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4731, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1699, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3032, device='cuda:0', dtype=torch.float16)
pa tensor(0.3032, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6714, device='cuda:0', dtype=torch.float16) acp tensor(0.4517, device='cuda:0', dtype=torch.float16) r 0.14340254778346018

-------------------step: 1-------------------

x1 29892 x2 1623 a 29892
q[a] 0.9560546875 q[x1] 0.9560546875 q[x2] 3.325939178466797e-05
gtp[x1] 0.9921875 gtp[x2] 0.0 gtp[a] 0.9921875
pp sum tensor(0.9922, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0356, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9922, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0356, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0007, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2535186727955153
q_ai sum tensor(0.9561, device='cuda:0', dtype=torch.float16) q[a] 0.9560546875
pp sum tensor(0.9922, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9561, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9922, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9561, device='cuda:0', dtype=torch.float16)
pa tensor(0.9922, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9561, device='cuda:0', dtype=torch.float16) acp tensor(1.0381, device='cuda:0', dtype=torch.float16) r 0.04835067269206672

-------------------step: 2-------------------

directly accept a 322

-------------------step: 3-------------------

x1 6505 x2 13389 a 13389
q[a] 0.35302734375 q[x1] 0.0372314453125 q[x2] 0.35302734375
gtp[x1] 0.11065673828125 gtp[x2] 0.12347412109375 gtp[a] 0.12347412109375
px1 tensor(0.1107, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0372, device='cuda:0') acp tensor(2.9721, device='cuda:0') r 0.7402381689981958

-------------------step: 1-------------------

x1 6575 x2 1190 a 6575
q[a] 0.82470703125 q[x1] 0.82470703125 q[x2] 0.08758544921875
gtp[x1] 0.8525390625 gtp[x2] 0.040496826171875 gtp[a] 0.8525390625
pp sum tensor(0.9307, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1063, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8525, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1063, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4124, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6531288281915821
q_ai sum tensor(0.8247, device='cuda:0', dtype=torch.float16) q[a] 0.82470703125
pp sum tensor(0.8906, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7847, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8525, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7847, device='cuda:0', dtype=torch.float16)
pa tensor(0.8525, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7847, device='cuda:0', dtype=torch.float16) acp tensor(1.0869, device='cuda:0', dtype=torch.float16) r 0.9936145422462549

-------------------step: 2-------------------

x1 842 x2 731 a 731
q[a] 0.488525390625 q[x1] 0.36865234375 q[x2] 0.488525390625
gtp[x1] 0.0325927734375 gtp[x2] 0.0156402587890625 gtp[a] 0.0156402587890625
px1 tensor(0.0326, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3687, device='cuda:0') acp tensor(0.0884, device='cuda:0') r 0.22864808870503806
pp sum tensor(0.9517, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4629, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0156, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4629, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4885, device='cuda:0', dtype=torch.float16) q[a] 0.488525390625
pp sum tensor(0.9385, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4753, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0156, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4753, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4629, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.021916240887788874
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9229, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 975 x2 763 a 975
q[a] 0.80859375 q[x1] 0.80859375 q[x2] 0.0048828125
gtp[x1] 0.9970703125 gtp[x2] 5.424022674560547e-06 gtp[a] 0.9970703125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1902, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9971, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1902, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0207, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3980034867089135
q_ai sum tensor(0.8086, device='cuda:0', dtype=torch.float16) q[a] 0.80859375
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8081, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9971, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8081, device='cuda:0', dtype=torch.float16)
pa tensor(0.9971, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8081, device='cuda:0', dtype=torch.float16) acp tensor(1.2334, device='cuda:0', dtype=torch.float16) r 0.3569952869542977

-------------------step: 2-------------------

x1 278 x2 2668 a 278
q[a] 0.97607421875 q[x1] 0.97607421875 q[x2] 5.960464477539063e-08
gtp[x1] 0.99072265625 gtp[x2] 0.0 gtp[a] 0.99072265625
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0233, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9907, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0233, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(2.4438e-06, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.08928900790484806
q_ai sum tensor(0.9761, device='cuda:0', dtype=torch.float16) q[a] 0.97607421875
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9741, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9907, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9741, device='cuda:0', dtype=torch.float16)
pa tensor(0.9907, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9741, device='cuda:0', dtype=torch.float16) acp tensor(1.0166, device='cuda:0', dtype=torch.float16) r 0.8840492850770253

-------------------step: 3-------------------

x1 25695 x2 6575 a 6575
q[a] 0.544921875 q[x1] 0.036224365234375 q[x2] 0.544921875
gtp[x1] 5.3882598876953125e-05 gtp[x2] 2.390146255493164e-05 gtp[a] 2.390146255493164e-05
px1 tensor(5.3883e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0362, device='cuda:0') acp tensor(0.0015, device='cuda:0') r 0.40306381846075945
pp sum tensor(0.8828, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3374, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.3901e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3374, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5449, device='cuda:0', dtype=torch.float16) q[a] 0.544921875
pp sum tensor(0.7715, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4336, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.3901e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4336, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3374, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6861680025966951
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7715, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 1847

-------------------step: 2-------------------

x1 23474 x2 19922 a 23474
q[a] 0.7861328125 q[x1] 0.7861328125 q[x2] 0.019989013671875
gtp[x1] 0.8046875 gtp[x2] 0.06304931640625 gtp[a] 0.8046875
pp sum tensor(0.9004, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1142, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8047, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0431, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1142, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0431, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0735, device='cuda:0', dtype=torch.float16) acp tensor(0.5854, device='cuda:0', dtype=torch.float16) r 0.3663510963143801

-------------------step: 3-------------------

x1 29889 x2 1550 a 29889
q[a] 0.99853515625 q[x1] 0.99853515625 q[x2] 7.134675979614258e-05
gtp[x1] 0.3173828125 gtp[x2] 2.372264862060547e-05 gtp[a] 0.3173828125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0005, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3174, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0005, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0493, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.464664986334403
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16) q[a] 0.99853515625
pp sum tensor(0.4937, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4929, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.3174, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4929, device='cuda:0', dtype=torch.float16)
pa tensor(0.3174, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4929, device='cuda:0', dtype=torch.float16) acp tensor(0.6440, device='cuda:0', dtype=torch.float16) r 0.9417050654343846
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1763, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 278

-------------------step: 2-------------------

x1 23474 x2 14328 a 14328
q[a] 0.56494140625 q[x1] 0.28857421875 q[x2] 0.56494140625
gtp[x1] 0.0109405517578125 gtp[x2] 0.98486328125 gtp[a] 0.98486328125
px1 tensor(0.0109, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2886, device='cuda:0') acp tensor(0.0379, device='cuda:0') r 0.40020874043032617
pp sum tensor(0.9873, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4221, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9849, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4221, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5649, device='cuda:0', dtype=torch.float16) q[a] 0.56494140625
pp sum tensor(0.9858, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5640, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9849, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5640, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4209, device='cuda:0', dtype=torch.float16)
pa tensor(0.4209, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4221, device='cuda:0', dtype=torch.float16) acp tensor(0.9971, device='cuda:0', dtype=torch.float16) r 0.7937502082169471

-------------------step: 3-------------------

x1 21091 x2 7561 a 21091
q[a] 0.697265625 q[x1] 0.697265625 q[x2] 4.589557647705078e-06
gtp[x1] 0.2279052734375 gtp[x2] 0.0 gtp[a] 0.2279052734375
pp sum tensor(0.9482, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2510, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2279, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2510, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(1.0610e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9433105749347109
q_ai sum tensor(0.6973, device='cuda:0', dtype=torch.float16) q[a] 0.697265625
pp sum tensor(0.8311, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5801, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.2279, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5801, device='cuda:0', dtype=torch.float16)
pa tensor(0.2279, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5801, device='cuda:0', dtype=torch.float16) acp tensor(0.3928, device='cuda:0', dtype=torch.float16) r 0.4700728943326651
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6030, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 13 x2 349 a 13
q[a] 0.98779296875 q[x1] 0.98779296875 q[x2] 8.225440979003906e-06
gtp[x1] 0.98779296875 gtp[x2] 8.344650268554688e-07 gtp[a] 0.98779296875
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0065, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9878, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0065, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0007, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9991057771726393
q_ai sum tensor(0.9878, device='cuda:0', dtype=torch.float16) q[a] 0.98779296875
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9814, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9878, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9814, device='cuda:0', dtype=torch.float16)
pa tensor(0.9878, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9814, device='cuda:0', dtype=torch.float16) acp tensor(1.0068, device='cuda:0', dtype=torch.float16) r 0.4693932838187497

-------------------step: 2-------------------

directly accept a 13

-------------------step: 3-------------------

x1 1252 x2 2744 a 2744
q[a] 0.27783203125 q[x1] 0.00060272216796875 q[x2] 0.27783203125
gtp[x1] 0.0001100301742553711 gtp[x2] 0.1197509765625 gtp[a] 0.1197509765625
px1 tensor(0.0001, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0006, device='cuda:0') acp tensor(0.1826, device='cuda:0') r 0.7700305935360483
pp sum tensor(0.5054, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2275, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1198, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2275, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2778, device='cuda:0', dtype=torch.float16) q[a] 0.27783203125
pp sum tensor(0.4277, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2003, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1198, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2003, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2275, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1488488913022613
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3079, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 263 x2 16375 a 263
q[a] 0.6416015625 q[x1] 0.6416015625 q[x2] 0.0281829833984375
gtp[x1] 0.8349609375 gtp[x2] 1.2874603271484375e-05 gtp[a] 0.8349609375
pp sum tensor(0.8555, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2136, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8350, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2136, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0505, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7602835761264355
q_ai sum tensor(0.6416, device='cuda:0', dtype=torch.float16) q[a] 0.6416015625
pp sum tensor(0.8369, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6230, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8350, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6230, device='cuda:0', dtype=torch.float16)
pa tensor(0.8350, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6230, device='cuda:0', dtype=torch.float16) acp tensor(1.3398, device='cuda:0', dtype=torch.float16) r 0.32924485744863075

-------------------step: 2-------------------

x1 6493 x2 16375 a 16375
q[a] 0.1971435546875 q[x1] 0.0233612060546875 q[x2] 0.1971435546875
gtp[x1] 3.4570693969726562e-06 gtp[x2] 0.0081329345703125 gtp[a] 0.0081329345703125
px1 tensor(3.4571e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0234, device='cuda:0') acp tensor(0.0001, device='cuda:0') r 0.4230905045859783
pp sum tensor(0.8267, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6294, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0081, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6294, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1971, device='cuda:0', dtype=torch.float16) q[a] 0.1971435546875
pp sum tensor(0.7993, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1702, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0081, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1702, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6294, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3943507988686423
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7915, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 16375 x2 17623 a 17623
q[a] 0.6328125 q[x1] 0.00506591796875 q[x2] 0.6328125
gtp[x1] 0.001270294189453125 gtp[x2] 0.87841796875 gtp[a] 0.87841796875
px1 tensor(0.0013, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0051, device='cuda:0') acp tensor(0.2508, device='cuda:0') r 0.5114927955886375
pp sum tensor(0.9287, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2957, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8784, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2957, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6328, device='cuda:0', dtype=torch.float16) q[a] 0.6328125
pp sum tensor(0.9014, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6060, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8784, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6060, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2725, device='cuda:0', dtype=torch.float16)
pa tensor(0.2725, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2957, device='cuda:0', dtype=torch.float16) acp tensor(0.9214, device='cuda:0', dtype=torch.float16) r 0.11289925253262778

-------------------step: 2-------------------

x1 332 x2 545 a 332
q[a] 0.97705078125 q[x1] 0.97705078125 q[x2] 0.0226287841796875
gtp[x1] 0.9990234375 gtp[x2] 0.0005702972412109375 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0222, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0222, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9668, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.30013662654583806
q_ai sum tensor(0.9771, device='cuda:0', dtype=torch.float16) q[a] 0.97705078125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9766, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9766, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9766, device='cuda:0', dtype=torch.float16) acp tensor(1.0234, device='cuda:0', dtype=torch.float16) r 0.7889770415826491

-------------------step: 3-------------------

directly accept a 681

-------------------step: 1-------------------

directly accept a 29892

-------------------step: 2-------------------

x1 26901 x2 278 a 278
q[a] 0.406494140625 q[x1] 0.04351806640625 q[x2] 0.406494140625
gtp[x1] 0.0004544258117675781 gtp[x2] 0.0007038116455078125 gtp[a] 0.0007038116455078125
px1 tensor(0.0005, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0435, device='cuda:0') acp tensor(0.0104, device='cuda:0') r 0.16256603774652878
pp sum tensor(0.7754, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3689, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0007, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3689, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4065, device='cuda:0', dtype=torch.float16) q[a] 0.406494140625
pp sum tensor(0.6802, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3115, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0007, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3115, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3689, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8381604155787487
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6792, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 446

-------------------step: 2-------------------

x1 304 x2 373 a 304
q[a] 0.84521484375 q[x1] 0.84521484375 q[x2] 0.10919189453125
gtp[x1] 0.91357421875 gtp[x2] 4.589557647705078e-06 gtp[a] 0.91357421875
pp sum tensor(0.9819, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1367, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9136, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1367, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5972, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.529735815072265
q_ai sum tensor(0.8452, device='cuda:0', dtype=torch.float16) q[a] 0.84521484375
pp sum tensor(0.9258, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7886, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9136, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7886, device='cuda:0', dtype=torch.float16)
pa tensor(0.9136, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7886, device='cuda:0', dtype=torch.float16) acp tensor(1.1582, device='cuda:0', dtype=torch.float16) r 0.7909119642538524

-------------------step: 3-------------------

x1 278 x2 14619 a 278
q[a] 0.9140625 q[x1] 0.9140625 q[x2] 9.357929229736328e-06
gtp[x1] 0.99560546875 gtp[x2] 0.0 gtp[a] 0.99560546875
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0822, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9956, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0822, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(9.9778e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5287951415082531
q_ai sum tensor(0.9141, device='cuda:0', dtype=torch.float16) q[a] 0.9140625
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9136, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9956, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9136, device='cuda:0', dtype=torch.float16)
pa tensor(0.9956, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9136, device='cuda:0', dtype=torch.float16) acp tensor(1.0898, device='cuda:0', dtype=torch.float16) r 0.04335055669116161

-------------------step: 1-------------------

directly accept a 310

-------------------step: 2-------------------

x1 476 x2 278 a 278
q[a] 0.6279296875 q[x1] 0.07159423828125 q[x2] 0.6279296875
gtp[x1] 0.0071868896484375 gtp[x2] 0.63720703125 gtp[a] 0.63720703125
px1 tensor(0.0072, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0716, device='cuda:0') acp tensor(0.1004, device='cuda:0') r 0.3571763289453992
pp sum tensor(0.9404, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3125, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6372, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3125, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6279, device='cuda:0', dtype=torch.float16) q[a] 0.6279296875
pp sum tensor(0.9023, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5898, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6372, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5898, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0474, device='cuda:0', dtype=torch.float16)
pa tensor(0.0474, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3125, device='cuda:0', dtype=torch.float16) acp tensor(0.1516, device='cuda:0', dtype=torch.float16) r 0.4311538028909402
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.2649, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 898

-------------------step: 2-------------------

x1 29884 x2 3357 a 3357
q[a] 0.45751953125 q[x1] 0.01904296875 q[x2] 0.45751953125
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0190, device='cuda:0') acp tensor(0., device='cuda:0') r 0.8756765468342887
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.5420, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5420, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4578, device='cuda:0', dtype=torch.float16) q[a] 0.45751953125
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.4578, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4578, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5420, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7696392823670265
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(1., device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 8040 x2 4306 a 4306
q[a] 0.315673828125 q[x1] 0.01006317138671875 q[x2] 0.315673828125
gtp[x1] 3.5762786865234375e-07 gtp[x2] 0.0007410049438476562 gtp[a] 0.0007410049438476562
px1 tensor(3.5763e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0101, device='cuda:0') acp tensor(3.5538e-05, device='cuda:0') r 0.17978252927289418
pp sum tensor(0.9893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6733, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0007, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6733, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3157, device='cuda:0', dtype=torch.float16) q[a] 0.315673828125
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3147, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0007, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3147, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6733, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.04567725507596254
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9873, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 278 x2 263 a 263
q[a] 0.650390625 q[x1] 0.332275390625 q[x2] 0.650390625
gtp[x1] 0.0003204345703125 gtp[x2] 0.7919921875 gtp[a] 0.7919921875
px1 tensor(0.0003, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3323, device='cuda:0') acp tensor(0.0010, device='cuda:0') r 0.6271055183911023
pp sum tensor(0.9844, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3342, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7920, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3342, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6504, device='cuda:0', dtype=torch.float16) q[a] 0.650390625
pp sum tensor(0.9692, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6357, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7920, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6357, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1562, device='cuda:0', dtype=torch.float16)
pa tensor(0.1562, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3342, device='cuda:0', dtype=torch.float16) acp tensor(0.4675, device='cuda:0', dtype=torch.float16) r 0.7825757317429454
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1772, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 21210 x2 9849 a 9849
q[a] 0.36962890625 q[x1] 0.0238037109375 q[x2] 0.36962890625
gtp[x1] 0.00012612342834472656 gtp[x2] 0.083251953125 gtp[a] 0.083251953125
px1 tensor(0.0001, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0238, device='cuda:0') acp tensor(0.0053, device='cuda:0') r 0.9584608798950062
pp sum tensor(0.8643, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4951, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0833, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4951, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3696, device='cuda:0', dtype=torch.float16) q[a] 0.36962890625
pp sum tensor(0.7979, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3027, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0833, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3027, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4951, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6162127539169256
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7144, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 270 x2 1700 a 1700
q[a] 0.37548828125 q[x1] 0.26416015625 q[x2] 0.37548828125
gtp[x1] 1.531839370727539e-05 gtp[x2] 0.97705078125 gtp[a] 0.97705078125
px1 tensor(1.5318e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2642, device='cuda:0') acp tensor(5.7989e-05, device='cuda:0') r 0.20416310727271525
pp sum tensor(0.9771, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6011, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9771, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6011, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3757, device='cuda:0', dtype=torch.float16) q[a] 0.37548828125
pp sum tensor(0.9771, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3757, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9771, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3757, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6016, device='cuda:0', dtype=torch.float16)
pa tensor(0.6016, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6011, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.11510965578034194

-------------------step: 2-------------------

x1 3068 x2 26004 a 26004
q[a] 0.56884765625 q[x1] 0.4228515625 q[x2] 0.56884765625
gtp[x1] 0.9921875 gtp[x2] 0.0079345703125 gtp[a] 0.0079345703125
px1 tensor(0.9922, device='cuda:0', dtype=torch.float16) qx1 tensor(0.4229, device='cuda:0') acp tensor(2.3464, device='cuda:0') r 0.09678307058547686

-------------------step: 3-------------------

directly accept a 293

-------------------step: 1-------------------

directly accept a 1008

-------------------step: 2-------------------

x1 393 x2 5982 a 393
q[a] 0.72021484375 q[x1] 0.72021484375 q[x2] 0.14404296875
gtp[x1] 0.76318359375 gtp[x2] 0.2255859375 gtp[a] 0.76318359375
pp sum tensor(0.8486, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1284, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7632, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0815, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1284, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0815, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3713, device='cuda:0', dtype=torch.float16) acp tensor(0.2196, device='cuda:0', dtype=torch.float16) r 0.11261494319276921

-------------------step: 3-------------------

x1 373 x2 2978 a 373
q[a] 0.8046875 q[x1] 0.8046875 q[x2] 0.0076446533203125
gtp[x1] 0.2034912109375 gtp[x2] 0.00449371337890625 gtp[a] 0.2034912109375
pp sum tensor(0.8213, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0163, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2035, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0163, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0315, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.42939755248550393
q_ai sum tensor(0.8047, device='cuda:0', dtype=torch.float16) q[a] 0.8046875
pp sum tensor(0.2036, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1871, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.2035, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1871, device='cuda:0', dtype=torch.float16)
pa tensor(0.2035, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1871, device='cuda:0', dtype=torch.float16) acp tensor(1.0879, device='cuda:0', dtype=torch.float16) r 0.2407759351994615

-------------------step: 1-------------------

x1 714 x2 12180 a 12180
q[a] 0.1983642578125 q[x1] 0.045654296875 q[x2] 0.1983642578125
gtp[x1] 0.07342529296875 gtp[x2] 0.0096282958984375 gtp[a] 0.0096282958984375
px1 tensor(0.0734, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0457, device='cuda:0') acp tensor(1.6083, device='cuda:0') r 0.31376087539726816

-------------------step: 2-------------------

directly accept a 808

-------------------step: 3-------------------

directly accept a 381

-------------------step: 1-------------------

directly accept a 310

-------------------step: 2-------------------

x1 278 x2 22552 a 278
q[a] 0.85888671875 q[x1] 0.85888671875 q[x2] 0.0941162109375
gtp[x1] 6.139278411865234e-05 gtp[x2] 0.873046875 gtp[a] 6.139278411865234e-05
pp sum tensor(0.9043, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0454, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(6.1393e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7788, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0454, device='cuda:0', dtype=torch.float16)
px2 tensor(0.7788, device='cuda:0', dtype=torch.float16) qx2 tensor(0.5723, device='cuda:0', dtype=torch.float16) acp tensor(1.3613, device='cuda:0', dtype=torch.float16) r 0.789792199951375

-------------------step: 3-------------------

directly accept a 638

-------------------step: 1-------------------

x1 29889 x2 17594 a 17594
q[a] 0.55810546875 q[x1] 0.371826171875 q[x2] 0.55810546875
gtp[x1] 0.9970703125 gtp[x2] 0.00307464599609375 gtp[a] 0.00307464599609375
px1 tensor(0.9971, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3718, device='cuda:0') acp tensor(2.6815, device='cuda:0') r 0.760822318118405

-------------------step: 2-------------------

x1 5976 x2 5741 a 5741
q[a] 0.1583251953125 q[x1] 0.02227783203125 q[x2] 0.1583251953125
gtp[x1] 2.980232238769531e-07 gtp[x2] 2.384185791015625e-07 gtp[a] 2.384185791015625e-07
px1 tensor(2.9802e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0223, device='cuda:0') acp tensor(1.3378e-05, device='cuda:0') r 0.9243997470039773
pp sum tensor(0.8521, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6938, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.3842e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6938, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1582, device='cuda:0', dtype=torch.float16) q[a] 0.1583251953125
pp sum tensor(0.8271, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1335, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.3842e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1335, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6938, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3166013336430725
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8271, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 2181 x2 2078 a 2181
q[a] 0.09735107421875 q[x1] 0.09735107421875 q[x2] 0.08795166015625
gtp[x1] 0.0004832744598388672 gtp[x2] 8.529424667358398e-05 gtp[a] 0.0004832744598388672
pp sum tensor(0.8276, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7300, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0005, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7300, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0095, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8104894707921164
q_ai sum tensor(0.0972, device='cuda:0', dtype=torch.float16) q[a] 0.09735107421875
pp sum tensor(0.8188, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0886, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0005, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0886, device='cuda:0', dtype=torch.float16)
pa tensor(0.0005, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.0886, device='cuda:0', dtype=torch.float16) acp tensor(0.0055, device='cuda:0', dtype=torch.float16) r 0.49196922598498205
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8184, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29896 x2 29941 a 29896
q[a] 0.394775390625 q[x1] 0.394775390625 q[x2] 0.050567626953125
gtp[x1] 0.9326171875 gtp[x2] 0.005764007568359375 gtp[a] 0.9326171875
pp sum tensor(0.9395, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5444, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9326, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5444, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0330, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8180429130544101
q_ai sum tensor(0.3950, device='cuda:0', dtype=torch.float16) q[a] 0.394775390625
pp sum tensor(0.9385, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3938, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9326, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3938, device='cuda:0', dtype=torch.float16)
pa tensor(0.9326, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3938, device='cuda:0', dtype=torch.float16) acp tensor(2.3691, device='cuda:0', dtype=torch.float16) r 0.6470408219879333

-------------------step: 2-------------------

x1 29945 x2 29900 a 29900
q[a] 0.87890625 q[x1] 0.036865234375 q[x2] 0.87890625
gtp[x1] 2.5033950805664062e-06 gtp[x2] 1.0728836059570312e-06 gtp[a] 1.0728836059570312e-06
px1 tensor(2.5034e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0369, device='cuda:0') acp tensor(6.7907e-05, device='cuda:0') r 0.34278805875364604
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1202, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.0729e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1202, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8789, device='cuda:0', dtype=torch.float16) q[a] 0.87890625
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8770, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.0729e-06, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8770, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1202, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6046858641095401
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9971, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29945 x2 29929 a 29945
q[a] 0.92822265625 q[x1] 0.92822265625 q[x2] 0.032257080078125
gtp[x1] 0.0048828125 gtp[x2] 2.9742717742919922e-05 gtp[a] 0.0048828125
pp sum tensor(0.9771, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0492, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0049, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0492, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4160, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3293521921246002
q_ai sum tensor(0.9282, device='cuda:0', dtype=torch.float16) q[a] 0.92822265625
pp sum tensor(0.8154, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7661, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0049, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7661, device='cuda:0', dtype=torch.float16)
pa tensor(0.0049, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7661, device='cuda:0', dtype=torch.float16) acp tensor(0.0064, device='cuda:0', dtype=torch.float16) r 0.0630060935524922
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8105, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 304 x2 380 a 304
q[a] 0.251220703125 q[x1] 0.251220703125 q[x2] 0.0040283203125
gtp[x1] 5.364418029785156e-07 gtp[x2] 0.0 gtp[a] 5.364418029785156e-07
pp sum tensor(0.9023, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6509, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(5.3644e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6509, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0014, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7328460745089455
q_ai sum tensor(0.2512, device='cuda:0', dtype=torch.float16) q[a] 0.251220703125
pp sum tensor(0.8828, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2314, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(5.3644e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2314, device='cuda:0', dtype=torch.float16)
pa tensor(5.3644e-07, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2314, device='cuda:0', dtype=torch.float16) acp tensor(2.3246e-06, device='cuda:0', dtype=torch.float16) r 0.3568874393863203
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8828, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 26763

-------------------step: 2-------------------

x1 7251 x2 26203 a 7251
q[a] 0.716796875 q[x1] 0.716796875 q[x2] 0.2086181640625
gtp[x1] 0.50439453125 gtp[x2] 0.045501708984375 gtp[a] 0.50439453125
pp sum tensor(0.9448, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2279, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.5044, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2279, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5288, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.33136127283303185
q_ai sum tensor(0.7168, device='cuda:0', dtype=torch.float16) q[a] 0.716796875
pp sum tensor(0.9365, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7090, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.5044, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7090, device='cuda:0', dtype=torch.float16)
pa tensor(0.5044, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7090, device='cuda:0', dtype=torch.float16) acp tensor(0.7114, device='cuda:0', dtype=torch.float16) r 0.6271553822935166

-------------------step: 3-------------------

directly accept a 446

-------------------step: 1-------------------

directly accept a 278

-------------------step: 2-------------------

x1 2246 x2 10784 a 2246
q[a] 0.46337890625 q[x1] 0.46337890625 q[x2] 0.024749755859375
gtp[x1] 0.60693359375 gtp[x2] 5.960464477539063e-08 gtp[a] 0.60693359375
pp sum tensor(0.8682, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4048, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6069, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4048, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0214, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8890264942062056
q_ai sum tensor(0.4634, device='cuda:0', dtype=torch.float16) q[a] 0.46337890625
pp sum tensor(0.7554, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3506, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.6069, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3506, device='cuda:0', dtype=torch.float16)
pa tensor(0.6069, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3506, device='cuda:0', dtype=torch.float16) acp tensor(1.7314, device='cuda:0', dtype=torch.float16) r 0.44136610150287414

-------------------step: 3-------------------

x1 310 x2 2 a 310
q[a] 1.0 q[x1] 1.0 q[x2] 9.608268737792969e-05
gtp[x1] 0.0082244873046875 gtp[x2] 8.344650268554688e-06 gtp[a] 0.0082244873046875
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(8.9765e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0082, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(8.9765e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5459, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1824913143048693
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.6582, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6582, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0082, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6582, device='cuda:0', dtype=torch.float16)
pa tensor(0.0082, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6582, device='cuda:0', dtype=torch.float16) acp tensor(0.0125, device='cuda:0', dtype=torch.float16) r 0.46649558858734064
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6499, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 18066 x2 20751 a 20751
q[a] 0.5107421875 q[x1] 0.052154541015625 q[x2] 0.5107421875
gtp[x1] 0.29638671875 gtp[x2] 0.010467529296875 gtp[a] 0.010467529296875
px1 tensor(0.2964, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0522, device='cuda:0') acp tensor(5.6829, device='cuda:0') r 0.5628135439391345

-------------------step: 2-------------------

directly accept a 292

-------------------step: 3-------------------

x1 322 x2 29892 a 29892
q[a] 0.921875 q[x1] 0.064697265625 q[x2] 0.921875
gtp[x1] 9.799003601074219e-05 gtp[x2] 0.76953125 gtp[a] 0.76953125
px1 tensor(9.7990e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0647, device='cuda:0') acp tensor(0.0015, device='cuda:0') r 0.891567428876854
pp sum tensor(0.9922, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0705, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7695, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0705, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9224, device='cuda:0', dtype=torch.float16) q[a] 0.921875
pp sum tensor(0.9189, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8491, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7695, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8491, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.0705, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9897116485288286
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1495, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 20751 x2 26606 a 20751
q[a] 0.8115234375 q[x1] 0.8115234375 q[x2] 7.015466690063477e-05
gtp[x1] 0.87646484375 gtp[x2] 0.0001304149627685547 gtp[a] 0.87646484375
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1760, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8765, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(6.0260e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1760, device='cuda:0', dtype=torch.float16)
px2 tensor(6.0260e-05, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0003, device='cuda:0', dtype=torch.float16) acp tensor(0.1990, device='cuda:0', dtype=torch.float16) r 0.03871758239113565

-------------------step: 2-------------------

x1 20751 x2 7901 a 20751
q[a] 0.7041015625 q[x1] 0.7041015625 q[x2] 0.004489898681640625
gtp[x1] 0.9990234375 gtp[x2] 0.0 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2949, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2949, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0107, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7848676899455336
q_ai sum tensor(0.7041, device='cuda:0', dtype=torch.float16) q[a] 0.7041015625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7041, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7041, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7041, device='cuda:0', dtype=torch.float16) acp tensor(1.4189, device='cuda:0', dtype=torch.float16) r 0.23926527326025582

-------------------step: 3-------------------

directly accept a 292

-------------------step: 1-------------------

x1 411 x2 322 a 411
q[a] 0.7900390625 q[x1] 0.7900390625 q[x2] 0.105224609375
gtp[x1] 0.849609375 gtp[x2] 0.01373291015625 gtp[a] 0.849609375
pp sum tensor(0.8887, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0988, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8496, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0988, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3958, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2600672749055468
q_ai sum tensor(0.7900, device='cuda:0', dtype=torch.float16) q[a] 0.7900390625
pp sum tensor(0.8496, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7510, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8496, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7510, device='cuda:0', dtype=torch.float16)
pa tensor(0.8496, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7510, device='cuda:0', dtype=torch.float16) acp tensor(1.1309, device='cuda:0', dtype=torch.float16) r 0.9152889132017423

-------------------step: 2-------------------

x1 263 x2 380 a 380
q[a] 0.61572265625 q[x1] 0.01459503173828125 q[x2] 0.61572265625
gtp[x1] 0.0003352165222167969 gtp[x2] 0.2978515625 gtp[a] 0.2978515625
px1 tensor(0.0003, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0146, device='cuda:0') acp tensor(0.0230, device='cuda:0') r 0.3456321783525317
pp sum tensor(0.8110, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1949, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2979, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1949, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6157, device='cuda:0', dtype=torch.float16) q[a] 0.61572265625
pp sum tensor(0.5518, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3564, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2979, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3564, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1949, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.42290956883210373
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.2539, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 272

-------------------step: 2-------------------

x1 3304 x2 293 a 293
q[a] 0.46728515625 q[x1] 0.00992584228515625 q[x2] 0.46728515625
gtp[x1] 4.76837158203125e-07 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(4.7684e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0099, device='cuda:0') acp tensor(4.8040e-05, device='cuda:0') r 0.9620772377610041
pp sum tensor(0.9702, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5029, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5029, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4673, device='cuda:0', dtype=torch.float16) q[a] 0.46728515625
pp sum tensor(0.9443, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4414, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4414, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5029, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.49766089460114016
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9443, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 293

-------------------step: 2-------------------

directly accept a 8386

-------------------step: 3-------------------

x1 310 x2 393 a 310
q[a] 0.990234375 q[x1] 0.990234375 q[x2] 0.00351715087890625
gtp[x1] 0.9990234375 gtp[x2] 0.0008554458618164062 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0086, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0086, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3616, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.42723889475595167
q_ai sum tensor(0.9902, device='cuda:0', dtype=torch.float16) q[a] 0.990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9897, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9897, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9897, device='cuda:0', dtype=torch.float16) acp tensor(1.0098, device='cuda:0', dtype=torch.float16) r 0.05553548819541143

-------------------step: 1-------------------

x1 29895 x2 15218 a 29895
q[a] 0.2109375 q[x1] 0.2109375 q[x2] 0.00331878662109375
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
pp sum tensor(0.8721, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6611, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6611, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0009, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7134897902047235
q_ai sum tensor(0.2109, device='cuda:0', dtype=torch.float16) q[a] 0.2109375
pp sum tensor(0.8379, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1768, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1768, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1768, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6084592701561752
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8379, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 21528

-------------------step: 2-------------------

x1 322 x2 363 a 322
q[a] 0.97802734375 q[x1] 0.97802734375 q[x2] 0.0008916854858398438
gtp[x1] 0.978515625 gtp[x2] 6.556510925292969e-07 gtp[a] 0.978515625
pp sum tensor(0.9844, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0065, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9785, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0065, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0393, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8811131437545121
q_ai sum tensor(0.9780, device='cuda:0', dtype=torch.float16) q[a] 0.97802734375
pp sum tensor(0.9785, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9722, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9785, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9722, device='cuda:0', dtype=torch.float16)
pa tensor(0.9785, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9722, device='cuda:0', dtype=torch.float16) acp tensor(1.0068, device='cuda:0', dtype=torch.float16) r 0.9391636673506243

-------------------step: 3-------------------

x1 22552 x2 278 a 278
q[a] 0.79443359375 q[x1] 0.05364990234375 q[x2] 0.79443359375
gtp[x1] 0.0167236328125 gtp[x2] 0.97216796875 gtp[a] 0.97216796875
px1 tensor(0.0167, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0536, device='cuda:0') acp tensor(0.3117, device='cuda:0') r 0.6303455153704504
pp sum tensor(0.9736, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1791, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9722, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1791, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7944, device='cuda:0', dtype=torch.float16) q[a] 0.79443359375
pp sum tensor(0.9722, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7935, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9722, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7935, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1787, device='cuda:0', dtype=torch.float16)
pa tensor(0.1787, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1791, device='cuda:0', dtype=torch.float16) acp tensor(0.9980, device='cuda:0', dtype=torch.float16) r 0.5486933880940726

-------------------step: 1-------------------

x1 515 x2 14744 a 515
q[a] 0.214111328125 q[x1] 0.214111328125 q[x2] 0.06683349609375
gtp[x1] 0.062469482421875 gtp[x2] 1.0132789611816406e-06 gtp[a] 0.062469482421875
pp sum tensor(0.7129, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4985, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0625, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4985, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0182, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.17334382465726872
q_ai sum tensor(0.2141, device='cuda:0', dtype=torch.float16) q[a] 0.214111328125
pp sum tensor(0.6665, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1678, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0625, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1678, device='cuda:0', dtype=torch.float16)
pa tensor(0.0625, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1678, device='cuda:0', dtype=torch.float16) acp tensor(0.3721, device='cuda:0', dtype=torch.float16) r 0.6305866698628648
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6040, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29889 x2 8724 a 29889
q[a] 0.67919921875 q[x1] 0.67919921875 q[x2] 0.0007891654968261719
gtp[x1] 0.9990234375 gtp[x2] 0.0 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3196, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3196, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0017, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6542431301333989
q_ai sum tensor(0.6792, device='cuda:0', dtype=torch.float16) q[a] 0.67919921875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6792, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6792, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6792, device='cuda:0', dtype=torch.float16) acp tensor(1.4707, device='cuda:0', dtype=torch.float16) r 0.5596018253247635

-------------------step: 2-------------------

x1 13 x2 1522 a 13
q[a] 0.88916015625 q[x1] 0.88916015625 q[x2] 0.005207061767578125
gtp[x1] 0.64111328125 gtp[x2] 0.0367431640625 gtp[a] 0.64111328125
pp sum tensor(0.9131, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0242, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6411, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0315, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0242, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0315, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0418, device='cuda:0', dtype=torch.float16) acp tensor(0.7544, device='cuda:0', dtype=torch.float16) r 0.5970510147401169

-------------------step: 3-------------------

x1 1854 x2 2763 a 1854
q[a] 0.990234375 q[x1] 0.990234375 q[x2] 0.0005307197570800781
gtp[x1] 0.9599609375 gtp[x2] 1.9669532775878906e-06 gtp[a] 0.9599609375
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0066, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9600, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0066, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0536, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.26640141306804377
q_ai sum tensor(0.9902, device='cuda:0', dtype=torch.float16) q[a] 0.990234375
pp sum tensor(0.9600, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9531, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9600, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9531, device='cuda:0', dtype=torch.float16)
pa tensor(0.9600, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9531, device='cuda:0', dtype=torch.float16) acp tensor(1.0068, device='cuda:0', dtype=torch.float16) r 0.9549296514778352

-------------------step: 1-------------------

x1 17229 x2 2125 a 2125
q[a] 0.316650390625 q[x1] 0.099609375 q[x2] 0.316650390625
gtp[x1] 0.000568389892578125 gtp[x2] 0.01377105712890625 gtp[a] 0.01377105712890625
px1 tensor(0.0006, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0996, device='cuda:0') acp tensor(0.0057, device='cuda:0') r 0.5016726481981576
pp sum tensor(0.6890, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3726, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0138, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3726, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3167, device='cuda:0', dtype=torch.float16) q[a] 0.316650390625
pp sum tensor(0.6157, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2428, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0138, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2428, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3726, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8128117249681568
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6016, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 596 x2 4688 a 4688
q[a] 0.480224609375 q[x1] 0.437255859375 q[x2] 0.480224609375
gtp[x1] 0.2734375 gtp[x2] 0.63623046875 gtp[a] 0.63623046875
px1 tensor(0.2734, device='cuda:0', dtype=torch.float16) qx1 tensor(0.4373, device='cuda:0') acp tensor(0.6253, device='cuda:0') r 0.5367738883833126

-------------------step: 2-------------------

x1 16342 x2 17487 a 17487
q[a] 0.318603515625 q[x1] 0.1639404296875 q[x2] 0.318603515625
gtp[x1] 0.033721923828125 gtp[x2] 0.0014820098876953125 gtp[a] 0.0014820098876953125
px1 tensor(0.0337, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1639, device='cuda:0') acp tensor(0.2057, device='cuda:0') r 0.3448292404899437
pp sum tensor(0.9033, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5850, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0015, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5850, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3184, device='cuda:0', dtype=torch.float16) q[a] 0.318603515625
pp sum tensor(0.8760, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2910, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0015, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2910, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5850, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7680127046703391
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8745, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 446

-------------------step: 2-------------------

x1 4688 x2 11095 a 4688
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 5.692243576049805e-05
gtp[x1] 0.9990234375 gtp[x2] 3.88026237487793e-05 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0003, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0003, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1194, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8677210645260224
q_ai sum tensor(0.9995, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.36765939687723903

-------------------step: 3-------------------

x1 304 x2 322 a 322
q[a] 0.277099609375 q[x1] 0.1248779296875 q[x2] 0.277099609375
gtp[x1] 0.047637939453125 gtp[x2] 0.00018286705017089844 gtp[a] 0.00018286705017089844
px1 tensor(0.0476, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1249, device='cuda:0') acp tensor(0.3815, device='cuda:0') r 0.4717782727623404
pp sum tensor(0.7041, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4268, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0002, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4268, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2771, device='cuda:0', dtype=torch.float16) q[a] 0.277099609375
pp sum tensor(0.6240, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1969, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0002, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1969, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4268, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9529345153206222
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6240, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 278

-------------------step: 2-------------------

x1 7250 x2 4688 a 7250
q[a] 0.9931640625 q[x1] 0.9931640625 q[x2] 0.0008182525634765625
gtp[x1] 0.99169921875 gtp[x2] 0.0 gtp[a] 0.99169921875
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0067, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0067, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1193, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7577336669864191
q_ai sum tensor(0.9932, device='cuda:0', dtype=torch.float16) q[a] 0.9931640625
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9849, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9849, device='cuda:0', dtype=torch.float16)
pa tensor(0.9917, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9849, device='cuda:0', dtype=torch.float16) acp tensor(1.0068, device='cuda:0', dtype=torch.float16) r 0.1820460884310353

-------------------step: 3-------------------

x1 304 x2 29892 a 304
q[a] 0.95458984375 q[x1] 0.95458984375 q[x2] 0.041290283203125
gtp[x1] 0.87255859375 gtp[x2] 0.11993408203125 gtp[a] 0.87255859375
pp sum tensor(0.9565, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0021, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8726, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0786, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0021, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0786, device='cuda:0', dtype=torch.float16) qx2 tensor(0.8701, device='cuda:0', dtype=torch.float16) acp tensor(0.0903, device='cuda:0', dtype=torch.float16) r 0.4876989210471153
q_ai sum tensor(0.9546, device='cuda:0', dtype=torch.float16) q[a] 0.95458984375
pp sum tensor(0.8730, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8706, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8726, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8706, device='cuda:0', dtype=torch.float16)
pa tensor(0.8726, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8706, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.00877663805229778

-------------------step: 1-------------------

x1 278 x2 380 a 380
q[a] 0.162841796875 q[x1] 0.06683349609375 q[x2] 0.162841796875
gtp[x1] 0.9990234375 gtp[x2] 1.7881393432617188e-07 gtp[a] 1.7881393432617188e-07
px1 tensor(0.9990, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0668, device='cuda:0') acp tensor(14.9479, device='cuda:0') r 0.3943930578601358

-------------------step: 2-------------------

x1 7375 x2 11660 a 11660
q[a] 0.28076171875 q[x1] 0.0021953582763671875 q[x2] 0.28076171875
gtp[x1] 0.01812744140625 gtp[x2] 0.1297607421875 gtp[a] 0.1297607421875
px1 tensor(0.0181, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0022, device='cuda:0') acp tensor(8.2572, device='cuda:0') r 0.9352921562729377

-------------------step: 3-------------------

x1 1236 x2 9758 a 9758
q[a] 0.11834716796875 q[x1] 0.00466156005859375 q[x2] 0.11834716796875
gtp[x1] 6.556510925292969e-07 gtp[x2] 7.152557373046875e-07 gtp[a] 7.152557373046875e-07
px1 tensor(6.5565e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0047, device='cuda:0') acp tensor(0.0001, device='cuda:0') r 0.45790107456114304
pp sum tensor(0.9409, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8223, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(7.1526e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8223, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1183, device='cuda:0', dtype=torch.float16) q[a] 0.11834716796875
pp sum tensor(0.9370, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1143, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(7.1526e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1143, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8223, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6539578972425957
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9370, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 298 x2 286 a 286
q[a] 0.330322265625 q[x1] 0.006801605224609375 q[x2] 0.330322265625
gtp[x1] 6.318092346191406e-06 gtp[x2] 0.048309326171875 gtp[a] 0.048309326171875
px1 tensor(6.3181e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0068, device='cuda:0') acp tensor(0.0009, device='cuda:0') r 0.002350627133904548
pp sum tensor(0.6934, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3630, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0483, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3630, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3301, device='cuda:0', dtype=torch.float16) q[a] 0.330322265625
pp sum tensor(0.5884, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2249, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0483, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2249, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3630, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.18049685124131865
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5400, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 7176

-------------------step: 2-------------------

x1 5855 x2 17724 a 17724
q[a] 0.397705078125 q[x1] 0.021575927734375 q[x2] 0.397705078125
gtp[x1] 0.912109375 gtp[x2] 0.0131072998046875 gtp[a] 0.0131072998046875
px1 tensor(0.9121, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0216, device='cuda:0') acp tensor(42.2744, device='cuda:0') r 0.9638339206487708

-------------------step: 3-------------------

x1 322 x2 310 a 310
q[a] 0.370361328125 q[x1] 0.20458984375 q[x2] 0.370361328125
gtp[x1] 5.739927291870117e-05 gtp[x2] 0.0154266357421875 gtp[a] 0.0154266357421875
px1 tensor(5.7399e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2046, device='cuda:0') acp tensor(0.0003, device='cuda:0') r 0.5044728143913588
pp sum tensor(0.8770, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5063, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0154, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5063, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3704, device='cuda:0', dtype=torch.float16) q[a] 0.370361328125
pp sum tensor(0.8101, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3035, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0154, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3035, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5063, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.17645222979881148
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7949, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 508 x2 1033 a 508
q[a] 0.55810546875 q[x1] 0.55810546875 q[x2] 0.0016813278198242188
gtp[x1] 0.806640625 gtp[x2] 1.6093254089355469e-06 gtp[a] 0.806640625
pp sum tensor(0.9395, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3813, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8066, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3813, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0021, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.525145024192306
q_ai sum tensor(0.5581, device='cuda:0', dtype=torch.float16) q[a] 0.55810546875
pp sum tensor(0.8838, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5024, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8066, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5024, device='cuda:0', dtype=torch.float16)
pa tensor(0.8066, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5024, device='cuda:0', dtype=torch.float16) acp tensor(1.6055, device='cuda:0', dtype=torch.float16) r 0.4748438003706664

-------------------step: 2-------------------

x1 367 x2 2041 a 367
q[a] 0.5087890625 q[x1] 0.5087890625 q[x2] 0.39599609375
gtp[x1] 0.0081329345703125 gtp[x2] 0.0059967041015625 gtp[a] 0.0081329345703125
pp sum tensor(0.9663, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4578, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0081, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4578, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4102, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.11652239497207129
q_ai sum tensor(0.5088, device='cuda:0', dtype=torch.float16) q[a] 0.5087890625
pp sum tensor(0.9458, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4880, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0081, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4880, device='cuda:0', dtype=torch.float16)
pa tensor(0.0081, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4880, device='cuda:0', dtype=torch.float16) acp tensor(0.0167, device='cuda:0', dtype=torch.float16) r 0.9403472560543997
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9380, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 373 x2 2645 a 2645
q[a] 0.5302734375 q[x1] 0.039642333984375 q[x2] 0.5302734375
gtp[x1] 9.655952453613281e-05 gtp[x2] 0.0053558349609375 gtp[a] 0.0053558349609375
px1 tensor(9.6560e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0396, device='cuda:0') acp tensor(0.0024, device='cuda:0') r 0.1529708350247596
pp sum tensor(0.9492, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4185, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0054, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4185, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5303, device='cuda:0', dtype=torch.float16) q[a] 0.5302734375
pp sum tensor(0.8979, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4788, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0054, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4788, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4185, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.08642744059946084
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8926, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 297

-------------------step: 2-------------------

directly accept a 278

-------------------step: 3-------------------

x1 7250 x2 2462 a 7250
q[a] 0.57861328125 q[x1] 0.57861328125 q[x2] 0.00424957275390625
gtp[x1] 4.172325134277344e-07 gtp[x2] 1.0 gtp[a] 4.172325134277344e-07
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4167, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(4.1723e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9956, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4167, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9956, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0058, device='cuda:0', dtype=torch.float16) acp tensor(170.5000, device='cuda:0', dtype=torch.float16) r 0.8763915514669223

-------------------step: 1-------------------

directly accept a 13

-------------------step: 2-------------------

directly accept a 13

-------------------step: 3-------------------

x1 2855 x2 797 a 797
q[a] 0.1962890625 q[x1] 0.10504150390625 q[x2] 0.1962890625
gtp[x1] 0.011871337890625 gtp[x2] 0.63818359375 gtp[a] 0.63818359375
px1 tensor(0.0119, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1050, device='cuda:0') acp tensor(0.1130, device='cuda:0') r 0.3311833677299576
pp sum tensor(0.7593, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5630, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6382, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5630, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1963, device='cuda:0', dtype=torch.float16) q[a] 0.1962890625
pp sum tensor(0.7559, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1930, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6382, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1930, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4453, device='cuda:0', dtype=torch.float16)
pa tensor(0.4453, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5630, device='cuda:0', dtype=torch.float16) acp tensor(0.7910, device='cuda:0', dtype=torch.float16) r 0.6524062509813862

-------------------step: 1-------------------

directly accept a 29892

-------------------step: 2-------------------

x1 26901 x2 565 a 26901
q[a] 0.65625 q[x1] 0.65625 q[x2] 0.07598876953125
gtp[x1] 0.9326171875 gtp[x2] 0.00438690185546875 gtp[a] 0.9326171875
pp sum tensor(0.9761, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3201, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9326, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3201, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1450, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4762019747275421
q_ai sum tensor(0.6562, device='cuda:0', dtype=torch.float16) q[a] 0.65625
pp sum tensor(0.9702, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6499, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9326, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6499, device='cuda:0', dtype=torch.float16)
pa tensor(0.9326, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6499, device='cuda:0', dtype=torch.float16) acp tensor(1.4346, device='cuda:0', dtype=torch.float16) r 0.2602946210633821

-------------------step: 3-------------------

directly accept a 29875

-------------------step: 1-------------------

x1 263 x2 385 a 385
q[a] 0.603515625 q[x1] 0.395751953125 q[x2] 0.603515625
gtp[x1] 0.78857421875 gtp[x2] 0.181640625 gtp[a] 0.181640625
px1 tensor(0.7886, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3958, device='cuda:0') acp tensor(1.9926, device='cuda:0') r 0.10973701767320632

-------------------step: 2-------------------

x1 16375 x2 19781 a 19781
q[a] 0.374267578125 q[x1] 0.01953125 q[x2] 0.374267578125
gtp[x1] 0.01214599609375 gtp[x2] 0.08978271484375 gtp[a] 0.08978271484375
px1 tensor(0.0121, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0195, device='cuda:0') acp tensor(0.6219, device='cuda:0') r 0.21149507269783174

-------------------step: 3-------------------

x1 7271 x2 28970 a 7271
q[a] 0.380126953125 q[x1] 0.380126953125 q[x2] 8.940696716308594e-07
gtp[x1] 0.0046844482421875 gtp[x2] 0.0 gtp[a] 0.0046844482421875
pp sum tensor(0.9097, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5298, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0047, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5298, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(5.3644e-07, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9505296312447501
q_ai sum tensor(0.3804, device='cuda:0', dtype=torch.float16) q[a] 0.380126953125
pp sum tensor(0.8706, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3411, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0047, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3411, device='cuda:0', dtype=torch.float16)
pa tensor(0.0047, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3411, device='cuda:0', dtype=torch.float16) acp tensor(0.0137, device='cuda:0', dtype=torch.float16) r 0.9297559760588364
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8657, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 17623 x2 1737 a 17623
q[a] 0.1434326171875 q[x1] 0.1434326171875 q[x2] 0.007541656494140625
gtp[x1] 0.0020961761474609375 gtp[x2] 0.0041046142578125 gtp[a] 0.0020961761474609375
pp sum tensor(0.9766, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8325, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0021, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8325, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0013, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7325865322633448
q_ai sum tensor(0.1433, device='cuda:0', dtype=torch.float16) q[a] 0.1434326171875
pp sum tensor(0.9736, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1405, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0021, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1405, device='cuda:0', dtype=torch.float16)
pa tensor(0.0021, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1405, device='cuda:0', dtype=torch.float16) acp tensor(0.0149, device='cuda:0', dtype=torch.float16) r 0.06984118463444977
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9717, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 17623 x2 26811 a 26811
q[a] 0.306396484375 q[x1] 0.068359375 q[x2] 0.306396484375
gtp[x1] 0.0007658004760742188 gtp[x2] 0.31884765625 gtp[a] 0.31884765625
px1 tensor(0.0008, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0684, device='cuda:0') acp tensor(0.0112, device='cuda:0') r 0.6474780026182557
pp sum tensor(0.6196, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3135, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3188, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3135, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3064, device='cuda:0', dtype=torch.float16) q[a] 0.306396484375
pp sum tensor(0.5059, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1925, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3188, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1925, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1263, device='cuda:0', dtype=torch.float16)
pa tensor(0.1263, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3135, device='cuda:0', dtype=torch.float16) acp tensor(0.4031, device='cuda:0', dtype=torch.float16) r 0.9953849050204676
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1870, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 1049 x2 304 a 1049
q[a] 0.734375 q[x1] 0.734375 q[x2] 0.0012121200561523438
gtp[x1] 0.7587890625 gtp[x2] 1.3470649719238281e-05 gtp[a] 0.7587890625
pp sum tensor(0.9756, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2417, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7588, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2417, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0034, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9659687964641399
q_ai sum tensor(0.7344, device='cuda:0', dtype=torch.float16) q[a] 0.734375
pp sum tensor(0.9219, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6807, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7588, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6807, device='cuda:0', dtype=torch.float16)
pa tensor(0.7588, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6807, device='cuda:0', dtype=torch.float16) acp tensor(1.1152, device='cuda:0', dtype=torch.float16) r 0.23765483775775476

-------------------step: 2-------------------

x1 2989 x2 393 a 393
q[a] 0.405029296875 q[x1] 0.10986328125 q[x2] 0.405029296875
gtp[x1] 0.0010900497436523438 gtp[x2] 0.72509765625 gtp[a] 0.72509765625
px1 tensor(0.0011, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1099, device='cuda:0') acp tensor(0.0099, device='cuda:0') r 0.7275606335207072
pp sum tensor(0.9746, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5698, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7251, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5698, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4050, device='cuda:0', dtype=torch.float16) q[a] 0.405029296875
pp sum tensor(0.9668, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3975, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7251, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3975, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3276, device='cuda:0', dtype=torch.float16)
pa tensor(0.3276, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5698, device='cuda:0', dtype=torch.float16) acp tensor(0.5752, device='cuda:0', dtype=torch.float16) r 0.45390609463096454

-------------------step: 3-------------------

x1 16688 x2 16964 a 16688
q[a] 0.55322265625 q[x1] 0.55322265625 q[x2] 0.01148223876953125
gtp[x1] 0.5986328125 gtp[x2] 0.0088043212890625 gtp[a] 0.5986328125
pp sum tensor(0.8296, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2764, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.5986, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2764, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0142, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.460165068156127
q_ai sum tensor(0.5532, device='cuda:0', dtype=torch.float16) q[a] 0.55322265625
pp sum tensor(0.8013, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5249, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.5986, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5249, device='cuda:0', dtype=torch.float16)
pa tensor(0.5986, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5249, device='cuda:0', dtype=torch.float16) acp tensor(1.1406, device='cuda:0', dtype=torch.float16) r 0.36036469028757634

-------------------step: 1-------------------

directly accept a 363

-------------------step: 2-------------------

x1 26824 x2 1432 a 26824
q[a] 0.421875 q[x1] 0.421875 q[x2] 0.128662109375
gtp[x1] 1.633167266845703e-05 gtp[x2] 0.051788330078125 gtp[a] 1.633167266845703e-05
pp sum tensor(0.7285, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3066, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.6332e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3066, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0939, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6248510419663074
q_ai sum tensor(0.4219, device='cuda:0', dtype=torch.float16) q[a] 0.421875
pp sum tensor(0.5688, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2622, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(1.6332e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2622, device='cuda:0', dtype=torch.float16)
pa tensor(1.6332e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2622, device='cuda:0', dtype=torch.float16) acp tensor(6.2287e-05, device='cuda:0', dtype=torch.float16) r 0.8619231654146579
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5688, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29889 x2 29892 a 29889
q[a] 0.9677734375 q[x1] 0.9677734375 q[x2] 0.02459716796875
gtp[x1] 0.9931640625 gtp[x2] 0.00628662109375 gtp[a] 0.9931640625
pp sum tensor(0.9932, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0255, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9932, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0255, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7344, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.11564699616986918
q_ai sum tensor(0.9678, device='cuda:0', dtype=torch.float16) q[a] 0.9677734375
pp sum tensor(0.9932, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9678, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9932, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9678, device='cuda:0', dtype=torch.float16)
pa tensor(0.9932, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9678, device='cuda:0', dtype=torch.float16) acp tensor(1.0264, device='cuda:0', dtype=torch.float16) r 0.5044105460758062

-------------------step: 2-------------------

x1 26460 x2 960 a 26460
q[a] 0.454345703125 q[x1] 0.454345703125 q[x2] 0.044281005859375
gtp[x1] 0.1937255859375 gtp[x2] 0.00013756752014160156 gtp[a] 0.1937255859375
pp sum tensor(0.6479, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1938, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1937, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1938, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0369, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2973691899432286
q_ai sum tensor(0.4543, device='cuda:0', dtype=torch.float16) q[a] 0.454345703125
pp sum tensor(0.3667, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1729, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1937, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1729, device='cuda:0', dtype=torch.float16)
pa tensor(0.1937, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1729, device='cuda:0', dtype=torch.float16) acp tensor(1.1211, device='cuda:0', dtype=torch.float16) r 0.04910691666562017

-------------------step: 3-------------------

x1 366 x2 372 a 366
q[a] 0.9052734375 q[x1] 0.9052734375 q[x2] 0.09393310546875
gtp[x1] 0.99609375 gtp[x2] 0.0035915374755859375 gtp[a] 0.99609375
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0912, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0912, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8960, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8707877826511835
q_ai sum tensor(0.9053, device='cuda:0', dtype=torch.float16) q[a] 0.9052734375
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9048, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9048, device='cuda:0', dtype=torch.float16)
pa tensor(0.9961, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9048, device='cuda:0', dtype=torch.float16) acp tensor(1.1006, device='cuda:0', dtype=torch.float16) r 0.6668661279820313

-------------------step: 1-------------------

directly accept a 276

-------------------step: 2-------------------

x1 3063 x2 8852 a 8852
q[a] 0.37890625 q[x1] 0.237060546875 q[x2] 0.37890625
gtp[x1] 0.0081024169921875 gtp[x2] 0.96630859375 gtp[a] 0.96630859375
px1 tensor(0.0081, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2371, device='cuda:0') acp tensor(0.0342, device='cuda:0') r 0.4614161236709462
pp sum tensor(0.9692, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5903, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9663, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5903, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3789, device='cuda:0', dtype=torch.float16) q[a] 0.37890625
pp sum tensor(0.9692, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3789, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9663, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3789, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5874, device='cuda:0', dtype=torch.float16)
pa tensor(0.5874, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5903, device='cuda:0', dtype=torch.float16) acp tensor(0.9951, device='cuda:0', dtype=torch.float16) r 0.4687265414584175

-------------------step: 3-------------------

directly accept a 297

-------------------step: 1-------------------

x1 29892 x2 322 a 29892
q[a] 0.97314453125 q[x1] 0.97314453125 q[x2] 0.0183868408203125
gtp[x1] 0.98779296875 gtp[x2] 0.00910186767578125 gtp[a] 0.98779296875
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0148, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9878, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0148, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6665, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.32013506403093384
q_ai sum tensor(0.9731, device='cuda:0', dtype=torch.float16) q[a] 0.97314453125
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9731, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9878, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9731, device='cuda:0', dtype=torch.float16)
pa tensor(0.9878, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9731, device='cuda:0', dtype=torch.float16) acp tensor(1.0146, device='cuda:0', dtype=torch.float16) r 0.9714436194755827

-------------------step: 2-------------------

x1 19133 x2 278 a 278
q[a] 0.140380859375 q[x1] 0.027008056640625 q[x2] 0.140380859375
gtp[x1] 8.314847946166992e-05 gtp[x2] 0.006450653076171875 gtp[a] 0.006450653076171875
px1 tensor(8.3148e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0270, device='cuda:0') acp tensor(0.0031, device='cuda:0') r 0.25972233214535945
pp sum tensor(0.9619, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8213, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0065, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8213, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1403, device='cuda:0', dtype=torch.float16) q[a] 0.140380859375
pp sum tensor(0.9570, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1356, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0065, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1356, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8213, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6370384961457474
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9507, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29892

-------------------step: 2-------------------

x1 470 x2 367 a 470
q[a] 0.921875 q[x1] 0.921875 q[x2] 0.01421356201171875
gtp[x1] 0.97802734375 gtp[x2] 0.0008916854858398438 gtp[a] 0.97802734375
pp sum tensor(0.9810, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0593, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9780, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0593, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1674, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7783038712879994
q_ai sum tensor(0.9219, device='cuda:0', dtype=torch.float16) q[a] 0.921875
pp sum tensor(0.9780, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9189, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9780, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9189, device='cuda:0', dtype=torch.float16)
pa tensor(0.9780, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9189, device='cuda:0', dtype=torch.float16) acp tensor(1.0645, device='cuda:0', dtype=torch.float16) r 0.775937855050902

-------------------step: 3-------------------

x1 925 x2 3763 a 3763
q[a] 0.54296875 q[x1] 0.443115234375 q[x2] 0.54296875
gtp[x1] 0.35302734375 gtp[x2] 0.498046875 gtp[a] 0.498046875
px1 tensor(0.3530, device='cuda:0', dtype=torch.float16) qx1 tensor(0.4431, device='cuda:0') acp tensor(0.7967, device='cuda:0') r 0.3027934153704236

-------------------step: 1-------------------

x1 292 x2 362 a 292
q[a] 1.0 q[x1] 1.0 q[x2] 0.00013339519500732422
gtp[x1] 0.978515625 gtp[x2] 0.0212860107421875 gtp[a] 0.978515625
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(7.0870e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9785, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0211, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(7.0870e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0211, device='cuda:0', dtype=torch.float16) qx2 tensor(0.6245, device='cuda:0', dtype=torch.float16) acp tensor(0.0339, device='cuda:0', dtype=torch.float16) r 0.6424513019323441
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9785, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9790, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9785, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9790, device='cuda:0', dtype=torch.float16)
pa tensor(0.9785, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9790, device='cuda:0', dtype=torch.float16) acp tensor(0.9995, device='cuda:0', dtype=torch.float16) r 0.06890008987336316

-------------------step: 2-------------------

x1 297 x2 29892 a 29892
q[a] 0.67919921875 q[x1] 0.27880859375 q[x2] 0.67919921875
gtp[x1] 0.006565093994140625 gtp[x2] 1.6808509826660156e-05 gtp[a] 1.6808509826660156e-05
px1 tensor(0.0066, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2788, device='cuda:0') acp tensor(0.0235, device='cuda:0') r 0.4821384218150162
pp sum tensor(0.9731, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2939, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.6809e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2939, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6792, device='cuda:0', dtype=torch.float16) q[a] 0.67919921875
pp sum tensor(0.9365, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6426, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.6809e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6426, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2939, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3769782100312611
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9365, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 278 x2 263 a 278
q[a] 0.498779296875 q[x1] 0.498779296875 q[x2] 0.406982421875
gtp[x1] 0.3046875 gtp[x2] 0.64501953125 gtp[a] 0.3046875
pp sum tensor(0.5723, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0729, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3047, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2380, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0729, device='cuda:0', dtype=torch.float16)
px2 tensor(0.2380, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4050, device='cuda:0', dtype=torch.float16) acp tensor(0.5879, device='cuda:0', dtype=torch.float16) r 0.11278896610109634

-------------------step: 2-------------------

x1 25695 x2 9560 a 25695
q[a] 0.7021484375 q[x1] 0.7021484375 q[x2] 0.0865478515625
gtp[x1] 0.0179290771484375 gtp[x2] 0.79931640625 gtp[a] 0.0179290771484375
pp sum tensor(0.8608, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1583, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0179, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7129, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1583, device='cuda:0', dtype=torch.float16)
px2 tensor(0.7129, device='cuda:0', dtype=torch.float16) qx2 tensor(0.2040, device='cuda:0', dtype=torch.float16) acp tensor(3.4941, device='cuda:0', dtype=torch.float16) r 0.4100427758598668

-------------------step: 3-------------------

x1 6575 x2 25695 a 25695
q[a] 0.845703125 q[x1] 0.0455322265625 q[x2] 0.845703125
gtp[x1] 2.8014183044433594e-06 gtp[x2] 0.9990234375 gtp[a] 0.9990234375
px1 tensor(2.8014e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0455, device='cuda:0') acp tensor(6.1526e-05, device='cuda:0') r 0.06715724496551456
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1530, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1530, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8457, device='cuda:0', dtype=torch.float16) q[a] 0.845703125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8457, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8457, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1533, device='cuda:0', dtype=torch.float16)
pa tensor(0.1533, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1530, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.4202227734328302

-------------------step: 1-------------------

x1 367 x2 26901 a 26901
q[a] 0.6904296875 q[x1] 0.0006151199340820312 q[x2] 0.6904296875
gtp[x1] 4.023313522338867e-05 gtp[x2] 0.1514892578125 gtp[a] 0.1514892578125
px1 tensor(4.0233e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0006, device='cuda:0') acp tensor(0.0654, device='cuda:0') r 0.3986673300734621
pp sum tensor(0.8706, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1798, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1515, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1798, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6904, device='cuda:0', dtype=torch.float16) q[a] 0.6904296875
pp sum tensor(0.7651, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5850, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1515, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5850, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1798, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.35846381230502355
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6138, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 2058 x2 11359 a 11359
q[a] 0.3583984375 q[x1] 0.0236358642578125 q[x2] 0.3583984375
gtp[x1] 8.511543273925781e-05 gtp[x2] 0.728515625 gtp[a] 0.728515625
px1 tensor(8.5115e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0236, device='cuda:0') acp tensor(0.0036, device='cuda:0') r 0.10370065056449163
pp sum tensor(0.8887, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5303, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7285, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5303, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3586, device='cuda:0', dtype=torch.float16) q[a] 0.3583984375
pp sum tensor(0.8506, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3203, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7285, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3203, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4082, device='cuda:0', dtype=torch.float16)
pa tensor(0.4082, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5303, device='cuda:0', dtype=torch.float16) acp tensor(0.7700, device='cuda:0', dtype=torch.float16) r 0.9835687845517458
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1220, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 2106 x2 11359 a 2106
q[a] 0.564453125 q[x1] 0.564453125 q[x2] 0.195068359375
gtp[x1] 4.309415817260742e-05 gtp[x2] 0.0008935928344726562 gtp[a] 4.309415817260742e-05
pp sum tensor(0.7876, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2230, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(4.3094e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2230, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2527, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.30375547031703576
q_ai sum tensor(0.5645, device='cuda:0', dtype=torch.float16) q[a] 0.564453125
pp sum tensor(0.5146, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2910, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(4.3094e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2910, device='cuda:0', dtype=torch.float16)
pa tensor(4.3094e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2910, device='cuda:0', dtype=torch.float16) acp tensor(0.0001, device='cuda:0', dtype=torch.float16) r 0.4812944589213739
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5146, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 895

-------------------step: 2-------------------

x1 338 x2 756 a 338
q[a] 0.556640625 q[x1] 0.556640625 q[x2] 0.302734375
gtp[x1] 0.279541015625 gtp[x2] 0.70263671875 gtp[a] 0.279541015625
pp sum tensor(0.6846, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1279, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2795, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3999, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1279, device='cuda:0', dtype=torch.float16)
px2 tensor(0.3999, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3801, device='cuda:0', dtype=torch.float16) acp tensor(1.0518, device='cuda:0', dtype=torch.float16) r 0.5389661073039914

-------------------step: 3-------------------

x1 263 x2 1554 a 1554
q[a] 0.53076171875 q[x1] 0.1983642578125 q[x2] 0.53076171875
gtp[x1] 0.0009336471557617188 gtp[x2] 0.337646484375 gtp[a] 0.337646484375
px1 tensor(0.0009, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1984, device='cuda:0') acp tensor(0.0047, device='cuda:0') r 0.10952343493072247
pp sum tensor(0.9521, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4214, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3376, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4214, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5308, device='cuda:0', dtype=torch.float16) q[a] 0.53076171875
pp sum tensor(0.9434, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5225, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3376, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5225, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4214, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3387782416599906
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6060, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 599

-------------------step: 2-------------------

x1 363 x2 304 a 363
q[a] 0.515625 q[x1] 0.515625 q[x2] 0.15478515625
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4834, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4834, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1649, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.27930285370388874
q_ai sum tensor(0.5156, device='cuda:0', dtype=torch.float16) q[a] 0.515625
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5146, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5146, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5146, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6655965437894116
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9980, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 2973 x2 1105 a 1105
q[a] 0.6298828125 q[x1] 0.039031982421875 q[x2] 0.6298828125
gtp[x1] 0.003398895263671875 gtp[x2] 0.80615234375 gtp[a] 0.80615234375
px1 tensor(0.0034, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0390, device='cuda:0') acp tensor(0.0871, device='cuda:0') r 0.23414315551484233
pp sum tensor(0.9448, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3145, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8062, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3145, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6299, device='cuda:0', dtype=torch.float16) q[a] 0.6298828125
pp sum tensor(0.9355, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6206, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8062, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6206, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1855, device='cuda:0', dtype=torch.float16)
pa tensor(0.1855, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3145, device='cuda:0', dtype=torch.float16) acp tensor(0.5898, device='cuda:0', dtype=torch.float16) r 0.8773284820545483
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1294, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 4966 x2 19781 a 4966
q[a] 0.599609375 q[x1] 0.599609375 q[x2] 0.0013856887817382812
gtp[x1] 0.053436279296875 gtp[x2] 0.0001283884048461914 gtp[a] 0.053436279296875
pp sum tensor(0.8276, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2279, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0534, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2279, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0021, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6201097423478991
q_ai sum tensor(0.5996, device='cuda:0', dtype=torch.float16) q[a] 0.599609375
pp sum tensor(0.6753, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4470, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0534, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4470, device='cuda:0', dtype=torch.float16)
pa tensor(0.0534, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4470, device='cuda:0', dtype=torch.float16) acp tensor(0.1196, device='cuda:0', dtype=torch.float16) r 0.5779239946042862
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6221, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 6907 x2 27878 a 6907
q[a] 0.69140625 q[x1] 0.69140625 q[x2] 0.0013341903686523438
gtp[x1] 0.98583984375 gtp[x2] 5.245208740234375e-06 gtp[a] 0.98583984375
pp sum tensor(0.9858, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2944, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9858, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2944, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0030, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.0222540282720759
q_ai sum tensor(0.6914, device='cuda:0', dtype=torch.float16) q[a] 0.69140625
pp sum tensor(0.9858, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6914, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9858, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6914, device='cuda:0', dtype=torch.float16)
pa tensor(0.9858, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6914, device='cuda:0', dtype=torch.float16) acp tensor(1.4258, device='cuda:0', dtype=torch.float16) r 0.5159487784165703

-------------------step: 2-------------------

x1 6493 x2 9850 a 6493
q[a] 0.427490234375 q[x1] 0.427490234375 q[x2] 0.046875
gtp[x1] 0.0185546875 gtp[x2] 2.47955322265625e-05 gtp[a] 0.0185546875
pp sum tensor(0.9668, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5396, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0186, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5396, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0350, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6518823555454558
q_ai sum tensor(0.4275, device='cuda:0', dtype=torch.float16) q[a] 0.427490234375
pp sum tensor(0.9561, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4170, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0186, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4170, device='cuda:0', dtype=torch.float16)
pa tensor(0.0186, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4170, device='cuda:0', dtype=torch.float16) acp tensor(0.0445, device='cuda:0', dtype=torch.float16) r 0.25279822537164975
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9375, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 304 x2 263 a 263
q[a] 0.82177734375 q[x1] 0.083984375 q[x2] 0.82177734375
gtp[x1] 1.7285346984863281e-06 gtp[x2] 0.00789642333984375 gtp[a] 0.00789642333984375
px1 tensor(1.7285e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0840, device='cuda:0') acp tensor(2.0582e-05, device='cuda:0') r 0.5546801078023778
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1770, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0079, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1770, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8218, device='cuda:0', dtype=torch.float16) q[a] 0.82177734375
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8188, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0079, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8188, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1770, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.02942925499006699
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9873, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 304

-------------------step: 2-------------------

x1 26901 x2 278 a 26901
q[a] 0.71142578125 q[x1] 0.71142578125 q[x2] 0.1771240234375
gtp[x1] 0.0 gtp[x2] 2.980232238769531e-07 gtp[a] 0.0
pp sum tensor(0.8975, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1857, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1857, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4370, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.13932343425833194
q_ai sum tensor(0.7114, device='cuda:0', dtype=torch.float16) q[a] 0.71142578125
pp sum tensor(0.6445, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4583, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4583, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4583, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9409660791606489
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6445, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 9850 x2 2446 a 2446
q[a] 0.369140625 q[x1] 0.220458984375 q[x2] 0.369140625
gtp[x1] 0.79931640625 gtp[x2] 0.00019621849060058594 gtp[a] 0.00019621849060058594
px1 tensor(0.7993, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2205, device='cuda:0') acp tensor(3.6257, device='cuda:0') r 0.6279742628280592

-------------------step: 2-------------------

x1 364 x2 20968 a 20968
q[a] 0.40185546875 q[x1] 0.0008931159973144531 q[x2] 0.40185546875
gtp[x1] 0.0 gtp[x2] 0.94189453125 gtp[a] 0.94189453125
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0009, device='cuda:0') acp tensor(0., device='cuda:0') r 0.18813959448576112
pp sum tensor(0.9507, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5483, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9419, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5483, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4019, device='cuda:0', dtype=torch.float16) q[a] 0.40185546875
pp sum tensor(0.9458, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3972, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9419, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3972, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5449, device='cuda:0', dtype=torch.float16)
pa tensor(0.5449, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5483, device='cuda:0', dtype=torch.float16) acp tensor(0.9937, device='cuda:0', dtype=torch.float16) r 0.2340609682906034

-------------------step: 3-------------------

x1 363 x2 322 a 363
q[a] 0.60693359375 q[x1] 0.60693359375 q[x2] 0.2303466796875
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.3928, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3928, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3560, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.513216414493711
q_ai sum tensor(0.6069, device='cuda:0', dtype=torch.float16) q[a] 0.60693359375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.6069, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6069, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6069, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4808530060635783
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(1., device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 322 x2 29892 a 322
q[a] 0.53271484375 q[x1] 0.53271484375 q[x2] 0.280517578125
gtp[x1] 0.164306640625 gtp[x2] 0.80908203125 gtp[a] 0.164306640625
pp sum tensor(0.7031, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1704, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1643, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5283, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1704, device='cuda:0', dtype=torch.float16)
px2 tensor(0.5283, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3198, device='cuda:0', dtype=torch.float16) acp tensor(1.6523, device='cuda:0', dtype=torch.float16) r 0.31300255405419963

-------------------step: 2-------------------

x1 322 x2 2 a 322
q[a] 0.9970703125 q[x1] 0.9970703125 q[x2] 0.0002906322479248047
gtp[x1] 0.99755859375 gtp[x2] 1.6510486602783203e-05 gtp[a] 0.99755859375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0022, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0022, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1015, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2624957070941174
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16) q[a] 0.9970703125
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9956, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9956, device='cuda:0', dtype=torch.float16)
pa tensor(0.9976, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9956, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.30450533696782545

-------------------step: 3-------------------

x1 372 x2 306 a 306
q[a] 0.47900390625 q[x1] 0.07177734375 q[x2] 0.47900390625
gtp[x1] 4.4226646423339844e-05 gtp[x2] 0.89453125 gtp[a] 0.89453125
px1 tensor(4.4227e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0718, device='cuda:0') acp tensor(0.0006, device='cuda:0') r 0.036611245202634146
pp sum tensor(0.9653, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4861, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8945, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4861, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4792, device='cuda:0', dtype=torch.float16) q[a] 0.47900390625
pp sum tensor(0.9609, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4749, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8945, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4749, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4197, device='cuda:0', dtype=torch.float16)
pa tensor(0.4197, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4861, device='cuda:0', dtype=torch.float16) acp tensor(0.8633, device='cuda:0', dtype=torch.float16) r 0.15116807005307953

-------------------step: 1-------------------

x1 366 x2 372 a 366
q[a] 0.77197265625 q[x1] 0.77197265625 q[x2] 0.029937744140625
gtp[x1] 0.014434814453125 gtp[x2] 1.2516975402832031e-06 gtp[a] 0.014434814453125
pp sum tensor(0.9453, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1735, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0144, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1735, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1015, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9212494954266237
q_ai sum tensor(0.7720, device='cuda:0', dtype=torch.float16) q[a] 0.77197265625
pp sum tensor(0.7671, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5938, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0144, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5938, device='cuda:0', dtype=torch.float16)
pa tensor(0.0144, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5938, device='cuda:0', dtype=torch.float16) acp tensor(0.0243, device='cuda:0', dtype=torch.float16) r 0.5983721013169736
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7529, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 4274 x2 1400 a 1400
q[a] 0.181396484375 q[x1] 0.060302734375 q[x2] 0.181396484375
gtp[x1] 0.017791748046875 gtp[x2] 0.405029296875 gtp[a] 0.405029296875
px1 tensor(0.0178, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0603, device='cuda:0') acp tensor(0.2950, device='cuda:0') r 0.686568553009688
pp sum tensor(0.8130, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6313, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4050, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6313, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1813, device='cuda:0', dtype=torch.float16) q[a] 0.181396484375
pp sum tensor(0.7944, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1628, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4050, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1628, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2422, device='cuda:0', dtype=torch.float16)
pa tensor(0.2422, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6313, device='cuda:0', dtype=torch.float16) acp tensor(0.3835, device='cuda:0', dtype=torch.float16) r 0.963318918609326
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3894, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 1400

-------------------step: 2-------------------

x1 674 x2 4076 a 674
q[a] 0.72705078125 q[x1] 0.72705078125 q[x2] 0.01763916015625
gtp[x1] 0.00042319297790527344 gtp[x2] 0.0032253265380859375 gtp[a] 0.00042319297790527344
pp sum tensor(0.9395, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2125, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0004, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2125, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0469, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3076575417005639
q_ai sum tensor(0.7271, device='cuda:0', dtype=torch.float16) q[a] 0.72705078125
pp sum tensor(0.8237, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6113, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0004, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6113, device='cuda:0', dtype=torch.float16)
pa tensor(0.0004, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6113, device='cuda:0', dtype=torch.float16) acp tensor(0.0007, device='cuda:0', dtype=torch.float16) r 0.8510829927945296
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8232, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 20603 x2 4944 a 20603
q[a] 0.64599609375 q[x1] 0.64599609375 q[x2] 0.0400390625
gtp[x1] 0.86181640625 gtp[x2] 0.01019287109375 gtp[a] 0.86181640625
pp sum tensor(0.8887, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2424, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8618, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2424, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0730, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9839868180813848
q_ai sum tensor(0.6460, device='cuda:0', dtype=torch.float16) q[a] 0.64599609375
pp sum tensor(0.8804, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6377, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8618, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6377, device='cuda:0', dtype=torch.float16)
pa tensor(0.8618, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6377, device='cuda:0', dtype=torch.float16) acp tensor(1.3516, device='cuda:0', dtype=torch.float16) r 0.7891991725207352

-------------------step: 2-------------------

x1 366 x2 2 a 366
q[a] 0.98974609375 q[x1] 0.98974609375 q[x2] 0.0026531219482421875
gtp[x1] 0.9990234375 gtp[x2] 0.0003249645233154297 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0096, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0096, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2529, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7380093467622637
q_ai sum tensor(0.9897, device='cuda:0', dtype=torch.float16) q[a] 0.98974609375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9897, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9897, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9897, device='cuda:0', dtype=torch.float16) acp tensor(1.0098, device='cuda:0', dtype=torch.float16) r 0.33226631969543163

-------------------step: 3-------------------

directly accept a 304

-------------------step: 1-------------------

x1 901 x2 278 a 278
q[a] 0.775390625 q[x1] 0.002468109130859375 q[x2] 0.775390625
gtp[x1] 5.960464477539063e-08 gtp[x2] 0.00655364990234375 gtp[a] 0.00655364990234375
px1 tensor(5.9605e-08, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0025, device='cuda:0') acp tensor(2.4150e-05, device='cuda:0') r 0.022926096164578302
pp sum tensor(0.9302, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1545, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0066, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1545, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7754, device='cuda:0', dtype=torch.float16) q[a] 0.775390625
pp sum tensor(0.8340, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6792, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0066, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6792, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1545, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.35163256629560924
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8276, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 29991 x2 29889 a 29889
q[a] 0.60400390625 q[x1] 0.39013671875 q[x2] 0.60400390625
gtp[x1] 0.5087890625 gtp[x2] 0.4853515625 gtp[a] 0.4853515625
px1 tensor(0.5088, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3901, device='cuda:0') acp tensor(1.3041, device='cuda:0') r 0.3906064345880157

-------------------step: 2-------------------

x1 2 x2 13 a 2
q[a] 0.76025390625 q[x1] 0.76025390625 q[x2] 0.2177734375
gtp[x1] 0.6259765625 gtp[x2] 0.0224456787109375 gtp[a] 0.6259765625
pp sum tensor(0.9736, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2137, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6260, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2137, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6899, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.731208268720289
q_ai sum tensor(0.7598, device='cuda:0', dtype=torch.float16) q[a] 0.76025390625
pp sum tensor(0.9707, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7568, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.6260, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7568, device='cuda:0', dtype=torch.float16)
pa tensor(0.6260, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7568, device='cuda:0', dtype=torch.float16) acp tensor(0.8271, device='cuda:0', dtype=torch.float16) r 0.3256966822294646

-------------------step: 3-------------------

directly accept a 1

Output:
 Aloha travelers! I recently embarked on a once-in-a-lifetime trip to the beautiful state of Hawaii, and let me tell you, it was an experience I'll never forget. From breathtaking beaches to cultural experiences that truly showcase the island's rich history and traditions, Hawaii has something for everyone.

One of the top places to visit in Hawaii is the Pearl Harbor National Monument. This historical site is a must-see for anyone interested in World War II history. The attack on Pearl Harbor on December 7, 1941, was a pivotal moment in U.S. history, and this memorial serves as a somber reminder of that fateful day. The spot is marked by the USS Arizona Memorial, a somber and humbling experience that honors the 1,177 sailors and Marines who lost their lives during the attack.

For a more cultural experience, visit the Iolani Palace, the only former royal palace in the United States. This stunning palace was the official residence of the Hawaiian monarchs from 1845 to 1893, and serves as a fascinating look into Hawaii's history and the lives of its royal families. Don't miss the opportunity to take a tour of the palace, and learn about the state's rich past from knowledgeable and passionate guides.

But Hawaii isn't all history and monuments. The island's natural beauty is simply stunning, with miles of pristine beaches, lush rainforests, and towering waterfalls. One of the top beaches to visit in Hawaii is Waikiki Beach, with its crystal-clear waters and soft, white sand. Take a stroll along the beach, grab a pastry and coffee from a local vendor, and watch the sun rise over the sparkling waters of the Pacific.

For a more adventurous experience, hike to the top of Diamond Head, an ancient volcanic crater located on the outskirts of Waikiki. The 1.6-mile hike to the top is challenging but thoroughly rewarding, with panoramic views of Honolulu and the ocean beyond. Be sure to start your hike early in the morning to avoid the hot and crowded conditions that can occur later in the day.

In summary, Hawaii is a cultural and natural wonderland that offers something for everyone. Whether you're interested in history, nature, or just relaxing on a beautiful beach, this tropical paradise has it all. I highly recommend adding it to your travel bucket list, and I hope this blog post has inspired you to do so!</s><s> 


-------------------step: 1-------------------

x1 29892 x2 13283 a 29892
q[a] 0.7421875 q[x1] 0.7421875 q[x2] 1.4901161193847656e-06
gtp[x1] 0.93408203125 gtp[x2] 0.0 gtp[a] 0.93408203125
pp sum tensor(0.9873, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2454, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9341, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2454, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(4.2915e-06, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.25385644802330765
q_ai sum tensor(0.7422, device='cuda:0', dtype=torch.float16) q[a] 0.7421875
pp sum tensor(0.9702, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7251, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9341, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7251, device='cuda:0', dtype=torch.float16)
pa tensor(0.9341, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7251, device='cuda:0', dtype=torch.float16) acp tensor(1.2881, device='cuda:0', dtype=torch.float16) r 0.4122029084014184

-------------------step: 2-------------------

x1 363 x2 306 a 306
q[a] 0.280029296875 q[x1] 0.00292205810546875 q[x2] 0.280029296875
gtp[x1] 4.076957702636719e-05 gtp[x2] 0.014739990234375 gtp[a] 0.014739990234375
px1 tensor(4.0770e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0029, device='cuda:0') acp tensor(0.0140, device='cuda:0') r 0.9216258770296578
pp sum tensor(0.9473, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6670, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0147, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6670, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2800, device='cuda:0', dtype=torch.float16) q[a] 0.280029296875
pp sum tensor(0.9424, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2747, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0147, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2747, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6670, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7625604689605151
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9272, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29875

-------------------step: 2-------------------

x1 29892 x2 338 a 29892
q[a] 0.45654296875 q[x1] 0.45654296875 q[x2] 0.04278564453125
gtp[x1] 0.418212890625 gtp[x2] 0.014312744140625 gtp[a] 0.418212890625
pp sum tensor(0.8164, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3599, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4182, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3599, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0359, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.13512057240533804
q_ai sum tensor(0.4565, device='cuda:0', dtype=torch.float16) q[a] 0.45654296875
pp sum tensor(0.7915, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4319, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4182, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4319, device='cuda:0', dtype=torch.float16)
pa tensor(0.4182, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4319, device='cuda:0', dtype=torch.float16) acp tensor(0.9683, device='cuda:0', dtype=torch.float16) r 0.54087112902912

-------------------step: 3-------------------

x1 263 x2 278 a 263
q[a] 0.83056640625 q[x1] 0.83056640625 q[x2] 0.030731201171875
gtp[x1] 0.74267578125 gtp[x2] 0.14404296875 gtp[a] 0.74267578125
pp sum tensor(0.9385, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1078, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7427, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1133, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1078, device='cuda:0', dtype=torch.float16)
px2 tensor(0.1133, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1509, device='cuda:0', dtype=torch.float16) acp tensor(0.7510, device='cuda:0', dtype=torch.float16) r 0.9986594679158249
q_ai sum tensor(0.8306, device='cuda:0', dtype=torch.float16) q[a] 0.83056640625
pp sum tensor(0.7939, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6860, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7427, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6860, device='cuda:0', dtype=torch.float16)
pa tensor(0.7427, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6860, device='cuda:0', dtype=torch.float16) acp tensor(1.0830, device='cuda:0', dtype=torch.float16) r 0.3119520634626872

-------------------step: 1-------------------

x1 322 x2 26811 a 322
q[a] 0.52685546875 q[x1] 0.52685546875 q[x2] 0.0701904296875
gtp[x1] 0.41259765625 gtp[x2] 0.047760009765625 gtp[a] 0.41259765625
pp sum tensor(0.6802, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1534, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4126, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1534, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0781, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9585282795417992
q_ai sum tensor(0.5269, device='cuda:0', dtype=torch.float16) q[a] 0.52685546875
pp sum tensor(0.5366, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3828, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4126, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3828, device='cuda:0', dtype=torch.float16)
pa tensor(0.4126, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3828, device='cuda:0', dtype=torch.float16) acp tensor(1.0781, device='cuda:0', dtype=torch.float16) r 0.770267753205117

-------------------step: 2-------------------

x1 16984 x2 16375 a 16984
q[a] 0.11138916015625 q[x1] 0.11138916015625 q[x2] 0.0190582275390625
gtp[x1] 0.170166015625 gtp[x2] 0.1346435546875 gtp[a] 0.170166015625
pp sum tensor(0.7168, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6050, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1702, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1156, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6050, device='cuda:0', dtype=torch.float16)
px2 tensor(0.1156, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0024, device='cuda:0', dtype=torch.float16) acp tensor(48.4062, device='cuda:0', dtype=torch.float16) r 0.012611609354688524

-------------------step: 3-------------------

x1 26811 x2 3190 a 26811
q[a] 0.865234375 q[x1] 0.865234375 q[x2] 0.0012025833129882812
gtp[x1] 0.658203125 gtp[x2] 0.00551605224609375 gtp[a] 0.658203125
pp sum tensor(0.9209, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0553, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6582, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0043, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0553, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0043, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0077, device='cuda:0', dtype=torch.float16) acp tensor(0.5581, device='cuda:0', dtype=torch.float16) r 0.4178866153354778

-------------------step: 1-------------------

directly accept a 295

-------------------step: 2-------------------

x1 411 x2 310 a 310
q[a] 0.481689453125 q[x1] 0.14013671875 q[x2] 0.481689453125
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.1401, device='cuda:0') acp tensor(0., device='cuda:0') r 0.08101415015612345
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.5181, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5181, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4817, device='cuda:0', dtype=torch.float16) q[a] 0.481689453125
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.4817, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4817, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5181, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.31887861260548533
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(1., device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 310 x2 274 a 310
q[a] 0.499267578125 q[x1] 0.499267578125 q[x2] 3.74913215637207e-05
gtp[x1] 0.0162200927734375 gtp[x2] 5.0067901611328125e-06 gtp[a] 0.0162200927734375
pp sum tensor(0.7578, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2585, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0162, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2585, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(3.7551e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.47582922144136286
q_ai sum tensor(0.4993, device='cuda:0', dtype=torch.float16) q[a] 0.499267578125
pp sum tensor(0.5522, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2937, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0162, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2937, device='cuda:0', dtype=torch.float16)
pa tensor(0.0162, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2937, device='cuda:0', dtype=torch.float16) acp tensor(0.0552, device='cuda:0', dtype=torch.float16) r 0.0767032498929463
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5361, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 297 x2 373 a 297
q[a] 0.9423828125 q[x1] 0.9423828125 q[x2] 0.03326416015625
gtp[x1] 0.99267578125 gtp[x2] 0.0004551410675048828 gtp[a] 0.99267578125
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0547, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9927, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0547, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5459, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3005433011271249
q_ai sum tensor(0.9424, device='cuda:0', dtype=torch.float16) q[a] 0.9423828125
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9409, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9927, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9409, device='cuda:0', dtype=torch.float16)
pa tensor(0.9927, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9409, device='cuda:0', dtype=torch.float16) acp tensor(1.0547, device='cuda:0', dtype=torch.float16) r 0.4943807555450346

-------------------step: 2-------------------

x1 278 x2 697 a 278
q[a] 0.85107421875 q[x1] 0.85107421875 q[x2] 0.040740966796875
gtp[x1] 0.99755859375 gtp[x2] 2.980232238769531e-07 gtp[a] 0.99755859375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1486, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1486, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2325, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8410400319653775
q_ai sum tensor(0.8511, device='cuda:0', dtype=torch.float16) q[a] 0.85107421875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8506, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8506, device='cuda:0', dtype=torch.float16)
pa tensor(0.9976, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8506, device='cuda:0', dtype=torch.float16) acp tensor(1.1729, device='cuda:0', dtype=torch.float16) r 0.8069334959842309

-------------------step: 3-------------------

x1 6641 x2 5192 a 5192
q[a] 0.7734375 q[x1] 0.0018873214721679688 q[x2] 0.7734375
gtp[x1] 0.0008592605590820312 gtp[x2] 0.01140594482421875 gtp[a] 0.01140594482421875
px1 tensor(0.0009, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0019, device='cuda:0') acp tensor(0.4553, device='cuda:0') r 0.17512549692897872

-------------------step: 1-------------------

x1 14328 x2 1196 a 14328
q[a] 0.74072265625 q[x1] 0.74072265625 q[x2] 0.00013148784637451172
gtp[x1] 0.9951171875 gtp[x2] 0.0 gtp[a] 0.9951171875
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2542, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9951, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2542, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0004, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4693313379397025
q_ai sum tensor(0.7407, device='cuda:0', dtype=torch.float16) q[a] 0.74072265625
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7407, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9951, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7407, device='cuda:0', dtype=torch.float16)
pa tensor(0.9951, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7407, device='cuda:0', dtype=torch.float16) acp tensor(1.3438, device='cuda:0', dtype=torch.float16) r 0.6211598134881365

-------------------step: 2-------------------

x1 13267 x2 310 a 310
q[a] 0.55126953125 q[x1] 4.1604042053222656e-05 q[x2] 0.55126953125
gtp[x1] 0.0 gtp[x2] 5.543231964111328e-06 gtp[a] 5.543231964111328e-06
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(4.1604e-05, device='cuda:0') acp tensor(0., device='cuda:0') r 0.48707513968214733
pp sum tensor(0.5933, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0426, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(5.5432e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0426, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5513, device='cuda:0', dtype=torch.float16) q[a] 0.55126953125
pp sum tensor(0.1085, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0663, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(5.5432e-06, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0663, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.0426, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5943341120547437
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1085, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29889 x2 29892 a 29889
q[a] 0.7626953125 q[x1] 0.7626953125 q[x2] 0.1649169921875
gtp[x1] 0.87939453125 gtp[x2] 0.1033935546875 gtp[a] 0.87939453125
pp sum tensor(0.8799, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1169, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8794, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1169, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5303, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2868149555185684
q_ai sum tensor(0.7627, device='cuda:0', dtype=torch.float16) q[a] 0.7626953125
pp sum tensor(0.8799, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7622, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8794, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7622, device='cuda:0', dtype=torch.float16)
pa tensor(0.8794, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7622, device='cuda:0', dtype=torch.float16) acp tensor(1.1533, device='cuda:0', dtype=torch.float16) r 0.14652264144754468

-------------------step: 2-------------------

x1 1619 x2 910 a 910
q[a] 0.29345703125 q[x1] 0.0155487060546875 q[x2] 0.29345703125
gtp[x1] 0.0007085800170898438 gtp[x2] 0.046295166015625 gtp[a] 0.046295166015625
px1 tensor(0.0007, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0155, device='cuda:0') acp tensor(0.0456, device='cuda:0') r 0.9644781054051782
pp sum tensor(0.6230, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3296, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0463, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3296, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2935, device='cuda:0', dtype=torch.float16) q[a] 0.29345703125
pp sum tensor(0.5884, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2588, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0463, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2588, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3296, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9267874593648711
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5420, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 776

-------------------step: 2-------------------

x1 373 x2 29892 a 29892
q[a] 0.50634765625 q[x1] 0.1077880859375 q[x2] 0.50634765625
gtp[x1] 1.1920928955078125e-07 gtp[x2] 1.6570091247558594e-05 gtp[a] 1.6570091247558594e-05
px1 tensor(1.1921e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1078, device='cuda:0') acp tensor(1.1060e-06, device='cuda:0') r 0.2658015966843643
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4802, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.6570e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4802, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5063, device='cuda:0', dtype=torch.float16) q[a] 0.50634765625
pp sum tensor(0.9795, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4998, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.6570e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4998, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4802, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8524854511989621
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9795, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 967 x2 2 a 967
q[a] 0.9970703125 q[x1] 0.9970703125 q[x2] 0.00035881996154785156
gtp[x1] 0.9970703125 gtp[x2] 0.00018477439880371094 gtp[a] 0.9970703125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0020, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9971, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0020, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1287, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4669011956682957
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16) q[a] 0.9970703125
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9951, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9971, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9951, device='cuda:0', dtype=torch.float16)
pa tensor(0.9971, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9951, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.32059725970453257

-------------------step: 2-------------------

x1 10067 x2 2078 a 2078
q[a] 0.197998046875 q[x1] 0.078125 q[x2] 0.197998046875
gtp[x1] 0.0017757415771484375 gtp[x2] 0.09393310546875 gtp[a] 0.09393310546875
px1 tensor(0.0018, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0781, device='cuda:0') acp tensor(0.0227, device='cuda:0') r 0.14686323839808357
pp sum tensor(0.7793, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5815, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0939, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5815, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1980, device='cuda:0', dtype=torch.float16) q[a] 0.197998046875
pp sum tensor(0.7427, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1610, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0939, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1610, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5815, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5182120492976116
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6484, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 27389

-------------------step: 2-------------------

x1 367 x2 5613 a 367
q[a] 0.83056640625 q[x1] 0.83056640625 q[x2] 0.0772705078125
gtp[x1] 0.7802734375 gtp[x2] 0.1273193359375 gtp[a] 0.7802734375
pp sum tensor(0.8931, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0622, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7803, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0500, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0622, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0500, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3792, device='cuda:0', dtype=torch.float16) acp tensor(0.1320, device='cuda:0', dtype=torch.float16) r 0.5699244585115739
q_ai sum tensor(0.8306, device='cuda:0', dtype=torch.float16) q[a] 0.83056640625
pp sum tensor(0.7930, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7305, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7803, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7305, device='cuda:0', dtype=torch.float16)
pa tensor(0.7803, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7305, device='cuda:0', dtype=torch.float16) acp tensor(1.0684, device='cuda:0', dtype=torch.float16) r 0.23169594987922215

-------------------step: 3-------------------

directly accept a 14520

-------------------step: 1-------------------

x1 301 x2 2078 a 301
q[a] 0.4990234375 q[x1] 0.4990234375 q[x2] 0.03424072265625
gtp[x1] 0.794921875 gtp[x2] 0.019744873046875 gtp[a] 0.794921875
pp sum tensor(0.8447, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3457, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7949, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3457, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0341, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.27828339394655455
q_ai sum tensor(0.4990, device='cuda:0', dtype=torch.float16) q[a] 0.4990234375
pp sum tensor(0.8125, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4668, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7949, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4668, device='cuda:0', dtype=torch.float16)
pa tensor(0.7949, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4668, device='cuda:0', dtype=torch.float16) acp tensor(1.7031, device='cuda:0', dtype=torch.float16) r 0.3023506541641262

-------------------step: 2-------------------

x1 1878 x2 3598 a 1878
q[a] 0.94775390625 q[x1] 0.94775390625 q[x2] 0.0367431640625
gtp[x1] 0.9990234375 gtp[x2] 0.0003457069396972656 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0509, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0509, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6694, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4215990896970355
q_ai sum tensor(0.9473, device='cuda:0', dtype=torch.float16) q[a] 0.94775390625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9473, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9473, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9473, device='cuda:0', dtype=torch.float16) acp tensor(1.0547, device='cuda:0', dtype=torch.float16) r 0.9319551658986367

-------------------step: 3-------------------

x1 25695 x2 2982 a 2982
q[a] 0.18701171875 q[x1] 0.00041556358337402344 q[x2] 0.18701171875
gtp[x1] 5.960464477539063e-08 gtp[x2] 0.0986328125 gtp[a] 0.0986328125
px1 tensor(5.9605e-08, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0004, device='cuda:0') acp tensor(0.0001, device='cuda:0') r 0.37789988354653437
pp sum tensor(0.8125, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6260, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0986, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6260, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1870, device='cuda:0', dtype=torch.float16) q[a] 0.18701171875
pp sum tensor(0.7861, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1606, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0986, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1606, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6260, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6922241073001055
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6875, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 1454 x2 363 a 1454
q[a] 0.98779296875 q[x1] 0.98779296875 q[x2] 0.011322021484375
gtp[x1] 0.99853515625 gtp[x2] 0.0015726089477539062 gtp[a] 0.99853515625
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0104, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0104, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9238, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.14483016281201788
q_ai sum tensor(0.9878, device='cuda:0', dtype=torch.float16) q[a] 0.98779296875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9878, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9878, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9878, device='cuda:0', dtype=torch.float16) acp tensor(1.0107, device='cuda:0', dtype=torch.float16) r 0.7817376689073064

-------------------step: 2-------------------

x1 9197 x2 342 a 9197
q[a] 0.99755859375 q[x1] 0.99755859375 q[x2] 0.0019254684448242188
gtp[x1] 0.998046875 gtp[x2] 0.0016222000122070312 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0006, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0006, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7954, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6080512598554664
q_ai sum tensor(0.9976, device='cuda:0', dtype=torch.float16) q[a] 0.99755859375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9976, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9976, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9976, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.08108589755646567

-------------------step: 3-------------------

x1 29892 x2 322 a 29892
q[a] 0.98779296875 q[x1] 0.98779296875 q[x2] 0.01186370849609375
gtp[x1] 0.9560546875 gtp[x2] 0.04266357421875 gtp[a] 0.9560546875
pp sum tensor(0.9873, device='cuda:0', dtype=torch.float16) qp sum tensor(2.9683e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9561, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0308, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(2.9683e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0308, device='cuda:0', dtype=torch.float16) qx2 tensor(0.9487, device='cuda:0', dtype=torch.float16) acp tensor(0.0325, device='cuda:0', dtype=torch.float16) r 0.8229240060834997
q_ai sum tensor(0.9878, device='cuda:0', dtype=torch.float16) q[a] 0.98779296875
pp sum tensor(0.9561, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9565, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9561, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9565, device='cuda:0', dtype=torch.float16)
pa tensor(0.9561, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9565, device='cuda:0', dtype=torch.float16) acp tensor(0.9995, device='cuda:0', dtype=torch.float16) r 0.3580496612989419

-------------------step: 1-------------------

x1 544 x2 19372 a 19372
q[a] 0.283203125 q[x1] 0.0022830963134765625 q[x2] 0.283203125
gtp[x1] 0.00046634674072265625 gtp[x2] 0.552734375 gtp[a] 0.552734375
px1 tensor(0.0005, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0023, device='cuda:0') acp tensor(0.2043, device='cuda:0') r 0.2535201697771806
pp sum tensor(0.5962, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3130, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5527, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3130, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2832, device='cuda:0', dtype=torch.float16) q[a] 0.283203125
pp sum tensor(0.5776, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2644, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5527, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2644, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2883, device='cuda:0', dtype=torch.float16)
pa tensor(0.2883, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3130, device='cuda:0', dtype=torch.float16) acp tensor(0.9214, device='cuda:0', dtype=torch.float16) r 0.4034343890736727

-------------------step: 2-------------------

directly accept a 292

-------------------step: 3-------------------

x1 1700 x2 325 a 1700
q[a] 0.265869140625 q[x1] 0.265869140625 q[x2] 0.015838623046875
gtp[x1] 0.0025501251220703125 gtp[x2] 7.748603820800781e-07 gtp[a] 0.0025501251220703125
pp sum tensor(0.8516, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5854, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0026, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5854, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0057, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.04988831969604246
q_ai sum tensor(0.2659, device='cuda:0', dtype=torch.float16) q[a] 0.265869140625
pp sum tensor(0.7979, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2123, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0026, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2123, device='cuda:0', dtype=torch.float16)
pa tensor(0.0026, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2123, device='cuda:0', dtype=torch.float16) acp tensor(0.0120, device='cuda:0', dtype=torch.float16) r 0.43626715301141283
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7954, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 12559

-------------------step: 2-------------------

x1 29892 x2 29889 a 29892
q[a] 0.96337890625 q[x1] 0.96337890625 q[x2] 0.00807952880859375
gtp[x1] 0.9931640625 gtp[x2] 0.00537872314453125 gtp[a] 0.9931640625
pp sum tensor(0.9932, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0301, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9932, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0301, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2118, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.27961001285762543
q_ai sum tensor(0.9634, device='cuda:0', dtype=torch.float16) q[a] 0.96337890625
pp sum tensor(0.9932, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9634, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9932, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9634, device='cuda:0', dtype=torch.float16)
pa tensor(0.9932, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9634, device='cuda:0', dtype=torch.float16) acp tensor(1.0312, device='cuda:0', dtype=torch.float16) r 0.17873652160935183

-------------------step: 3-------------------

x1 2 x2 372 a 372
q[a] 0.3115234375 q[x1] 0.0253753662109375 q[x2] 0.3115234375
gtp[x1] 0.00039696693420410156 gtp[x2] 0.485595703125 gtp[a] 0.485595703125
px1 tensor(0.0004, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0254, device='cuda:0') acp tensor(0.0156, device='cuda:0') r 0.9578832272232846
pp sum tensor(0.8608, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5498, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4856, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5498, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3113, device='cuda:0', dtype=torch.float16) q[a] 0.3115234375
pp sum tensor(0.8062, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2566, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4856, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2566, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2290, device='cuda:0', dtype=torch.float16)
pa tensor(0.2290, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5498, device='cuda:0', dtype=torch.float16) acp tensor(0.4165, device='cuda:0', dtype=torch.float16) r 0.7655669978864337
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3206, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 26901 x2 11359 a 11359
q[a] 0.77490234375 q[x1] 0.10009765625 q[x2] 0.77490234375
gtp[x1] 0.07086181640625 gtp[x2] 0.2802734375 gtp[a] 0.2802734375
px1 tensor(0.0709, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1001, device='cuda:0') acp tensor(0.7079, device='cuda:0') r 0.951576371146416
pp sum tensor(0.8628, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0875, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2803, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0875, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7749, device='cuda:0', dtype=torch.float16) q[a] 0.77490234375
pp sum tensor(0.6675, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5796, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2803, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5796, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.0875, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.41320301079883914
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3872, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 310 x2 338 a 338
q[a] 0.5078125 q[x1] 0.32275390625 q[x2] 0.5078125
gtp[x1] 0.035430908203125 gtp[x2] 0.380859375 gtp[a] 0.380859375
px1 tensor(0.0354, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3228, device='cuda:0') acp tensor(0.1098, device='cuda:0') r 0.4752791581950129
pp sum tensor(0.8457, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3379, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3809, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3379, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5078, device='cuda:0', dtype=torch.float16) q[a] 0.5078125
pp sum tensor(0.8164, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4785, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3809, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4785, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3379, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8502608451129479
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.4355, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 263 x2 385 a 263
q[a] 0.92041015625 q[x1] 0.92041015625 q[x2] 0.0626220703125
gtp[x1] 0.68505859375 gtp[x2] 0.063720703125 gtp[a] 0.68505859375
pp sum tensor(0.9214, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0011, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6851, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0011, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0011, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0011, device='cuda:0', dtype=torch.float16) qx2 tensor(0.7266, device='cuda:0', dtype=torch.float16) acp tensor(0.0015, device='cuda:0', dtype=torch.float16) r 0.6787999404668892
q_ai sum tensor(0.9204, device='cuda:0', dtype=torch.float16) q[a] 0.92041015625
pp sum tensor(0.8389, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8379, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.6851, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8379, device='cuda:0', dtype=torch.float16)
pa tensor(0.6851, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8379, device='cuda:0', dtype=torch.float16) acp tensor(0.8174, device='cuda:0', dtype=torch.float16) r 0.8607196248569566
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1538, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 414

-------------------step: 2-------------------

x1 29892 x2 322 a 322
q[a] 0.409423828125 q[x1] 0.0157470703125 q[x2] 0.409423828125
gtp[x1] 7.450580596923828e-06 gtp[x2] 0.0012121200561523438 gtp[a] 0.0012121200561523438
px1 tensor(7.4506e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0157, device='cuda:0') acp tensor(0.0005, device='cuda:0') r 0.6910409051224486
pp sum tensor(0.7261, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3167, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0012, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3167, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4094, device='cuda:0', dtype=torch.float16) q[a] 0.409423828125
pp sum tensor(0.5469, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2305, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0012, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2305, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3167, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1324158776758907
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5459, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 5412 x2 330 a 5412
q[a] 0.53271484375 q[x1] 0.53271484375 q[x2] 0.007843017578125
gtp[x1] 0.31298828125 gtp[x2] 0.0034236907958984375 gtp[a] 0.31298828125
pp sum tensor(0.6450, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1121, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3130, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1121, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0089, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6200698370829895
q_ai sum tensor(0.5327, device='cuda:0', dtype=torch.float16) q[a] 0.53271484375
pp sum tensor(0.5371, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4250, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.3130, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4250, device='cuda:0', dtype=torch.float16)
pa tensor(0.3130, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4250, device='cuda:0', dtype=torch.float16) acp tensor(0.7363, device='cuda:0', dtype=torch.float16) r 0.6657853016799393

-------------------step: 2-------------------

x1 322 x2 7271 a 7271
q[a] 0.5078125 q[x1] 0.46240234375 q[x2] 0.5078125
gtp[x1] 0.7978515625 gtp[x2] 0.07086181640625 gtp[a] 0.07086181640625
px1 tensor(0.7979, device='cuda:0', dtype=torch.float16) qx1 tensor(0.4624, device='cuda:0') acp tensor(1.7254, device='cuda:0') r 0.7748988153518921

-------------------step: 3-------------------

x1 26959 x2 443 a 443
q[a] 0.35009765625 q[x1] 0.08056640625 q[x2] 0.35009765625
gtp[x1] 0.261962890625 gtp[x2] 0.6484375 gtp[a] 0.6484375
px1 tensor(0.2620, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0806, device='cuda:0') acp tensor(3.2515, device='cuda:0') r 0.9673280301987203

-------------------step: 1-------------------

x1 7271 x2 17487 a 7271
q[a] 0.9033203125 q[x1] 0.9033203125 q[x2] 0.003387451171875
gtp[x1] 0.986328125 gtp[x2] 0.0005898475646972656 gtp[a] 0.986328125
pp sum tensor(0.9868, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0836, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0836, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0317, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7665284693896057
q_ai sum tensor(0.9033, device='cuda:0', dtype=torch.float16) q[a] 0.9033203125
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9028, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9028, device='cuda:0', dtype=torch.float16)
pa tensor(0.9863, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9028, device='cuda:0', dtype=torch.float16) acp tensor(1.0928, device='cuda:0', dtype=torch.float16) r 0.47842382487303814

-------------------step: 2-------------------

x1 29889 x2 411 a 29889
q[a] 0.8994140625 q[x1] 0.8994140625 q[x2] 0.00024628639221191406
gtp[x1] 0.974609375 gtp[x2] 0.00012218952178955078 gtp[a] 0.974609375
pp sum tensor(0.9824, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0829, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9746, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0829, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0022, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.45850957651070556
q_ai sum tensor(0.8994, device='cuda:0', dtype=torch.float16) q[a] 0.8994140625
pp sum tensor(0.9746, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8916, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9746, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8916, device='cuda:0', dtype=torch.float16)
pa tensor(0.9746, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8916, device='cuda:0', dtype=torch.float16) acp tensor(1.0928, device='cuda:0', dtype=torch.float16) r 0.3596620329078539

-------------------step: 3-------------------

x1 13 x2 3645 a 13
q[a] 0.391357421875 q[x1] 0.391357421875 q[x2] 0.2030029296875
gtp[x1] 0.452392578125 gtp[x2] 0.0218353271484375 gtp[a] 0.452392578125
pp sum tensor(0.8369, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4456, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4524, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4456, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1305, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5459399851457536
q_ai sum tensor(0.3914, device='cuda:0', dtype=torch.float16) q[a] 0.391357421875
pp sum tensor(0.8076, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3623, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4524, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3623, device='cuda:0', dtype=torch.float16)
pa tensor(0.4524, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3623, device='cuda:0', dtype=torch.float16) acp tensor(1.2490, device='cuda:0', dtype=torch.float16) r 0.1286544765594323

-------------------step: 1-------------------

x1 2744 x2 6716 a 6716
q[a] 0.482666015625 q[x1] 0.01326751708984375 q[x2] 0.482666015625
gtp[x1] 0.004955291748046875 gtp[x2] 0.6591796875 gtp[a] 0.6591796875
px1 tensor(0.0050, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0133, device='cuda:0') acp tensor(0.3735, device='cuda:0') r 0.9625593433532088
pp sum tensor(0.6777, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1946, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6592, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1946, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4829, device='cuda:0', dtype=torch.float16) q[a] 0.482666015625
pp sum tensor(0.6733, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4788, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6592, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4788, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1804, device='cuda:0', dtype=torch.float16)
pa tensor(0.1804, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1946, device='cuda:0', dtype=torch.float16) acp tensor(0.9272, device='cuda:0', dtype=torch.float16) r 0.3622857118995312

-------------------step: 2-------------------

x1 310 x2 2 a 310
q[a] 0.9697265625 q[x1] 0.9697265625 q[x2] 0.006137847900390625
gtp[x1] 0.83251953125 gtp[x2] 4.667043685913086e-05 gtp[a] 0.83251953125
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0183, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8325, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0183, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1954, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6583385116649453
q_ai sum tensor(0.9697, device='cuda:0', dtype=torch.float16) q[a] 0.9697265625
pp sum tensor(0.8745, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8564, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8325, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8564, device='cuda:0', dtype=torch.float16)
pa tensor(0.8325, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8564, device='cuda:0', dtype=torch.float16) acp tensor(0.9722, device='cuda:0', dtype=torch.float16) r 0.6422125059393173

-------------------step: 3-------------------

x1 278 x2 2 a 278
q[a] 1.0 q[x1] 1.0 q[x2] 0.00012934207916259766
gtp[x1] 0.998046875 gtp[x2] 6.80088996887207e-05 gtp[a] 0.998046875
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(8.1778e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(8.1778e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6514, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8113344454059589
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(0.9995, device='cuda:0', dtype=torch.float16) r 0.4417376845298553

-------------------step: 1-------------------

x1 19650 x2 1098 a 19650
q[a] 0.9716796875 q[x1] 0.9716796875 q[x2] 0.0048675537109375
gtp[x1] 0.44580078125 gtp[x2] 0.0007357597351074219 gtp[a] 0.44580078125
pp sum tensor(0.9771, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0053, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.4458, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0053, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1681, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6990300753335875
q_ai sum tensor(0.9717, device='cuda:0', dtype=torch.float16) q[a] 0.9716796875
pp sum tensor(0.5771, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5718, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.4458, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5718, device='cuda:0', dtype=torch.float16)
pa tensor(0.4458, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5718, device='cuda:0', dtype=torch.float16) acp tensor(0.7798, device='cuda:0', dtype=torch.float16) r 0.9085356702354143
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1316, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 19650 x2 27482 a 19650
q[a] 0.84814453125 q[x1] 0.84814453125 q[x2] 0.0199432373046875
gtp[x1] 0.19287109375 gtp[x2] 0.78662109375 gtp[a] 0.19287109375
pp sum tensor(0.9600, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1121, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1929, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7666, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1121, device='cuda:0', dtype=torch.float16)
px2 tensor(0.7666, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1114, device='cuda:0', dtype=torch.float16) acp tensor(6.8828, device='cuda:0', dtype=torch.float16) r 0.2028004388022172

-------------------step: 2-------------------

x1 373 x2 304 a 304
q[a] 0.287109375 q[x1] 0.0167083740234375 q[x2] 0.287109375
gtp[x1] 8.887052536010742e-05 gtp[x2] 0.77294921875 gtp[a] 0.77294921875
px1 tensor(8.8871e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0167, device='cuda:0') acp tensor(0.0053, device='cuda:0') r 0.5405317982540597
pp sum tensor(0.8711, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5840, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7729, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5840, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2871, device='cuda:0', dtype=torch.float16) q[a] 0.287109375
pp sum tensor(0.8291, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2451, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7729, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2451, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5278, device='cuda:0', dtype=torch.float16)
pa tensor(0.5278, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5840, device='cuda:0', dtype=torch.float16) acp tensor(0.9038, device='cuda:0', dtype=torch.float16) r 0.628603501000344

-------------------step: 3-------------------

x1 6493 x2 1083 a 6493
q[a] 0.54638671875 q[x1] 0.54638671875 q[x2] 1.1205673217773438e-05
gtp[x1] 7.987022399902344e-05 gtp[x2] 0.0 gtp[a] 7.987022399902344e-05
pp sum tensor(0.9639, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4170, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(7.9870e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4170, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(1.3530e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.74716793013726
q_ai sum tensor(0.5464, device='cuda:0', dtype=torch.float16) q[a] 0.54638671875
pp sum tensor(0.9263, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5088, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(7.9870e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5088, device='cuda:0', dtype=torch.float16)
pa tensor(7.9870e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5088, device='cuda:0', dtype=torch.float16) acp tensor(0.0002, device='cuda:0', dtype=torch.float16) r 0.9658083500137741
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9263, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 297 x2 746 a 297
q[a] 0.70703125 q[x1] 0.70703125 q[x2] 0.00583648681640625
gtp[x1] 0.8974609375 gtp[x2] 0.0246734619140625 gtp[a] 0.8974609375
pp sum tensor(0.9209, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2141, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8975, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0188, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2141, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0188, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0141, device='cuda:0', dtype=torch.float16) acp tensor(1.3389, device='cuda:0', dtype=torch.float16) r 0.7533072075575336

-------------------step: 2-------------------

x1 6493 x2 3902 a 6493
q[a] 0.78857421875 q[x1] 0.78857421875 q[x2] 0.10675048828125
gtp[x1] 0.97265625 gtp[x2] 0.00020420551300048828 gtp[a] 0.97265625
pp sum tensor(0.9834, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1945, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9727, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1945, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3989, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.293585978146078
q_ai sum tensor(0.7886, device='cuda:0', dtype=torch.float16) q[a] 0.78857421875
pp sum tensor(0.9814, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7866, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9727, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7866, device='cuda:0', dtype=torch.float16)
pa tensor(0.9727, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7866, device='cuda:0', dtype=torch.float16) acp tensor(1.2363, device='cuda:0', dtype=torch.float16) r 0.7111430413511861

-------------------step: 3-------------------

directly accept a 292

-------------------step: 1-------------------

directly accept a 29875

-------------------step: 2-------------------

x1 338 x2 723 a 338
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 2.1457672119140625e-06
gtp[x1] 0.99853515625 gtp[x2] 6.490945816040039e-05 gtp[a] 0.99853515625
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(4.5300e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(6.2764e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(4.5300e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(6.2764e-05, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0043, device='cuda:0', dtype=torch.float16) acp tensor(0.0147, device='cuda:0', dtype=torch.float16) r 0.46535850707758175
q_ai sum tensor(0.9995, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9980, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.9774650906951616

-------------------step: 3-------------------

x1 263 x2 278 a 263
q[a] 0.54443359375 q[x1] 0.54443359375 q[x2] 0.330322265625
gtp[x1] 0.349365234375 gtp[x2] 0.333251953125 gtp[a] 0.349365234375
pp sum tensor(0.6611, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1163, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3494, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0029, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1163, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0029, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3950, device='cuda:0', dtype=torch.float16) acp tensor(0.0074, device='cuda:0', dtype=torch.float16) r 0.8770523219536759
q_ai sum tensor(0.5444, device='cuda:0', dtype=torch.float16) q[a] 0.54443359375
pp sum tensor(0.6553, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5386, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.3494, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5386, device='cuda:0', dtype=torch.float16)
pa tensor(0.3494, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5386, device='cuda:0', dtype=torch.float16) acp tensor(0.6489, device='cuda:0', dtype=torch.float16) r 0.7567462526117693
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3059, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 8253

-------------------step: 2-------------------

x1 278 x2 967 a 278
q[a] 0.9921875 q[x1] 0.9921875 q[x2] 0.0007443428039550781
gtp[x1] 0.91259765625 gtp[x2] 0.004428863525390625 gtp[a] 0.91259765625
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0053, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9126, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0037, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0053, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0037, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0952, device='cuda:0', dtype=torch.float16) acp tensor(0.0387, device='cuda:0', dtype=torch.float16) r 0.33135949624907524
q_ai sum tensor(0.9922, device='cuda:0', dtype=torch.float16) q[a] 0.9921875
pp sum tensor(0.9839, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9785, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9126, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9785, device='cuda:0', dtype=torch.float16)
pa tensor(0.9126, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9785, device='cuda:0', dtype=torch.float16) acp tensor(0.9326, device='cuda:0', dtype=torch.float16) r 0.147695840855256

-------------------step: 3-------------------

x1 11359 x2 319 a 319
q[a] 0.1527099609375 q[x1] 0.07861328125 q[x2] 0.1527099609375
gtp[x1] 0.00757598876953125 gtp[x2] 4.035234451293945e-05 gtp[a] 4.035234451293945e-05
px1 tensor(0.0076, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0786, device='cuda:0') acp tensor(0.0964, device='cuda:0') r 0.015696189553590867

-------------------step: 1-------------------

directly accept a 29879

-------------------step: 2-------------------

x1 12297 x2 22879 a 22879
q[a] 0.389892578125 q[x1] 0.0179443359375 q[x2] 0.389892578125
gtp[x1] 0.0010747909545898438 gtp[x2] 0.01361083984375 gtp[a] 0.01361083984375
px1 tensor(0.0011, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0179, device='cuda:0') acp tensor(0.0599, device='cuda:0') r 0.2812011590795297
pp sum tensor(0.6162, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2261, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0136, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2261, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3901, device='cuda:0', dtype=torch.float16) q[a] 0.389892578125
pp sum tensor(0.4182, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1919, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0136, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1919, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2261, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4101396546559529
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.4045, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 4955 x2 4940 a 4955
q[a] 0.9970703125 q[x1] 0.9970703125 q[x2] 0.0009379386901855469
gtp[x1] 0.986328125 gtp[x2] 0.0014829635620117188 gtp[a] 0.986328125
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0007, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0005, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0007, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0005, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3191, device='cuda:0', dtype=torch.float16) acp tensor(0.0017, device='cuda:0', dtype=torch.float16) r 0.8934502751290864
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16) q[a] 0.9970703125
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9858, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9858, device='cuda:0', dtype=torch.float16)
pa tensor(0.9863, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9858, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.4028543105299728

-------------------step: 2-------------------

x1 322 x2 29892 a 322
q[a] 0.7744140625 q[x1] 0.7744140625 q[x2] 0.1064453125
gtp[x1] 0.2919921875 gtp[x2] 0.0280303955078125 gtp[a] 0.2919921875
pp sum tensor(0.8540, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0793, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2920, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0793, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3657, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6911212670211316
q_ai sum tensor(0.7749, device='cuda:0', dtype=torch.float16) q[a] 0.7744140625
pp sum tensor(0.6392, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5601, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.2920, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5601, device='cuda:0', dtype=torch.float16)
pa tensor(0.2920, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5601, device='cuda:0', dtype=torch.float16) acp tensor(0.5215, device='cuda:0', dtype=torch.float16) r 0.19588666365919483

-------------------step: 3-------------------

x1 4955 x2 25005 a 4955
q[a] 0.2386474609375 q[x1] 0.2386474609375 q[x2] 5.3942203521728516e-05
gtp[x1] 4.76837158203125e-06 gtp[x2] 1.7881393432617188e-07 gtp[a] 4.76837158203125e-06
pp sum tensor(0.9048, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6655, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(4.7684e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6655, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(1.6928e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.43833678635142304
q_ai sum tensor(0.2386, device='cuda:0', dtype=torch.float16) q[a] 0.2386474609375
pp sum tensor(0.8877, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2219, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(4.7684e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2219, device='cuda:0', dtype=torch.float16)
pa tensor(4.7684e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2219, device='cuda:0', dtype=torch.float16) acp tensor(2.1458e-05, device='cuda:0', dtype=torch.float16) r 0.44027586789460005
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8877, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 2187

-------------------step: 2-------------------

x1 29889 x2 1549 a 29889
q[a] 0.8583984375 q[x1] 0.8583984375 q[x2] 0.0298309326171875
gtp[x1] 0.7890625 gtp[x2] 0.0117950439453125 gtp[a] 0.7890625
pp sum tensor(0.9170, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0587, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7891, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0587, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1805, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5991005550230915
q_ai sum tensor(0.8584, device='cuda:0', dtype=torch.float16) q[a] 0.8583984375
pp sum tensor(0.7896, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7305, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7891, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7305, device='cuda:0', dtype=torch.float16)
pa tensor(0.7891, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7305, device='cuda:0', dtype=torch.float16) acp tensor(1.0801, device='cuda:0', dtype=torch.float16) r 0.004767164473678531

-------------------step: 3-------------------

x1 5741 x2 450 a 450
q[a] 0.448974609375 q[x1] 0.19921875 q[x2] 0.448974609375
gtp[x1] 0.00713348388671875 gtp[x2] 0.65234375 gtp[a] 0.65234375
px1 tensor(0.0071, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1992, device='cuda:0') acp tensor(0.0358, device='cuda:0') r 0.47411310741401547
pp sum tensor(0.8696, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4207, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6523, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4207, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4490, device='cuda:0', dtype=torch.float16) q[a] 0.448974609375
pp sum tensor(0.8037, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3831, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6523, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3831, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2693, device='cuda:0', dtype=torch.float16)
pa tensor(0.2693, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4207, device='cuda:0', dtype=torch.float16) acp tensor(0.6401, device='cuda:0', dtype=torch.float16) r 0.05336998358235179

-------------------step: 1-------------------

directly accept a 29880

-------------------step: 2-------------------

x1 22904 x2 7906 a 7906
q[a] 0.10302734375 q[x1] 0.00628662109375 q[x2] 0.10302734375
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0063, device='cuda:0') acp tensor(0., device='cuda:0') r 0.19326539692032485
pp sum tensor(0.9434, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8403, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8403, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1029, device='cuda:0', dtype=torch.float16) q[a] 0.10302734375
pp sum tensor(0.9370, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0964, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0964, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8403, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.21347815908504375
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9370, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 4089

-------------------step: 2-------------------

directly accept a 3086

-------------------step: 3-------------------

x1 23542 x2 4815 a 23542
q[a] 0.438720703125 q[x1] 0.438720703125 q[x2] 0.1552734375
gtp[x1] 0.99609375 gtp[x2] 5.662441253662109e-06 gtp[a] 0.99609375
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5571, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5571, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1215, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3757611507212383
q_ai sum tensor(0.4387, device='cuda:0', dtype=torch.float16) q[a] 0.438720703125
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4387, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4387, device='cuda:0', dtype=torch.float16)
pa tensor(0.9961, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4387, device='cuda:0', dtype=torch.float16) acp tensor(2.2695, device='cuda:0', dtype=torch.float16) r 0.3119818877339552

-------------------step: 1-------------------

x1 263 x2 278 a 263
q[a] 0.9912109375 q[x1] 0.9912109375 q[x2] 0.0012950897216796875
gtp[x1] 0.92333984375 gtp[x2] 0.0020198822021484375 gtp[a] 0.92333984375
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0001, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9233, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0007, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0001, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0007, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1487, device='cuda:0', dtype=torch.float16) acp tensor(0.0049, device='cuda:0', dtype=torch.float16) r 0.6569879413988399
q_ai sum tensor(0.9912, device='cuda:0', dtype=torch.float16) q[a] 0.9912109375
pp sum tensor(0.9238, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9233, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9233, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9233, device='cuda:0', dtype=torch.float16)
pa tensor(0.9233, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9233, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.650871911823764

-------------------step: 2-------------------

x1 1818 x2 5613 a 1818
q[a] 0.91064453125 q[x1] 0.91064453125 q[x2] 0.00017404556274414062
gtp[x1] 0.9931640625 gtp[x2] 4.172325134277344e-07 gtp[a] 0.9931640625
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0858, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9932, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0858, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0018, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.22840760922389003
q_ai sum tensor(0.9106, device='cuda:0', dtype=torch.float16) q[a] 0.91064453125
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9092, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9932, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9092, device='cuda:0', dtype=torch.float16)
pa tensor(0.9932, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9092, device='cuda:0', dtype=torch.float16) acp tensor(1.0928, device='cuda:0', dtype=torch.float16) r 0.44251986045386826

-------------------step: 3-------------------

x1 29899 x2 2 a 29899
q[a] 0.9609375 q[x1] 0.9609375 q[x2] 0.036102294921875
gtp[x1] 0.99853515625 gtp[x2] 6.598234176635742e-05 gtp[a] 0.99853515625
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0389, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0389, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8833, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2528850346467161
q_ai sum tensor(0.9609, device='cuda:0', dtype=torch.float16) q[a] 0.9609375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9604, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9604, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9604, device='cuda:0', dtype=torch.float16) acp tensor(1.0400, device='cuda:0', dtype=torch.float16) r 0.8412964539282906

-------------------step: 1-------------------

x1 363 x2 29892 a 29892
q[a] 0.54931640625 q[x1] 0.33837890625 q[x2] 0.54931640625
gtp[x1] 0.73583984375 gtp[x2] 0.07757568359375 gtp[a] 0.07757568359375
px1 tensor(0.7358, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3384, device='cuda:0') acp tensor(2.1746, device='cuda:0') r 0.1200638368874285

-------------------step: 2-------------------

x1 5019 x2 738 a 5019
q[a] 0.4951171875 q[x1] 0.4951171875 q[x2] 0.18798828125
gtp[x1] 0.90966796875 gtp[x2] 0.047454833984375 gtp[a] 0.90966796875
pp sum tensor(0.9346, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4397, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9097, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4397, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1844, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4160156195853929
q_ai sum tensor(0.4951, device='cuda:0', dtype=torch.float16) q[a] 0.4951171875
pp sum tensor(0.9341, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4944, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9097, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4944, device='cuda:0', dtype=torch.float16)
pa tensor(0.9097, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4944, device='cuda:0', dtype=torch.float16) acp tensor(1.8398, device='cuda:0', dtype=torch.float16) r 0.9273397636393662

-------------------step: 3-------------------

x1 3063 x2 6493 a 6493
q[a] 0.460205078125 q[x1] 0.279052734375 q[x2] 0.460205078125
gtp[x1] 0.0006079673767089844 gtp[x2] 0.005855560302734375 gtp[a] 0.005855560302734375
px1 tensor(0.0006, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2791, device='cuda:0') acp tensor(0.0022, device='cuda:0') r 0.27597683930506267
pp sum tensor(0.8330, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3728, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0059, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3728, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4602, device='cuda:0', dtype=torch.float16) q[a] 0.460205078125
pp sum tensor(0.6943, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3215, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0059, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3215, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3728, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5889321372979851
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6885, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 297

-------------------step: 2-------------------

x1 4955 x2 278 a 278
q[a] 0.485595703125 q[x1] 0.1815185546875 q[x2] 0.485595703125
gtp[x1] 0.0009751319885253906 gtp[x2] 0.0113372802734375 gtp[a] 0.0113372802734375
px1 tensor(0.0010, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1815, device='cuda:0') acp tensor(0.0054, device='cuda:0') r 0.8544047998279313
pp sum tensor(0.9448, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4595, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0113, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4595, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4856, device='cuda:0', dtype=torch.float16) q[a] 0.485595703125
pp sum tensor(0.9165, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4573, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0113, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4573, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4595, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.32809959710480385
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9053, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 3362

-------------------step: 2-------------------

directly accept a 1944

-------------------step: 3-------------------

x1 4955 x2 2 a 4955
q[a] 0.89501953125 q[x1] 0.89501953125 q[x2] 0.0019588470458984375
gtp[x1] 0.9892578125 gtp[x2] 0.00011116266250610352 gtp[a] 0.9892578125
pp sum tensor(0.9893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0938, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9893, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0938, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0168, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7359472359654337
q_ai sum tensor(0.8950, device='cuda:0', dtype=torch.float16) q[a] 0.89501953125
pp sum tensor(0.9893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8950, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9893, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8950, device='cuda:0', dtype=torch.float16)
pa tensor(0.9893, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8950, device='cuda:0', dtype=torch.float16) acp tensor(1.1055, device='cuda:0', dtype=torch.float16) r 0.6681622474178085

-------------------step: 1-------------------

x1 5741 x2 450 a 450
q[a] 0.7666015625 q[x1] 0.0283660888671875 q[x2] 0.7666015625
gtp[x1] 0.0224151611328125 gtp[x2] 0.8544921875 gtp[a] 0.8544921875
px1 tensor(0.0224, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0284, device='cuda:0') acp tensor(0.7902, device='cuda:0') r 0.7622779556267582

-------------------step: 2-------------------

x1 17259 x2 277 a 17259
q[a] 0.8447265625 q[x1] 0.8447265625 q[x2] 0.0947265625
gtp[x1] 0.96630859375 gtp[x2] 0.025360107421875 gtp[a] 0.96630859375
pp sum tensor(0.9663, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1219, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9663, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1219, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5142, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6357694680641183
q_ai sum tensor(0.8442, device='cuda:0', dtype=torch.float16) q[a] 0.8447265625
pp sum tensor(0.9663, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8442, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9663, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8442, device='cuda:0', dtype=torch.float16)
pa tensor(0.9663, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8442, device='cuda:0', dtype=torch.float16) acp tensor(1.1445, device='cuda:0', dtype=torch.float16) r 0.2922915402928111

-------------------step: 3-------------------

x1 304 x2 526 a 304
q[a] 0.79296875 q[x1] 0.79296875 q[x2] 0.029571533203125
gtp[x1] 0.01235198974609375 gtp[x2] 0.0005960464477539062 gtp[a] 0.01235198974609375
pp sum tensor(0.9766, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1833, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0124, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1833, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1133, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7201433885292711
q_ai sum tensor(0.7930, device='cuda:0', dtype=torch.float16) q[a] 0.79296875
pp sum tensor(0.9004, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7173, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0124, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7173, device='cuda:0', dtype=torch.float16)
pa tensor(0.0124, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7173, device='cuda:0', dtype=torch.float16) acp tensor(0.0172, device='cuda:0', dtype=torch.float16) r 0.3994463849158947
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8882, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 5110 x2 26987 a 26987
q[a] 0.174560546875 q[x1] 0.1492919921875 q[x2] 0.174560546875
gtp[x1] 0.171630859375 gtp[x2] 0.1944580078125 gtp[a] 0.1944580078125
px1 tensor(0.1716, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1493, device='cuda:0') acp tensor(1.1496, device='cuda:0') r 0.8711302906566121

-------------------step: 2-------------------

x1 1048 x2 278 a 1048
q[a] 0.95654296875 q[x1] 0.95654296875 q[x2] 0.029815673828125
gtp[x1] 0.982421875 gtp[x2] 3.695487976074219e-05 gtp[a] 0.982421875
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0380, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9824, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0380, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6592, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2649819718727301
q_ai sum tensor(0.9565, device='cuda:0', dtype=torch.float16) q[a] 0.95654296875
pp sum tensor(0.9834, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9448, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9824, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9448, device='cuda:0', dtype=torch.float16)
pa tensor(0.9824, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9448, device='cuda:0', dtype=torch.float16) acp tensor(1.0400, device='cuda:0', dtype=torch.float16) r 0.9858546738278566

-------------------step: 3-------------------

x1 278 x2 1438 a 278
q[a] 0.9990234375 q[x1] 0.9990234375 q[x2] 1.055002212524414e-05
gtp[x1] 0.9990234375 gtp[x2] 0.0 gtp[a] 0.9990234375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0088, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9867118011302459
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16) q[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.27822996785443155

-------------------step: 1-------------------

x1 373 x2 322 a 373
q[a] 0.9306640625 q[x1] 0.9306640625 q[x2] 0.0604248046875
gtp[x1] 0.95849609375 gtp[x2] 0.00024271011352539062 gtp[a] 0.95849609375
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0647, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9585, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0647, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8120, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7605051349540004
q_ai sum tensor(0.9307, device='cuda:0', dtype=torch.float16) q[a] 0.9306640625
pp sum tensor(0.9585, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8940, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9585, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8940, device='cuda:0', dtype=torch.float16)
pa tensor(0.9585, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8940, device='cuda:0', dtype=torch.float16) acp tensor(1.0723, device='cuda:0', dtype=torch.float16) r 0.9640238899027298

-------------------step: 2-------------------

x1 278 x2 21265 a 21265
q[a] 0.428955078125 q[x1] 0.328857421875 q[x2] 0.428955078125
gtp[x1] 0.00262451171875 gtp[x2] 0.9638671875 gtp[a] 0.9638671875
px1 tensor(0.0026, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3289, device='cuda:0') acp tensor(0.0080, device='cuda:0') r 0.3056352125598394
pp sum tensor(0.9639, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5347, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9639, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5347, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4292, device='cuda:0', dtype=torch.float16) q[a] 0.428955078125
pp sum tensor(0.9639, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4292, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9639, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4292, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5347, device='cuda:0', dtype=torch.float16)
pa tensor(0.5347, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5347, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.5181324412746128

-------------------step: 3-------------------

directly accept a 29880

-------------------step: 1-------------------

directly accept a 4089

-------------------step: 2-------------------

x1 393 x2 322 a 393
q[a] 0.64794921875 q[x1] 0.64794921875 q[x2] 0.1539306640625
gtp[x1] 0.004070281982421875 gtp[x2] 0.06884765625 gtp[a] 0.004070281982421875
pp sum tensor(0.9058, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2578, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0041, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2578, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2832, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7092752823741253
q_ai sum tensor(0.6479, device='cuda:0', dtype=torch.float16) q[a] 0.64794921875
pp sum tensor(0.8960, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6382, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0041, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6382, device='cuda:0', dtype=torch.float16)
pa tensor(0.0041, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6382, device='cuda:0', dtype=torch.float16) acp tensor(0.0064, device='cuda:0', dtype=torch.float16) r 0.2842462914577216
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8916, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 5846

-------------------step: 2-------------------

directly accept a 29871

-------------------step: 3-------------------

x1 29896 x2 29955 a 29896
q[a] 0.9990234375 q[x1] 0.9990234375 q[x2] 0.0002589225769042969
gtp[x1] 1.0132789611816406e-05 gtp[x2] 1.0 gtp[a] 1.0132789611816406e-05
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0005, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.0133e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9995, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0005, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9995, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3428, device='cuda:0', dtype=torch.float16) acp tensor(2.9160, device='cuda:0', dtype=torch.float16) r 0.8105151048316664

-------------------step: 1-------------------

directly accept a 29871

-------------------step: 2-------------------

directly accept a 29896

-------------------step: 3-------------------

directly accept a 29929

-------------------step: 1-------------------

directly accept a 29896

-------------------step: 2-------------------

x1 322 x2 29892 a 29892
q[a] 0.6767578125 q[x1] 0.319580078125 q[x2] 0.6767578125
gtp[x1] 0.130615234375 gtp[x2] 0.865234375 gtp[a] 0.865234375
px1 tensor(0.1306, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3196, device='cuda:0') acp tensor(0.4087, device='cuda:0') r 0.63050388632245
pp sum tensor(0.8682, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1917, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8652, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1917, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6768, device='cuda:0', dtype=torch.float16) q[a] 0.6767578125
pp sum tensor(0.8672, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6753, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8652, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6753, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1899, device='cuda:0', dtype=torch.float16)
pa tensor(0.1899, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.1917, device='cuda:0', dtype=torch.float16) acp tensor(0.9912, device='cuda:0', dtype=torch.float16) r 0.8579038833453421

-------------------step: 3-------------------

x1 322 x2 278 a 322
q[a] 0.97119140625 q[x1] 0.97119140625 q[x2] 0.0020923614501953125
gtp[x1] 0.86474609375 gtp[x2] 0.0003902912139892578 gtp[a] 0.86474609375
pp sum tensor(0.9854, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0138, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8647, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0138, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0709, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.13229569047237066
q_ai sum tensor(0.9707, device='cuda:0', dtype=torch.float16) q[a] 0.97119140625
pp sum tensor(0.9414, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9272, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8647, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9272, device='cuda:0', dtype=torch.float16)
pa tensor(0.8647, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9272, device='cuda:0', dtype=torch.float16) acp tensor(0.9326, device='cuda:0', dtype=torch.float16) r 0.6018163863318132

-------------------step: 1-------------------

x1 263 x2 29871 a 263
q[a] 0.83837890625 q[x1] 0.83837890625 q[x2] 0.00010925531387329102
gtp[x1] 6.508827209472656e-05 gtp[x2] 0.0 gtp[a] 6.508827209472656e-05
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1600, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(6.5088e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1600, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0006, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5098660865661669
q_ai sum tensor(0.8384, device='cuda:0', dtype=torch.float16) q[a] 0.83837890625
pp sum tensor(0.9902, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8301, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(6.5088e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8301, device='cuda:0', dtype=torch.float16)
pa tensor(6.5088e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8301, device='cuda:0', dtype=torch.float16) acp tensor(7.8440e-05, device='cuda:0', dtype=torch.float16) r 0.5579101120620217
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9902, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 3390

-------------------step: 2-------------------

x1 304 x2 29879 a 304
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 0.0003006458282470703
gtp[x1] 6.812810897827148e-05 gtp[x2] 1.0 gtp[a] 6.812810897827148e-05
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0002, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(6.8128e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9995, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0002, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9995, device='cuda:0', dtype=torch.float16) qx2 tensor(0.5825, device='cuda:0', dtype=torch.float16) acp tensor(1.7158, device='cuda:0', dtype=torch.float16) r 0.237221288473477

-------------------step: 3-------------------

x1 304 x2 2 a 304
q[a] 1.0 q[x1] 1.0 q[x2] 0.0001881122589111328
gtp[x1] 0.1539306640625 gtp[x2] 0.0003476142883300781 gtp[a] 0.1539306640625
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(1.2100e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.1539, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0002, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(1.2100e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0002, device='cuda:0', dtype=torch.float16) qx2 tensor(0.9067, device='cuda:0', dtype=torch.float16) acp tensor(0.0002, device='cuda:0', dtype=torch.float16) r 0.32199798383665357
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9995, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.1539, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9995, device='cuda:0', dtype=torch.float16)
pa tensor(0.1539, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9995, device='cuda:0', dtype=torch.float16) acp tensor(0.1541, device='cuda:0', dtype=torch.float16) r 0.9794875309856415
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8452, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 278

-------------------step: 2-------------------

x1 4956 x2 22879 a 22879
q[a] 0.109619140625 q[x1] 4.273653030395508e-05 q[x2] 0.109619140625
gtp[x1] 5.960464477539063e-08 gtp[x2] 0.00013363361358642578 gtp[a] 0.00013363361358642578
px1 tensor(5.9605e-08, device='cuda:0', dtype=torch.float16) qx1 tensor(4.2737e-05, device='cuda:0') acp tensor(0.0014, device='cuda:0') r 0.7584417307614512
pp sum tensor(0.9204, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8105, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0001, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8105, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1095, device='cuda:0', dtype=torch.float16) q[a] 0.109619140625
pp sum tensor(0.9111, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1006, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0001, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1006, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8105, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8148198898971429
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9111, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 23716

-------------------step: 2-------------------

directly accept a 19722

-------------------step: 3-------------------

x1 29892 x2 29889 a 29892
q[a] 0.46875 q[x1] 0.46875 q[x2] 0.353759765625
gtp[x1] 0.70556640625 gtp[x2] 0.2939453125 gtp[a] 0.70556640625
pp sum tensor(0.7056, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2367, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.7056, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2367, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3123, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5070598179887836
q_ai sum tensor(0.4688, device='cuda:0', dtype=torch.float16) q[a] 0.46875
pp sum tensor(0.7056, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4688, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.7056, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4688, device='cuda:0', dtype=torch.float16)
pa tensor(0.7056, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4688, device='cuda:0', dtype=torch.float16) acp tensor(1.5049, device='cuda:0', dtype=torch.float16) r 0.9450145472944912

-------------------step: 1-------------------

x1 17436 x2 2626 a 2626
q[a] 0.26513671875 q[x1] 0.0005488395690917969 q[x2] 0.26513671875
gtp[x1] 5.5849552154541016e-05 gtp[x2] 0.016876220703125 gtp[a] 0.016876220703125
px1 tensor(5.5850e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0005, device='cuda:0') acp tensor(0.1018, device='cuda:0') r 0.38264434260919755
pp sum tensor(0.7563, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4907, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0169, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4907, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2651, device='cuda:0', dtype=torch.float16) q[a] 0.26513671875
pp sum tensor(0.7041, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2133, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0169, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2133, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4907, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.01921986449973745
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6875, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 495

-------------------step: 2-------------------

x1 7055 x2 2626 a 2626
q[a] 0.3564453125 q[x1] 0.0008363723754882812 q[x2] 0.3564453125
gtp[x1] 0.0 gtp[x2] 0.0017414093017578125 gtp[a] 0.0017414093017578125
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0008, device='cuda:0') acp tensor(0., device='cuda:0') r 0.589657207473755
pp sum tensor(0.9478, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5913, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0017, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5913, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3567, device='cuda:0', dtype=torch.float16) q[a] 0.3564453125
pp sum tensor(0.9292, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3384, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0017, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3384, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5913, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1992703282005619
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9272, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 26384 x2 3165 a 3165
q[a] 0.405029296875 q[x1] 0.12939453125 q[x2] 0.405029296875
gtp[x1] 0.0005984306335449219 gtp[x2] 0.955078125 gtp[a] 0.955078125
px1 tensor(0.0006, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1294, device='cuda:0') acp tensor(0.0046, device='cuda:0') r 0.3765528820166931
pp sum tensor(0.9551, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5498, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9551, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5498, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4050, device='cuda:0', dtype=torch.float16) q[a] 0.405029296875
pp sum tensor(0.9551, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4050, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9551, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4050, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5498, device='cuda:0', dtype=torch.float16)
pa tensor(0.5498, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5498, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.06404829195525019

-------------------step: 2-------------------

directly accept a 21435

-------------------step: 3-------------------

x1 1083 x2 260 a 1083
q[a] 0.69970703125 q[x1] 0.69970703125 q[x2] 0.200439453125
gtp[x1] 0.001972198486328125 gtp[x2] 0.0048065185546875 gtp[a] 0.001972198486328125
pp sum tensor(0.9829, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2830, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0020, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2830, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4670, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1420232147521714
q_ai sum tensor(0.6997, device='cuda:0', dtype=torch.float16) q[a] 0.69970703125
pp sum tensor(0.9614, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6777, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0020, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6777, device='cuda:0', dtype=torch.float16)
pa tensor(0.0020, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6777, device='cuda:0', dtype=torch.float16) acp tensor(0.0029, device='cuda:0', dtype=torch.float16) r 0.44579593458329436
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9595, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 393 x2 29889 a 393
q[a] 0.77001953125 q[x1] 0.77001953125 q[x2] 0.22412109375
gtp[x1] 0.904296875 gtp[x2] 0.09234619140625 gtp[a] 0.904296875
pp sum tensor(0.9072, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1371, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9043, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1371, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7505, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8493468125450971
q_ai sum tensor(0.7700, device='cuda:0', dtype=torch.float16) q[a] 0.77001953125
pp sum tensor(0.9072, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7700, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9043, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7700, device='cuda:0', dtype=torch.float16)
pa tensor(0.9043, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7700, device='cuda:0', dtype=torch.float16) acp tensor(1.1748, device='cuda:0', dtype=torch.float16) r 0.3764671707309982

-------------------step: 2-------------------

x1 4207 x2 19781 a 4207
q[a] 0.77978515625 q[x1] 0.77978515625 q[x2] 0.0543212890625
gtp[x1] 0.99658203125 gtp[x2] 6.4373016357421875e-06 gtp[a] 0.99658203125
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2172, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2172, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1924, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7842337723295695
q_ai sum tensor(0.7798, device='cuda:0', dtype=torch.float16) q[a] 0.77978515625
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7798, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7798, device='cuda:0', dtype=torch.float16)
pa tensor(0.9966, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7798, device='cuda:0', dtype=torch.float16) acp tensor(1.2783, device='cuda:0', dtype=torch.float16) r 0.709648421445592

-------------------step: 3-------------------

directly accept a 943

-------------------step: 1-------------------

x1 29871 x2 10405 a 29871
q[a] 0.857421875 q[x1] 0.857421875 q[x2] 0.00010663270950317383
gtp[x1] 0.99072265625 gtp[x2] 2.980232238769531e-07 gtp[a] 0.99072265625
pp sum tensor(0.9907, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1333, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9907, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1333, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0006, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8190828153215239
q_ai sum tensor(0.8574, device='cuda:0', dtype=torch.float16) q[a] 0.857421875
pp sum tensor(0.9907, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8574, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9907, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8574, device='cuda:0', dtype=torch.float16)
pa tensor(0.9907, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8574, device='cuda:0', dtype=torch.float16) acp tensor(1.1553, device='cuda:0', dtype=torch.float16) r 0.47475516333770984

-------------------step: 2-------------------

directly accept a 29896

-------------------step: 3-------------------

x1 29929 x2 29900 a 29929
q[a] 0.228515625 q[x1] 0.228515625 q[x2] 0.198486328125
gtp[x1] 4.172325134277344e-07 gtp[x2] 2.980232238769531e-07 gtp[a] 4.172325134277344e-07
pp sum tensor(0.9912, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7622, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(4.1723e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7622, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0588, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.09480663818630575
q_ai sum tensor(0.2285, device='cuda:0', dtype=torch.float16) q[a] 0.228515625
pp sum tensor(0.9888, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2260, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(4.1723e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2260, device='cuda:0', dtype=torch.float16)
pa tensor(4.1723e-07, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2260, device='cuda:0', dtype=torch.float16) acp tensor(1.8477e-06, device='cuda:0', dtype=torch.float16) r 0.568378779878045
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9888, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 29896

-------------------step: 2-------------------

directly accept a 29955

-------------------step: 3-------------------

directly accept a 29955

-------------------step: 1-------------------

directly accept a 943

-------------------step: 2-------------------

directly accept a 322

-------------------step: 3-------------------

x1 9418 x2 5144 a 5144
q[a] 0.06439208984375 q[x1] 0.00027370452880859375 q[x2] 0.06439208984375
gtp[x1] 0.0 gtp[x2] 5.960464477539063e-08 gtp[a] 5.960464477539063e-08
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0003, device='cuda:0') acp tensor(0., device='cuda:0') r 0.8518807444538914
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9341, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(5.9605e-08, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.9341, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0643, device='cuda:0', dtype=torch.float16) q[a] 0.06439208984375
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0642, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(5.9605e-08, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0642, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.9341, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9129140776313879
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9985, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 1475

-------------------step: 2-------------------

x1 1058 x2 5069 a 1058
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 0.00017392635345458984
gtp[x1] 0.9990234375 gtp[x2] 4.172325134277344e-06 gtp[a] 0.9990234375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0002, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0002, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5122, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.007820841226558573
q_ai sum tensor(0.9995, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.22165593221232605

-------------------step: 3-------------------

x1 892 x2 5714 a 892
q[a] 0.5439453125 q[x1] 0.5439453125 q[x2] 0.2529296875
gtp[x1] 0.00037360191345214844 gtp[x2] 0.998046875 gtp[a] 0.00037360191345214844
pp sum tensor(0.7456, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2019, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0004, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7451, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2019, device='cuda:0', dtype=torch.float16)
px2 tensor(0.7451, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3018, device='cuda:0', dtype=torch.float16) acp tensor(2.4688, device='cuda:0', dtype=torch.float16) r 0.7253915829981222

-------------------step: 1-------------------

directly accept a 12080

-------------------step: 2-------------------

x1 29889 x2 491 a 29889
q[a] 0.93603515625 q[x1] 0.93603515625 q[x2] 6.085634231567383e-05
gtp[x1] 0.0109405517578125 gtp[x2] 0.0 gtp[a] 0.0109405517578125
pp sum tensor(0.9512, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0148, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0109, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0148, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0009, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3854119327155596
q_ai sum tensor(0.9360, device='cuda:0', dtype=torch.float16) q[a] 0.93603515625
pp sum tensor(0.2468, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2313, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0109, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2313, device='cuda:0', dtype=torch.float16)
pa tensor(0.0109, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2313, device='cuda:0', dtype=torch.float16) acp tensor(0.0473, device='cuda:0', dtype=torch.float16) r 0.5614527881317553
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.2358, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 278 x2 393 a 278
q[a] 0.9951171875 q[x1] 0.9951171875 q[x2] 0.00490570068359375
gtp[x1] 0.998046875 gtp[x2] 0.0017538070678710938 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0032, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0032, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9805, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7984538056091283
q_ai sum tensor(0.9951, device='cuda:0', dtype=torch.float16) q[a] 0.9951171875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9946, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9946, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9946, device='cuda:0', dtype=torch.float16) acp tensor(1.0039, device='cuda:0', dtype=torch.float16) r 0.7136326923517425

-------------------step: 2-------------------

x1 2 x2 5337 a 2
q[a] 0.59423828125 q[x1] 0.59423828125 q[x2] 0.152587890625
gtp[x1] 0.00043010711669921875 gtp[x2] 0.99853515625 gtp[a] 0.00043010711669921875
pp sum tensor(0.8462, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2520, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0004, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8457, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2520, device='cuda:0', dtype=torch.float16)
px2 tensor(0.8457, device='cuda:0', dtype=torch.float16) qx2 tensor(0.2235, device='cuda:0', dtype=torch.float16) acp tensor(3.7832, device='cuda:0', dtype=torch.float16) r 0.2802711323060606

-------------------step: 3-------------------

x1 29889 x2 13 a 29889
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 7.152557373046875e-06
gtp[x1] 0.9990234375 gtp[x2] 2.8848648071289062e-05 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(3.5346e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.1696e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(3.5346e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(2.1696e-05, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0237, device='cuda:0', dtype=torch.float16) acp tensor(0.0009, device='cuda:0', dtype=torch.float16) r 0.4084222760803963
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.9934228354857064

-------------------step: 1-------------------

directly accept a 13

-------------------step: 2-------------------

x1 2744 x2 2831 a 2744
q[a] 0.625 q[x1] 0.625 q[x2] 0.202880859375
gtp[x1] 0.368896484375 gtp[x2] 0.368896484375 gtp[a] 0.368896484375
pp sum tensor(0.6919, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0668, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3689, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.1660, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0668, device='cuda:0', dtype=torch.float16)
px2 tensor(0.1660, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3381, device='cuda:0', dtype=torch.float16) acp tensor(0.4910, device='cuda:0', dtype=torch.float16) r 0.3864099303998344

-------------------step: 3-------------------

x1 263 x2 385 a 263
q[a] 0.488525390625 q[x1] 0.488525390625 q[x2] 0.0682373046875
gtp[x1] 0.84619140625 gtp[x2] 0.010650634765625 gtp[a] 0.84619140625
pp sum tensor(0.8936, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4050, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8462, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4050, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0651, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9194332272211349
q_ai sum tensor(0.4885, device='cuda:0', dtype=torch.float16) q[a] 0.488525390625
pp sum tensor(0.8501, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4448, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8462, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4448, device='cuda:0', dtype=torch.float16)
pa tensor(0.8462, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4448, device='cuda:0', dtype=torch.float16) acp tensor(1.9023, device='cuda:0', dtype=torch.float16) r 0.1986252628212265

-------------------step: 1-------------------

x1 16375 x2 427 a 16375
q[a] 0.54248046875 q[x1] 0.54248046875 q[x2] 0.005840301513671875
gtp[x1] 0.245849609375 gtp[x2] 0.002246856689453125 gtp[a] 0.245849609375
pp sum tensor(0.7280, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1855, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2458, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1855, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0069, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9018387450163495
q_ai sum tensor(0.5425, device='cuda:0', dtype=torch.float16) q[a] 0.54248046875
pp sum tensor(0.5698, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3840, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.2458, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3840, device='cuda:0', dtype=torch.float16)
pa tensor(0.2458, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3840, device='cuda:0', dtype=torch.float16) acp tensor(0.6401, device='cuda:0', dtype=torch.float16) r 0.6264331485860853

-------------------step: 2-------------------

x1 7271 x2 322 a 7271
q[a] 0.5751953125 q[x1] 0.5751953125 q[x2] 0.312744140625
gtp[x1] 0.9951171875 gtp[x2] 0.0033721923828125 gtp[a] 0.9951171875
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4197, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9951, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4197, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4238, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6033083867243038
q_ai sum tensor(0.5752, device='cuda:0', dtype=torch.float16) q[a] 0.5751953125
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5752, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9951, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5752, device='cuda:0', dtype=torch.float16)
pa tensor(0.9951, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5752, device='cuda:0', dtype=torch.float16) acp tensor(1.7305, device='cuda:0', dtype=torch.float16) r 0.6224443759990753

-------------------step: 3-------------------

x1 29892 x2 297 a 29892
q[a] 0.99365234375 q[x1] 0.99365234375 q[x2] 0.002704620361328125
gtp[x1] 0.9990234375 gtp[x2] 0.00022673606872558594 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0053, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0053, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4163, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6270851095782809
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16) q[a] 0.99365234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9937, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9937, device='cuda:0', dtype=torch.float16) acp tensor(1.0059, device='cuda:0', dtype=torch.float16) r 0.661841022995086

-------------------step: 1-------------------

x1 304 x2 508 a 508
q[a] 0.4228515625 q[x1] 0.212646484375 q[x2] 0.4228515625
gtp[x1] 0.004344940185546875 gtp[x2] 0.7900390625 gtp[a] 0.7900390625
px1 tensor(0.0043, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2126, device='cuda:0') acp tensor(0.0204, device='cuda:0') r 0.6747019108232699
pp sum tensor(0.9780, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5547, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7900, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5547, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4229, device='cuda:0', dtype=torch.float16) q[a] 0.4228515625
pp sum tensor(0.9668, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4116, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7900, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4116, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3784, device='cuda:0', dtype=torch.float16)
pa tensor(0.3784, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5547, device='cuda:0', dtype=torch.float16) acp tensor(0.6821, device='cuda:0', dtype=torch.float16) r 0.7001817109885642
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1768, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 884 x2 6493 a 6493
q[a] 0.302001953125 q[x1] 0.2174072265625 q[x2] 0.302001953125
gtp[x1] 0.31787109375 gtp[x2] 0.170166015625 gtp[a] 0.170166015625
px1 tensor(0.3179, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2174, device='cuda:0') acp tensor(1.4621, device='cuda:0') r 0.48902274169807924

-------------------step: 2-------------------

x1 6493 x2 2125 a 6493
q[a] 0.548828125 q[x1] 0.548828125 q[x2] 0.0882568359375
gtp[x1] 0.2288818359375 gtp[x2] 0.09246826171875 gtp[a] 0.2288818359375
pp sum tensor(0.6631, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1140, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2289, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0042, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1140, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0042, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1074, device='cuda:0', dtype=torch.float16) acp tensor(0.0392, device='cuda:0', dtype=torch.float16) r 0.7676027099586631
q_ai sum tensor(0.5488, device='cuda:0', dtype=torch.float16) q[a] 0.548828125
pp sum tensor(0.5850, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4709, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.2289, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4709, device='cuda:0', dtype=torch.float16)
pa tensor(0.2289, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4709, device='cuda:0', dtype=torch.float16) acp tensor(0.4861, device='cuda:0', dtype=torch.float16) r 0.2665512768913758

-------------------step: 3-------------------

x1 278 x2 438 a 278
q[a] 0.99462890625 q[x1] 0.99462890625 q[x2] 4.553794860839844e-05
gtp[x1] 0.99169921875 gtp[x2] 1.5497207641601562e-06 gtp[a] 0.99169921875
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0049, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0049, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0087, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.04215328811204622
q_ai sum tensor(0.9946, device='cuda:0', dtype=torch.float16) q[a] 0.99462890625
pp sum tensor(0.9946, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9897, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9897, device='cuda:0', dtype=torch.float16)
pa tensor(0.9917, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9897, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.1151331395649513

-------------------step: 1-------------------

directly accept a 324

-------------------step: 2-------------------

x1 433 x2 3270 a 3270
q[a] 0.56396484375 q[x1] 0.004878997802734375 q[x2] 0.56396484375
gtp[x1] 4.3272972106933594e-05 gtp[x2] 0.99853515625 gtp[a] 0.99853515625
px1 tensor(4.3273e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0049, device='cuda:0') acp tensor(0.0089, device='cuda:0') r 0.5764377516394107
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4346, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9985, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4346, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5640, device='cuda:0', dtype=torch.float16) q[a] 0.56396484375
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5640, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9985, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5640, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4346, device='cuda:0', dtype=torch.float16)
pa tensor(0.4346, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4346, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.4363608553691162

-------------------step: 3-------------------

x1 3086 x2 19722 a 3086
q[a] 0.521484375 q[x1] 0.521484375 q[x2] 0.03155517578125
gtp[x1] 0.0 gtp[x2] 0.0 gtp[a] 0.0
pp sum tensor(0.8643, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3425, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3425, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0344, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9427055926215748
q_ai sum tensor(0.5215, device='cuda:0', dtype=torch.float16) q[a] 0.521484375
pp sum tensor(0.7158, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3733, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3733, device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3733, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9007135895154955
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7158, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 29892 x2 29889 a 29892
q[a] 0.99169921875 q[x1] 0.99169921875 q[x2] 0.007114410400390625
gtp[x1] 0.900390625 gtp[x2] 0.09942626953125 gtp[a] 0.900390625
pp sum tensor(0.9927, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0009, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9004, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0923, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0009, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0923, device='cuda:0', dtype=torch.float16) qx2 tensor(0.8555, device='cuda:0', dtype=torch.float16) acp tensor(0.1078, device='cuda:0', dtype=torch.float16) r 0.6175299810616108
q_ai sum tensor(0.9917, device='cuda:0', dtype=torch.float16) q[a] 0.99169921875
pp sum tensor(0.9004, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8994, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9004, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8994, device='cuda:0', dtype=torch.float16)
pa tensor(0.9004, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8994, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.016161835204221098

-------------------step: 2-------------------

x1 263 x2 278 a 263
q[a] 0.734375 q[x1] 0.734375 q[x2] 0.1744384765625
gtp[x1] 0.0035247802734375 gtp[x2] 0.97705078125 gtp[a] 0.0035247802734375
pp sum tensor(0.8140, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0795, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0035, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.8027, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0795, device='cuda:0', dtype=torch.float16)
px2 tensor(0.8027, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4822, device='cuda:0', dtype=torch.float16) acp tensor(1.6650, device='cuda:0', dtype=torch.float16) r 0.9582369937009337

-------------------step: 3-------------------

x1 10150 x2 871 a 871
q[a] 0.39013671875 q[x1] 0.02984619140625 q[x2] 0.39013671875
gtp[x1] 6.9141387939453125e-06 gtp[x2] 0.99658203125 gtp[a] 0.99658203125
px1 tensor(6.9141e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0298, device='cuda:0') acp tensor(0.0002, device='cuda:0') r 0.9693967209082625
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6064, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9966, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6064, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3904, device='cuda:0', dtype=torch.float16) q[a] 0.39013671875
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3904, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9966, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3904, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6064, device='cuda:0', dtype=torch.float16)
pa tensor(0.6064, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6064, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.8792693049015288

-------------------step: 1-------------------

directly accept a 15150

-------------------step: 2-------------------

directly accept a 24369

-------------------step: 3-------------------

directly accept a 297

-------------------step: 1-------------------

directly accept a 3303

-------------------step: 2-------------------

directly accept a 3900

-------------------step: 3-------------------

x1 29889 x2 29892 a 29889
q[a] 0.9931640625 q[x1] 0.9931640625 q[x2] 0.004528045654296875
gtp[x1] 0.9892578125 gtp[x2] 0.00817108154296875 gtp[a] 0.9892578125
pp sum tensor(0.9941, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0009, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9893, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0036, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0009, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0036, device='cuda:0', dtype=torch.float16) qx2 tensor(0.6714, device='cuda:0', dtype=torch.float16) acp tensor(0.0054, device='cuda:0', dtype=torch.float16) r 0.1272510518639255
q_ai sum tensor(0.9932, device='cuda:0', dtype=torch.float16) q[a] 0.9931640625
pp sum tensor(0.9893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9888, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9893, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9888, device='cuda:0', dtype=torch.float16)
pa tensor(0.9893, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9888, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.28552034419225436

-------------------step: 1-------------------

x1 15839 x2 22879 a 22879
q[a] 0.1651611328125 q[x1] 0.044097900390625 q[x2] 0.1651611328125
gtp[x1] 0.0005578994750976562 gtp[x2] 0.0012578964233398438 gtp[a] 0.0012578964233398438
px1 tensor(0.0006, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0441, device='cuda:0') acp tensor(0.0127, device='cuda:0') r 0.4322305593585425
pp sum tensor(0.9028, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7373, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0013, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7373, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1650, device='cuda:0', dtype=torch.float16) q[a] 0.1651611328125
pp sum tensor(0.8877, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1499, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0013, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1499, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7373, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.20242148413903926
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8862, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 27389

-------------------step: 2-------------------

x1 24369 x2 3268 a 24369
q[a] 0.99365234375 q[x1] 0.99365234375 q[x2] 0.00010406970977783203
gtp[x1] 0.9990234375 gtp[x2] 1.430511474609375e-06 gtp[a] 0.9990234375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0058, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0058, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0158, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.995107724551594
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16) q[a] 0.99365234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9932, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9932, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9932, device='cuda:0', dtype=torch.float16) acp tensor(1.0059, device='cuda:0', dtype=torch.float16) r 0.2982589048231421

-------------------step: 3-------------------

x1 471 x2 338 a 471
q[a] 0.94189453125 q[x1] 0.94189453125 q[x2] 0.01837158203125
gtp[x1] 0.96728515625 gtp[x2] 4.458427429199219e-05 gtp[a] 0.96728515625
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0542, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9673, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0542, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2991, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9724898640257872
q_ai sum tensor(0.9419, device='cuda:0', dtype=torch.float16) q[a] 0.94189453125
pp sum tensor(0.9912, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9365, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9673, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9365, device='cuda:0', dtype=torch.float16)
pa tensor(0.9673, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9365, device='cuda:0', dtype=torch.float16) acp tensor(1.0332, device='cuda:0', dtype=torch.float16) r 0.4667182400147387

-------------------step: 1-------------------

directly accept a 6221

-------------------step: 2-------------------

directly accept a 25488

-------------------step: 3-------------------

directly accept a 310

-------------------step: 1-------------------

directly accept a 26901

-------------------step: 2-------------------

directly accept a 713

-------------------step: 3-------------------

x1 15150 x2 1601 a 15150
q[a] 0.47900390625 q[x1] 0.47900390625 q[x2] 0.01247406005859375
gtp[x1] 4.112720489501953e-06 gtp[x2] 6.920099258422852e-05 gtp[a] 4.112720489501953e-06
pp sum tensor(0.6836, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2041, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(4.1127e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2041, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0115, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.33412033402169306
q_ai sum tensor(0.4792, device='cuda:0', dtype=torch.float16) q[a] 0.47900390625
pp sum tensor(0.3923, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1880, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(4.1127e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1880, device='cuda:0', dtype=torch.float16)
pa tensor(4.1127e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1880, device='cuda:0', dtype=torch.float16) acp tensor(2.1875e-05, device='cuda:0', dtype=torch.float16) r 0.07300609685202875
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.3923, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 29879

-------------------step: 2-------------------

directly accept a 515

-------------------step: 3-------------------

directly accept a 29871

-------------------step: 1-------------------

directly accept a 29947

-------------------step: 2-------------------

x1 2 x2 29929 a 29929
q[a] 0.2076416015625 q[x1] 0.069580078125 q[x2] 0.2076416015625
gtp[x1] 5.3882598876953125e-05 gtp[x2] 2.0265579223632812e-06 gtp[a] 2.0265579223632812e-06
px1 tensor(5.3883e-05, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0696, device='cuda:0') acp tensor(0.0008, device='cuda:0') r 0.7452627581536836
pp sum tensor(0.9546, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7471, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.0266e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7471, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2076, device='cuda:0', dtype=torch.float16) q[a] 0.2076416015625
pp sum tensor(0.9429, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1957, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.0266e-06, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1957, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7471, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6569805548859834
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9429, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 29945

-------------------step: 2-------------------

directly accept a 304

-------------------step: 3-------------------

directly accept a 29871

-------------------step: 1-------------------

x1 29929 x2 29947 a 29929
q[a] 1.0 q[x1] 1.0 q[x2] 3.6954879760742188e-06
gtp[x1] 3.594160079956055e-05 gtp[x2] 1.0 gtp[a] 3.594160079956055e-05
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(5.9605e-08, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(3.5942e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(5.9605e-08, device='cuda:0', dtype=torch.float16)
px2 tensor(1., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8613, device='cuda:0', dtype=torch.float16) acp tensor(1.1611, device='cuda:0', dtype=torch.float16) r 0.6238517474397968

-------------------step: 2-------------------

directly accept a 29929

-------------------step: 3-------------------

x1 29955 x2 29896 a 29896
q[a] 0.493896484375 q[x1] 0.42236328125 q[x2] 0.493896484375
gtp[x1] 2.384185791015625e-07 gtp[x2] 7.152557373046875e-07 gtp[a] 7.152557373046875e-07
px1 tensor(2.3842e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.4224, device='cuda:0') acp tensor(5.6449e-07, device='cuda:0') r 0.5607401533576521
pp sum tensor(0.9810, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4868, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(7.1526e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4868, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4939, device='cuda:0', dtype=torch.float16) q[a] 0.493896484375
pp sum tensor(0.9624, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4753, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(7.1526e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4753, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4868, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.008505273153873283
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9624, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 29892 x2 29889 a 29892
q[a] 0.75634765625 q[x1] 0.75634765625 q[x2] 0.24169921875
gtp[x1] 0.65380859375 gtp[x2] 0.045928955078125 gtp[a] 0.65380859375
pp sum tensor(0.9531, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1969, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.6538, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1969, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7495, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.940560906264436
q_ai sum tensor(0.7563, device='cuda:0', dtype=torch.float16) q[a] 0.75634765625
pp sum tensor(0.9521, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7554, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.6538, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7554, device='cuda:0', dtype=torch.float16)
pa tensor(0.6538, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7554, device='cuda:0', dtype=torch.float16) acp tensor(0.8657, device='cuda:0', dtype=torch.float16) r 0.35470665279128244

-------------------step: 2-------------------

x1 322 x2 2645 a 322
q[a] 0.9443359375 q[x1] 0.9443359375 q[x2] 8.45789909362793e-05
gtp[x1] 0.99658203125 gtp[x2] 4.172325134277344e-07 gtp[a] 0.99658203125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0547, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0547, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0014, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7298787662852348
q_ai sum tensor(0.9443, device='cuda:0', dtype=torch.float16) q[a] 0.9443359375
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9419, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9419, device='cuda:0', dtype=torch.float16)
pa tensor(0.9966, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9419, device='cuda:0', dtype=torch.float16) acp tensor(1.0576, device='cuda:0', dtype=torch.float16) r 0.30013507325022615

-------------------step: 3-------------------

x1 372 x2 471 a 471
q[a] 0.5078125 q[x1] 0.215087890625 q[x2] 0.5078125
gtp[x1] 0.004520416259765625 gtp[x2] 2.1278858184814453e-05 gtp[a] 2.1278858184814453e-05
px1 tensor(0.0045, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2151, device='cuda:0') acp tensor(0.0210, device='cuda:0') r 0.20093341253721198
pp sum tensor(0.9668, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4590, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.1279e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4590, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5078, device='cuda:0', dtype=torch.float16) q[a] 0.5078125
pp sum tensor(0.9497, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4905, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.1279e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4905, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4590, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4456969546640517
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9497, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 408

-------------------step: 2-------------------

x1 263 x2 385 a 263
q[a] 0.9931640625 q[x1] 0.9931640625 q[x2] 0.005458831787109375
gtp[x1] 0.9990234375 gtp[x2] 0.0008039474487304688 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0062, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0062, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7705, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.581446068384971
q_ai sum tensor(0.9927, device='cuda:0', dtype=torch.float16) q[a] 0.9931640625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9927, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9927, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9927, device='cuda:0', dtype=torch.float16) acp tensor(1.0068, device='cuda:0', dtype=torch.float16) r 0.4322839760665418

-------------------step: 3-------------------

x1 6282 x2 21028 a 6282
q[a] 0.53125 q[x1] 0.53125 q[x2] 0.042938232421875
gtp[x1] 5.364418029785156e-07 gtp[x2] 0.99951171875 gtp[a] 5.364418029785156e-07
pp sum tensor(0.9565, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4253, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(5.3644e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9565, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4253, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9565, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0487, device='cuda:0', dtype=torch.float16) acp tensor(19.6562, device='cuda:0', dtype=torch.float16) r 0.4103735542755773

-------------------step: 1-------------------

directly accept a 1218

-------------------step: 2-------------------

x1 1106 x2 6282 a 1106
q[a] 0.450439453125 q[x1] 0.450439453125 q[x2] 0.1331787109375
gtp[x1] 0.998046875 gtp[x2] 2.1457672119140625e-06 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5474, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5474, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1092, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1717990976024698
q_ai sum tensor(0.4504, device='cuda:0', dtype=torch.float16) q[a] 0.450439453125
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4504, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4504, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4504, device='cuda:0', dtype=torch.float16) acp tensor(2.2148, device='cuda:0', dtype=torch.float16) r 0.2953866357003907

-------------------step: 3-------------------

directly accept a 964

-------------------step: 1-------------------

directly accept a 29875

-------------------step: 2-------------------

directly accept a 29915

-------------------step: 3-------------------

directly accept a 29879

-------------------step: 1-------------------

directly accept a 322

-------------------step: 2-------------------

directly accept a 278

-------------------step: 3-------------------

x1 27217 x2 8261 a 8261
q[a] 0.1593017578125 q[x1] 0.0001652240753173828 q[x2] 0.1593017578125
gtp[x1] 0.0 gtp[x2] 1.1920928955078125e-07 gtp[a] 1.1920928955078125e-07
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0002, device='cuda:0') acp tensor(0., device='cuda:0') r 0.5415000217270828
pp sum tensor(0.9731, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8135, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.1921e-07, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.8135, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1592, device='cuda:0', dtype=torch.float16) q[a] 0.1593017578125
pp sum tensor(0.9683, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1542, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.1921e-07, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1542, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.8135, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.267911711105401
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9683, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 310

-------------------step: 2-------------------

directly accept a 967

-------------------step: 3-------------------

x1 15150 x2 25552 a 15150
q[a] 0.9599609375 q[x1] 0.9599609375 q[x2] 0.006221771240234375
gtp[x1] 0.998046875 gtp[x2] 7.587671279907227e-05 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0381, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0381, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1503, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.44525266036671796
q_ai sum tensor(0.9600, device='cuda:0', dtype=torch.float16) q[a] 0.9599609375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9600, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9600, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9600, device='cuda:0', dtype=torch.float16) acp tensor(1.0400, device='cuda:0', dtype=torch.float16) r 0.5517068022506895

-------------------step: 1-------------------

directly accept a 29889

-------------------step: 2-------------------

x1 530 x2 13 a 13
q[a] 0.425537109375 q[x1] 0.0019550323486328125 q[x2] 0.425537109375
gtp[x1] 0.0001399517059326172 gtp[x2] 0.099853515625 gtp[a] 0.099853515625
px1 tensor(0.0001, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0020, device='cuda:0') acp tensor(0.0716, device='cuda:0') r 0.5778584422707447
pp sum tensor(0.7490, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3240, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0999, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3240, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4255, device='cuda:0', dtype=torch.float16) q[a] 0.425537109375
pp sum tensor(0.6719, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3481, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0999, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3481, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3240, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6426987761690321
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5718, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 2247 x2 9197 a 2247
q[a] 0.9404296875 q[x1] 0.9404296875 q[x2] 0.004093170166015625
gtp[x1] 0.093994140625 gtp[x2] 0.3896484375 gtp[a] 0.093994140625
pp sum tensor(0.9619, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0216, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0940, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3855, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0216, device='cuda:0', dtype=torch.float16)
px2 tensor(0.3855, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0647, device='cuda:0', dtype=torch.float16) acp tensor(5.9570, device='cuda:0', dtype=torch.float16) r 0.5420246349539248

-------------------step: 2-------------------

x1 508 x2 674 a 508
q[a] 0.62548828125 q[x1] 0.62548828125 q[x2] 0.0679931640625
gtp[x1] 0.92919921875 gtp[x2] 0.00479888916015625 gtp[a] 0.92919921875
pp sum tensor(0.9741, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3484, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9292, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3484, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1136, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.09109055728221649
q_ai sum tensor(0.6255, device='cuda:0', dtype=torch.float16) q[a] 0.62548828125
pp sum tensor(0.9692, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6206, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9292, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6206, device='cuda:0', dtype=torch.float16)
pa tensor(0.9292, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6206, device='cuda:0', dtype=torch.float16) acp tensor(1.4971, device='cuda:0', dtype=torch.float16) r 0.3528850394103814

-------------------step: 3-------------------

x1 2125 x2 1074 a 2125
q[a] 0.42529296875 q[x1] 0.42529296875 q[x2] 0.0181121826171875
gtp[x1] 0.97998046875 gtp[x2] 8.046627044677734e-06 gtp[a] 0.97998046875
pp sum tensor(0.9805, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5557, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9800, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5557, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0134, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7347421336538768
q_ai sum tensor(0.4253, device='cuda:0', dtype=torch.float16) q[a] 0.42529296875
pp sum tensor(0.9800, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4248, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9800, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4248, device='cuda:0', dtype=torch.float16)
pa tensor(0.9800, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4248, device='cuda:0', dtype=torch.float16) acp tensor(2.3066, device='cuda:0', dtype=torch.float16) r 0.13480834662760655

-------------------step: 1-------------------

x1 6282 x2 1410 a 6282
q[a] 0.49365234375 q[x1] 0.49365234375 q[x2] 0.409423828125
gtp[x1] 0.90283203125 gtp[x2] 0.0908203125 gtp[a] 0.90283203125
pp sum tensor(0.9028, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4089, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9028, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4089, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3992, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3590744670163878
q_ai sum tensor(0.4937, device='cuda:0', dtype=torch.float16) q[a] 0.49365234375
pp sum tensor(0.9028, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4937, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9028, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4937, device='cuda:0', dtype=torch.float16)
pa tensor(0.9028, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4937, device='cuda:0', dtype=torch.float16) acp tensor(1.8291, device='cuda:0', dtype=torch.float16) r 0.7132698011016348

-------------------step: 2-------------------

x1 310 x2 2 a 310
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 0.00019407272338867188
gtp[x1] 0.9990234375 gtp[x2] 4.982948303222656e-05 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0003, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0003, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4646, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2831000560461605
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.4506707921582802

-------------------step: 3-------------------

directly accept a 278

-------------------step: 1-------------------

x1 322 x2 29892 a 322
q[a] 0.79052734375 q[x1] 0.79052734375 q[x2] 0.1763916015625
gtp[x1] 0.9033203125 gtp[x2] 0.08404541015625 gtp[a] 0.9033203125
pp sum tensor(0.9038, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1132, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9033, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1132, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6660, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5696677446674001
q_ai sum tensor(0.7910, device='cuda:0', dtype=torch.float16) q[a] 0.79052734375
pp sum tensor(0.9038, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7905, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9033, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7905, device='cuda:0', dtype=torch.float16)
pa tensor(0.9033, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7905, device='cuda:0', dtype=torch.float16) acp tensor(1.1426, device='cuda:0', dtype=torch.float16) r 0.26358308642265305

-------------------step: 2-------------------

x1 5110 x2 679 a 5110
q[a] 0.99365234375 q[x1] 0.99365234375 q[x2] 0.0005850791931152344
gtp[x1] 0.99609375 gtp[x2] 2.7418136596679688e-05 gtp[a] 0.99609375
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0047, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0047, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0884, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.006039998079150788
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16) q[a] 0.99365234375
pp sum tensor(0.9961, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9912, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9961, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9912, device='cuda:0', dtype=torch.float16)
pa tensor(0.9961, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9912, device='cuda:0', dtype=torch.float16) acp tensor(1.0049, device='cuda:0', dtype=torch.float16) r 0.32614876603212617

-------------------step: 3-------------------

x1 1048 x2 2 a 1048
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 0.000209808349609375
gtp[x1] 0.9951171875 gtp[x2] 0.00015282630920410156 gtp[a] 0.9951171875
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0001, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9951, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0001, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3567, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1961103105733435
q_ai sum tensor(0.9995, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9951, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9951, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9951, device='cuda:0', dtype=torch.float16)
pa tensor(0.9951, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9951, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.07178565423682215

-------------------step: 1-------------------

x1 8261 x2 2106 a 2106
q[a] 0.294189453125 q[x1] 0.1336669921875 q[x2] 0.294189453125
gtp[x1] 0.00029015541076660156 gtp[x2] 0.99560546875 gtp[a] 0.99560546875
px1 tensor(0.0003, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1337, device='cuda:0') acp tensor(0.0022, device='cuda:0') r 0.5074788812494221
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7012, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9956, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7012, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2942, device='cuda:0', dtype=torch.float16) q[a] 0.294189453125
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2942, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9956, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2942, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7012, device='cuda:0', dtype=torch.float16)
pa tensor(0.7012, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7012, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.8005266227418351

-------------------step: 2-------------------

directly accept a 29915

-------------------step: 3-------------------

directly accept a 29879

-------------------step: 1-------------------

x1 4955 x2 4940 a 4940
q[a] 0.74853515625 q[x1] 0.2391357421875 q[x2] 0.74853515625
gtp[x1] 0.00026106834411621094 gtp[x2] 0.9990234375 gtp[a] 0.9990234375
px1 tensor(0.0003, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2391, device='cuda:0') acp tensor(0.0011, device='cuda:0') r 0.474303296961484
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2510, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2510, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7485, device='cuda:0', dtype=torch.float16) q[a] 0.74853515625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7485, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7485, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2505, device='cuda:0', dtype=torch.float16)
pa tensor(0.2505, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2510, device='cuda:0', dtype=torch.float16) acp tensor(0.9980, device='cuda:0', dtype=torch.float16) r 0.01375270282319252

-------------------step: 2-------------------

x1 515 x2 322 a 515
q[a] 0.92626953125 q[x1] 0.92626953125 q[x2] 0.04541015625
gtp[x1] 0.99658203125 gtp[x2] 0.0005960464477539062 gtp[a] 0.99658203125
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0705, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0705, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5703, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.816222954310119
q_ai sum tensor(0.9263, device='cuda:0', dtype=torch.float16) q[a] 0.92626953125
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9263, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9263, device='cuda:0', dtype=torch.float16)
pa tensor(0.9966, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9263, device='cuda:0', dtype=torch.float16) acp tensor(1.0762, device='cuda:0', dtype=torch.float16) r 0.9743855976826996

-------------------step: 3-------------------

x1 278 x2 26901 a 278
q[a] 0.93603515625 q[x1] 0.93603515625 q[x2] 0.0458984375
gtp[x1] 0.000469207763671875 gtp[x2] 0.0 gtp[a] 0.000469207763671875
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0636, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0005, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0636, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6748, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.936458765095646
q_ai sum tensor(0.9365, device='cuda:0', dtype=torch.float16) q[a] 0.93603515625
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9360, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0005, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9360, device='cuda:0', dtype=torch.float16)
pa tensor(0.0005, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9360, device='cuda:0', dtype=torch.float16) acp tensor(0.0005, device='cuda:0', dtype=torch.float16) r 0.05666908141786431
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9990, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 519

-------------------step: 2-------------------

x1 322 x2 1410 a 322
q[a] 0.93505859375 q[x1] 0.93505859375 q[x2] 0.048797607421875
gtp[x1] 0.99658203125 gtp[x2] 0.0031719207763671875 gtp[a] 0.99658203125
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0614, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0614, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7051, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3454849002852092
q_ai sum tensor(0.9351, device='cuda:0', dtype=torch.float16) q[a] 0.93505859375
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9351, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9351, device='cuda:0', dtype=torch.float16)
pa tensor(0.9966, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9351, device='cuda:0', dtype=torch.float16) acp tensor(1.0654, device='cuda:0', dtype=torch.float16) r 0.908864148001083

-------------------step: 3-------------------

directly accept a 15935

-------------------step: 1-------------------

x1 1410 x2 10754 a 1410
q[a] 0.9970703125 q[x1] 0.9970703125 q[x2] 0.0004572868347167969
gtp[x1] 0.99853515625 gtp[x2] 8.082389831542969e-05 gtp[a] 0.99853515625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0017, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0017, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1687, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.219935579849309
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16) q[a] 0.9970703125
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9971, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9971, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.17674364282586075

-------------------step: 2-------------------

directly accept a 2247

-------------------step: 3-------------------

directly accept a 29889

-------------------step: 1-------------------

directly accept a 13

-------------------step: 2-------------------

x1 2744 x2 2831 a 2831
q[a] 0.26806640625 q[x1] 0.2154541015625 q[x2] 0.26806640625
gtp[x1] 0.0198974609375 gtp[x2] 0.00030684471130371094 gtp[a] 0.00030684471130371094
px1 tensor(0.0199, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2155, device='cuda:0') acp tensor(0.0924, device='cuda:0') r 0.1826117920325362
pp sum tensor(0.7754, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5068, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0003, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5068, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2681, device='cuda:0', dtype=torch.float16) q[a] 0.26806640625
pp sum tensor(0.7520, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2444, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0003, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2444, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5068, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8888975654337796
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7515, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 1450 x2 1032 a 1032
q[a] 0.11004638671875 q[x1] 0.08770751953125 q[x2] 0.11004638671875
gtp[x1] 0.96923828125 gtp[x2] 3.933906555175781e-06 gtp[a] 3.933906555175781e-06
px1 tensor(0.9692, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0877, device='cuda:0') acp tensor(11.0508, device='cuda:0') r 0.22646910133084996

-------------------step: 2-------------------

directly accept a 1794

-------------------step: 3-------------------

x1 338 x2 17944 a 338
q[a] 0.37548828125 q[x1] 0.37548828125 q[x2] 0.00012022256851196289
gtp[x1] 1.7881393432617188e-07 gtp[x2] 0.0 gtp[a] 1.7881393432617188e-07
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6240, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.7881e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6240, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(7.2539e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.773322303722868
q_ai sum tensor(0.3757, device='cuda:0', dtype=torch.float16) q[a] 0.37548828125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3752, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(1.7881e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3752, device='cuda:0', dtype=torch.float16)
pa tensor(1.7881e-07, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3752, device='cuda:0', dtype=torch.float16) acp tensor(4.7684e-07, device='cuda:0', dtype=torch.float16) r 0.05135893900042254
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9990, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 29915 x2 16688 a 29915
q[a] 0.59716796875 q[x1] 0.59716796875 q[x2] 0.031646728515625
gtp[x1] 0.57080078125 gtp[x2] 0.003238677978515625 gtp[a] 0.57080078125
pp sum tensor(0.7490, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1514, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.5708, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1514, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0469, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8937175891544362
q_ai sum tensor(0.5972, device='cuda:0', dtype=torch.float16) q[a] 0.59716796875
pp sum tensor(0.5732, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4216, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.5708, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4216, device='cuda:0', dtype=torch.float16)
pa tensor(0.5708, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4216, device='cuda:0', dtype=torch.float16) acp tensor(1.3535, device='cuda:0', dtype=torch.float16) r 0.7765154334549028

-------------------step: 2-------------------

directly accept a 29879

-------------------step: 3-------------------

x1 9560 x2 451 a 451
q[a] 0.235107421875 q[x1] 0.041839599609375 q[x2] 0.235107421875
gtp[x1] 0.0022830963134765625 gtp[x2] 1.2516975402832031e-06 gtp[a] 1.2516975402832031e-06
px1 tensor(0.0023, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0418, device='cuda:0') acp tensor(0.0546, device='cuda:0') r 0.7211666572535733
pp sum tensor(0.8750, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6396, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.2517e-06, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6396, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2350, device='cuda:0', dtype=torch.float16) q[a] 0.235107421875
pp sum tensor(0.8389, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1989, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.2517e-06, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1989, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6396, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5390084801486518
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8389, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 15409

-------------------step: 2-------------------

x1 338 x2 756 a 338
q[a] 0.97802734375 q[x1] 0.97802734375 q[x2] 0.00017845630645751953
gtp[x1] 0.98876953125 gtp[x2] 1.537799835205078e-05 gtp[a] 0.98876953125
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0135, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9888, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0135, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0080, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.22225888868115617
q_ai sum tensor(0.9785, device='cuda:0', dtype=torch.float16) q[a] 0.97802734375
pp sum tensor(0.9888, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9756, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9888, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9756, device='cuda:0', dtype=torch.float16)
pa tensor(0.9888, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9756, device='cuda:0', dtype=torch.float16) acp tensor(1.0137, device='cuda:0', dtype=torch.float16) r 0.34491280335028396

-------------------step: 3-------------------

x1 884 x2 263 a 884
q[a] 0.7646484375 q[x1] 0.7646484375 q[x2] 0.09722900390625
gtp[x1] 0.35693359375 gtp[x2] 0.0014820098876953125 gtp[a] 0.35693359375
pp sum tensor(0.9805, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2158, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.3569, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2158, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3162, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6889391635677801
q_ai sum tensor(0.7646, device='cuda:0', dtype=torch.float16) q[a] 0.7646484375
pp sum tensor(0.9541, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7388, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.3569, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7388, device='cuda:0', dtype=torch.float16)
pa tensor(0.3569, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7388, device='cuda:0', dtype=torch.float16) acp tensor(0.4832, device='cuda:0', dtype=torch.float16) r 0.5051387037258772
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5972, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 2078 x2 380 a 2078
q[a] 0.5439453125 q[x1] 0.5439453125 q[x2] 0.2489013671875
gtp[x1] 0.043304443359375 gtp[x2] 0.95556640625 gtp[a] 0.043304443359375
pp sum tensor(0.7500, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2061, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0433, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7065, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2061, device='cuda:0', dtype=torch.float16)
px2 tensor(0.7065, device='cuda:0', dtype=torch.float16) qx2 tensor(0.2969, device='cuda:0', dtype=torch.float16) acp tensor(2.3809, device='cuda:0', dtype=torch.float16) r 0.8429812846132653

-------------------step: 2-------------------

directly accept a 27389

-------------------step: 3-------------------

x1 29892 x2 29889 a 29892
q[a] 0.7783203125 q[x1] 0.7783203125 q[x2] 0.1763916015625
gtp[x1] 0.9560546875 gtp[x2] 0.03375244140625 gtp[a] 0.9560546875
pp sum tensor(0.9590, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1810, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9561, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1810, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6182, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7927172851112123
q_ai sum tensor(0.7783, device='cuda:0', dtype=torch.float16) q[a] 0.7783203125
pp sum tensor(0.9575, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7764, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9561, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7764, device='cuda:0', dtype=torch.float16)
pa tensor(0.9561, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.7764, device='cuda:0', dtype=torch.float16) acp tensor(1.2314, device='cuda:0', dtype=torch.float16) r 0.49458863618654336

-------------------step: 1-------------------

x1 967 x2 2 a 967
q[a] 0.62939453125 q[x1] 0.62939453125 q[x2] 0.005275726318359375
gtp[x1] 0.0012807846069335938 gtp[x2] 4.738569259643555e-05 gtp[a] 0.0012807846069335938
pp sum tensor(0.8667, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2372, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0013, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2372, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0089, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7279512045643799
q_ai sum tensor(0.6294, device='cuda:0', dtype=torch.float16) q[a] 0.62939453125
pp sum tensor(0.6440, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4070, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0013, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4070, device='cuda:0', dtype=torch.float16)
pa tensor(0.0013, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4070, device='cuda:0', dtype=torch.float16) acp tensor(0.0031, device='cuda:0', dtype=torch.float16) r 0.5466805138729472
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6426, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

x1 310 x2 322 a 310
q[a] 0.9990234375 q[x1] 0.9990234375 q[x2] 0.00013124942779541016
gtp[x1] 0.994140625 gtp[x2] 0.003997802734375 gtp[a] 0.994140625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(3.8743e-06, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9941, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0039, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(3.8743e-06, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0039, device='cuda:0', dtype=torch.float16) qx2 tensor(0.1120, device='cuda:0', dtype=torch.float16) acp tensor(0.0345, device='cuda:0', dtype=torch.float16) r 0.2777777765622097
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16) q[a] 0.9990234375
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9951, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9941, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9951, device='cuda:0', dtype=torch.float16)
pa tensor(0.9941, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9951, device='cuda:0', dtype=torch.float16) acp tensor(0.9990, device='cuda:0', dtype=torch.float16) r 0.7967856471382142

-------------------step: 2-------------------

x1 22843 x2 544 a 544
q[a] 0.583984375 q[x1] 0.002349853515625 q[x2] 0.583984375
gtp[x1] 9.059906005859375e-06 gtp[x2] 0.99755859375 gtp[a] 0.99755859375
px1 tensor(9.0599e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0023, device='cuda:0') acp tensor(0.0039, device='cuda:0') r 0.2670440793230753
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4136, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9976, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4136, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5840, device='cuda:0', dtype=torch.float16) q[a] 0.583984375
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5840, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9976, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5840, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4136, device='cuda:0', dtype=torch.float16)
pa tensor(0.4136, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4136, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.3117340953148886

-------------------step: 3-------------------

directly accept a 391

-------------------step: 1-------------------

x1 367 x2 11982 a 367
q[a] 0.8310546875 q[x1] 0.8310546875 q[x2] 0.00644683837890625
gtp[x1] 0.9990234375 gtp[x2] 0.0001659393310546875 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1678, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1678, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0318, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.02393621973161031
q_ai sum tensor(0.8311, device='cuda:0', dtype=torch.float16) q[a] 0.8310546875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8311, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8311, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8311, device='cuda:0', dtype=torch.float16) acp tensor(1.2021, device='cuda:0', dtype=torch.float16) r 0.51679657872376

-------------------step: 2-------------------

directly accept a 14520

-------------------step: 3-------------------

x1 29892 x2 322 a 29892
q[a] 0.92041015625 q[x1] 0.92041015625 q[x2] 0.07794189453125
gtp[x1] 0.986328125 gtp[x2] 0.0130157470703125 gtp[a] 0.986328125
pp sum tensor(0.9868, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0662, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0662, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9009, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7836444256532891
q_ai sum tensor(0.9199, device='cuda:0', dtype=torch.float16) q[a] 0.92041015625
pp sum tensor(0.9863, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9199, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9199, device='cuda:0', dtype=torch.float16)
pa tensor(0.9863, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9199, device='cuda:0', dtype=torch.float16) acp tensor(1.0723, device='cuda:0', dtype=torch.float16) r 0.5889435114616686

-------------------step: 1-------------------

directly accept a 1878

-------------------step: 2-------------------

directly accept a 17251

-------------------step: 3-------------------

directly accept a 1454

-------------------step: 1-------------------

x1 29892 x2 2 a 29892
q[a] 0.99609375 q[x1] 0.99609375 q[x2] 0.0013217926025390625
gtp[x1] 0.9990234375 gtp[x2] 0.00045800209045410156 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0027, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0027, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3577, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.21988265088714665
q_ai sum tensor(0.9961, device='cuda:0', dtype=torch.float16) q[a] 0.99609375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9961, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9961, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9961, device='cuda:0', dtype=torch.float16) acp tensor(1.0029, device='cuda:0', dtype=torch.float16) r 0.7110073053223045

-------------------step: 2-------------------

x1 322 x2 4094 a 322
q[a] 0.99267578125 q[x1] 0.99267578125 q[x2] 0.00014662742614746094
gtp[x1] 0.9990234375 gtp[x2] 4.3272972106933594e-05 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0066, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0066, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0197, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.35006409841460273
q_ai sum tensor(0.9927, device='cuda:0', dtype=torch.float16) q[a] 0.99267578125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9927, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9927, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9927, device='cuda:0', dtype=torch.float16) acp tensor(1.0068, device='cuda:0', dtype=torch.float16) r 0.525635808409833

-------------------step: 3-------------------

x1 19372 x2 724 a 19372
q[a] 0.810546875 q[x1] 0.810546875 q[x2] 0.0005984306335449219
gtp[x1] 0.998046875 gtp[x2] 4.76837158203125e-07 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1879, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1879, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0026, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.43736482009489563
q_ai sum tensor(0.8105, device='cuda:0', dtype=torch.float16) q[a] 0.810546875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8105, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8105, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8105, device='cuda:0', dtype=torch.float16) acp tensor(1.2314, device='cuda:0', dtype=torch.float16) r 0.7681196414770111

-------------------step: 1-------------------

directly accept a 4094

-------------------step: 2-------------------

directly accept a 12559

-------------------step: 3-------------------

x1 29889 x2 393 a 29889
q[a] 0.9970703125 q[x1] 0.9970703125 q[x2] 0.0010633468627929688
gtp[x1] 0.99658203125 gtp[x2] 0.0014753341674804688 gtp[a] 0.99658203125
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0006, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0004, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0006, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0004, device='cuda:0', dtype=torch.float16) qx2 tensor(0.3752, device='cuda:0', dtype=torch.float16) acp tensor(0.0011, device='cuda:0', dtype=torch.float16) r 0.9105104646128452
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16) q[a] 0.9970703125
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9956, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9956, device='cuda:0', dtype=torch.float16)
pa tensor(0.9966, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9956, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.03570972914047699

-------------------step: 1-------------------

directly accept a 310

-------------------step: 2-------------------

directly accept a 278

-------------------step: 3-------------------

x1 1556 x2 298 a 1556
q[a] 0.79296875 q[x1] 0.79296875 q[x2] 7.677078247070312e-05
gtp[x1] 0.00211334228515625 gtp[x2] 2.384185791015625e-07 gtp[a] 0.00211334228515625
pp sum tensor(0.8135, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0209, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0021, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0209, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0003, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.36533422951492855
q_ai sum tensor(0.7930, device='cuda:0', dtype=torch.float16) q[a] 0.79296875
pp sum tensor(0.1038, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0833, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0021, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.0833, device='cuda:0', dtype=torch.float16)
pa tensor(0.0021, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.0833, device='cuda:0', dtype=torch.float16) acp tensor(0.0254, device='cuda:0', dtype=torch.float16) r 0.5955141409106063
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.1017, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 367 x2 805 a 367
q[a] 0.994140625 q[x1] 0.994140625 q[x2] 0.0008516311645507812
gtp[x1] 0.99658203125 gtp[x2] 1.1265277862548828e-05 gtp[a] 0.99658203125
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0036, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0036, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1514, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4289744733740126
q_ai sum tensor(0.9941, device='cuda:0', dtype=torch.float16) q[a] 0.994140625
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9927, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9927, device='cuda:0', dtype=torch.float16)
pa tensor(0.9966, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9927, device='cuda:0', dtype=torch.float16) acp tensor(1.0039, device='cuda:0', dtype=torch.float16) r 0.093675328927604

-------------------step: 2-------------------

directly accept a 14520

-------------------step: 3-------------------

x1 304 x2 297 a 304
q[a] 0.96142578125 q[x1] 0.96142578125 q[x2] 0.01788330078125
gtp[x1] 0.9990234375 gtp[x2] 4.9054622650146484e-05 gtp[a] 0.9990234375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0383, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0383, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4448, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.19860261406676372
q_ai sum tensor(0.9614, device='cuda:0', dtype=torch.float16) q[a] 0.96142578125
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9614, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9614, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9614, device='cuda:0', dtype=torch.float16) acp tensor(1.0391, device='cuda:0', dtype=torch.float16) r 0.1900564529199641

-------------------step: 1-------------------

x1 338 x2 297 a 338
q[a] 0.9912109375 q[x1] 0.9912109375 q[x2] 0.00431060791015625
gtp[x1] 0.2958984375 gtp[x2] 0.65625 gtp[a] 0.2958984375
pp sum tensor(0.9922, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0012, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.2959, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.6519, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0012, device='cuda:0', dtype=torch.float16)
px2 tensor(0.6519, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4744, device='cuda:0', dtype=torch.float16) acp tensor(1.3740, device='cuda:0', dtype=torch.float16) r 0.9784290811851222

-------------------step: 2-------------------

x1 278 x2 26901 a 26901
q[a] 0.76220703125 q[x1] 0.201904296875 q[x2] 0.76220703125
gtp[x1] 0.0018100738525390625 gtp[x2] 0.998046875 gtp[a] 0.998046875
px1 tensor(0.0018, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2019, device='cuda:0') acp tensor(0.0090, device='cuda:0') r 0.756669444325224
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2358, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9980, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2358, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7617, device='cuda:0', dtype=torch.float16) q[a] 0.76220703125
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7617, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9980, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.7617, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.2363, device='cuda:0', dtype=torch.float16)
pa tensor(0.2363, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.2358, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.46581170747512457

-------------------step: 3-------------------

directly accept a 29875

-------------------step: 1-------------------

x1 263 x2 319 a 319
q[a] 0.358154296875 q[x1] 0.036590576171875 q[x2] 0.358154296875
gtp[x1] 6.496906280517578e-06 gtp[x2] 0.0002028942108154297 gtp[a] 0.0002028942108154297
px1 tensor(6.4969e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0366, device='cuda:0') acp tensor(0.0002, device='cuda:0') r 0.553540823813893
pp sum tensor(0.8711, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5132, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0002, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5132, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3582, device='cuda:0', dtype=torch.float16) q[a] 0.358154296875
pp sum tensor(0.8008, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2881, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0002, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2881, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5132, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8823648237978059
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8008, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 638

-------------------step: 2-------------------

directly accept a 10058

-------------------step: 3-------------------

directly accept a 17594

-------------------step: 1-------------------

x1 411 x2 263 a 411
q[a] 0.865234375 q[x1] 0.865234375 q[x2] 0.0792236328125
gtp[x1] 0.947265625 gtp[x2] 0.004669189453125 gtp[a] 0.947265625
pp sum tensor(0.9785, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1132, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9473, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1132, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5088, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6559080619938046
q_ai sum tensor(0.8652, device='cuda:0', dtype=torch.float16) q[a] 0.865234375
pp sum tensor(0.9604, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8477, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9473, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8477, device='cuda:0', dtype=torch.float16)
pa tensor(0.9473, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8477, device='cuda:0', dtype=torch.float16) acp tensor(1.1172, device='cuda:0', dtype=torch.float16) r 0.9081657689158144

-------------------step: 2-------------------

directly accept a 967

-------------------step: 3-------------------

x1 18666 x2 380 a 380
q[a] 0.27099609375 q[x1] 0.0020046234130859375 q[x2] 0.27099609375
gtp[x1] 2.384185791015625e-07 gtp[x2] 1.329183578491211e-05 gtp[a] 1.329183578491211e-05
px1 tensor(2.3842e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0020, device='cuda:0') acp tensor(0.0001, device='cuda:0') r 0.9328147816429417
pp sum tensor(0.7461, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4749, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.3292e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4749, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2710, device='cuda:0', dtype=torch.float16) q[a] 0.27099609375
pp sum tensor(0.6528, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1779, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.3292e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1779, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4749, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7297749941084207
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.6528, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 11195

-------------------step: 2-------------------

x1 29899 x2 2 a 29899
q[a] 1.0 q[x1] 1.0 q[x2] 0.00016605854034423828
gtp[x1] 0.998046875 gtp[x2] 0.0011148452758789062 gtp[a] 0.998046875
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(2.3842e-07, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0009, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(2.3842e-07, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0009, device='cuda:0', dtype=torch.float16) qx2 tensor(0.9746, device='cuda:0', dtype=torch.float16) acp tensor(0.0010, device='cuda:0', dtype=torch.float16) r 0.8203749152913653
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9980, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.9698240677265668

-------------------step: 3-------------------

directly accept a 8551

-------------------step: 1-------------------

x1 322 x2 29892 a 322
q[a] 0.998046875 q[x1] 0.998046875 q[x2] 0.0008683204650878906
gtp[x1] 0.9990234375 gtp[x2] 0.0007433891296386719 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0009, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0009, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4531, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6527140159717261
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16) q[a] 0.998046875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9980, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.6264301538989302

-------------------step: 2-------------------

x1 16267 x2 10901 a 10901
q[a] 0.2225341796875 q[x1] 0.1370849609375 q[x2] 0.2225341796875
gtp[x1] 6.556510925292969e-07 gtp[x2] 0.0 gtp[a] 0.0
px1 tensor(6.5565e-07, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1371, device='cuda:0') acp tensor(4.7828e-06, device='cuda:0') r 0.8510470364798949
pp sum tensor(0.8218, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5991, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5991, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2225, device='cuda:0', dtype=torch.float16) q[a] 0.2225341796875
pp sum tensor(0.7710, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1718, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1718, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5991, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.987327529791165
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7710, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 29892 x2 2 a 29892
q[a] 1.0 q[x1] 1.0 q[x2] 2.9325485229492188e-05
gtp[x1] 0.99853515625 gtp[x2] 0.0007910728454589844 gtp[a] 0.99853515625
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(5.9605e-07, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0008, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(5.9605e-07, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0008, device='cuda:0', dtype=torch.float16) qx2 tensor(0.6221, device='cuda:0', dtype=torch.float16) acp tensor(0.0012, device='cuda:0', dtype=torch.float16) r 0.7535316621852506
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.19433938438992038

-------------------step: 2-------------------

directly accept a 4796

-------------------step: 3-------------------

directly accept a 11982

-------------------step: 1-------------------

x1 5741 x2 349 a 5741
q[a] 0.66259765625 q[x1] 0.66259765625 q[x2] 0.00030159950256347656
gtp[x1] 0.83056640625 gtp[x2] 1.7523765563964844e-05 gtp[a] 0.83056640625
pp sum tensor(0.9092, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2466, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8306, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2466, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0006, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5215643318792137
q_ai sum tensor(0.6626, device='cuda:0', dtype=torch.float16) q[a] 0.66259765625
pp sum tensor(0.8857, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6392, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8306, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6392, device='cuda:0', dtype=torch.float16)
pa tensor(0.8306, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6392, device='cuda:0', dtype=torch.float16) acp tensor(1.2998, device='cuda:0', dtype=torch.float16) r 0.7836228672088986

-------------------step: 2-------------------

directly accept a 17259

-------------------step: 3-------------------

x1 304 x2 508 a 508
q[a] 0.90087890625 q[x1] 0.059417724609375 q[x2] 0.90087890625
gtp[x1] 6.020069122314453e-06 gtp[x2] 0.9931640625 gtp[a] 0.9931640625
px1 tensor(6.0201e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0594, device='cuda:0') acp tensor(0.0001, device='cuda:0') r 0.9953164936704538
pp sum tensor(0.9932, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0921, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9932, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0921, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9004, device='cuda:0', dtype=torch.float16) q[a] 0.90087890625
pp sum tensor(0.9932, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9004, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9932, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9004, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0928, device='cuda:0', dtype=torch.float16)
pa tensor(0.0928, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.0921, device='cuda:0', dtype=torch.float16) acp tensor(1.0068, device='cuda:0', dtype=torch.float16) r 0.47001583066073804

-------------------step: 1-------------------

directly accept a 1245

-------------------step: 2-------------------

directly accept a 3412

-------------------step: 3-------------------

directly accept a 278

-------------------step: 1-------------------

x1 29892 x2 322 a 29892
q[a] 0.92529296875 q[x1] 0.92529296875 q[x2] 0.0736083984375
gtp[x1] 0.99072265625 gtp[x2] 0.00926971435546875 gtp[a] 0.99072265625
pp sum tensor(0.9907, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0652, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9907, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0652, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9121, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.29379403168213336
q_ai sum tensor(0.9253, device='cuda:0', dtype=torch.float16) q[a] 0.92529296875
pp sum tensor(0.9907, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9253, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9907, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9253, device='cuda:0', dtype=torch.float16)
pa tensor(0.9907, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9253, device='cuda:0', dtype=torch.float16) acp tensor(1.0703, device='cuda:0', dtype=torch.float16) r 0.875606121218829

-------------------step: 2-------------------

x1 17229 x2 3143 a 17229
q[a] 0.916015625 q[x1] 0.916015625 q[x2] 9.083747863769531e-05
gtp[x1] 0.97509765625 gtp[x2] 0.0 gtp[a] 0.97509765625
pp sum tensor(0.9888, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0723, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9751, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0723, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0010, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9331754777927476
q_ai sum tensor(0.9160, device='cuda:0', dtype=torch.float16) q[a] 0.916015625
pp sum tensor(0.9761, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9033, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9751, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9033, device='cuda:0', dtype=torch.float16)
pa tensor(0.9751, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9033, device='cuda:0', dtype=torch.float16) acp tensor(1.0791, device='cuda:0', dtype=torch.float16) r 0.6714681615816013

-------------------step: 3-------------------

directly accept a 263

-------------------step: 1-------------------

directly accept a 2202

-------------------step: 2-------------------

directly accept a 322

-------------------step: 3-------------------

x1 5807 x2 263 a 263
q[a] 0.256103515625 q[x1] 0.072265625 q[x2] 0.256103515625
gtp[x1] 0.0 gtp[x2] 0.0001971721649169922 gtp[a] 0.0001971721649169922
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(0.0723, device='cuda:0') acp tensor(0., device='cuda:0') r 0.8897370795873062
pp sum tensor(0.8550, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5986, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0002, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5986, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2561, device='cuda:0', dtype=torch.float16) q[a] 0.256103515625
pp sum tensor(0.8052, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2061, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0002, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2061, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5986, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2243368001077728
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8052, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 515 x2 304 a 515
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 2.6285648345947266e-05
gtp[x1] 0.9990234375 gtp[x2] 5.960464477539063e-08 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0.0003, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0003, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0424, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6840637854587966
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9980, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.6238584725997836

-------------------step: 2-------------------

directly accept a 263

-------------------step: 3-------------------

directly accept a 1887

-------------------step: 1-------------------

x1 29892 x2 322 a 29892
q[a] 0.998046875 q[x1] 0.998046875 q[x2] 0.001987457275390625
gtp[x1] 0.9990234375 gtp[x2] 0.0005354881286621094 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0015, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0015, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9541, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.10343943283216062
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16) q[a] 0.998046875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9976, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9976, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9976, device='cuda:0', dtype=torch.float16) acp tensor(1.0020, device='cuda:0', dtype=torch.float16) r 0.8864189822730704

-------------------step: 2-------------------

directly accept a 322

-------------------step: 3-------------------

x1 2125 x2 13389 a 13389
q[a] 0.443115234375 q[x1] 0.33984375 q[x2] 0.443115234375
gtp[x1] 0.0015344619750976562 gtp[x2] 0.0081634521484375 gtp[a] 0.0081634521484375
px1 tensor(0.0015, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3398, device='cuda:0') acp tensor(0.0045, device='cuda:0') r 0.9927382735212112
pp sum tensor(0.9741, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5317, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0082, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5317, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4431, device='cuda:0', dtype=torch.float16) q[a] 0.443115234375
pp sum tensor(0.9561, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4248, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0082, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4248, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5317, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.34614043741926137
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9478, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 278 x2 2 a 278
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 0.00037407875061035156
gtp[x1] 0.9990234375 gtp[x2] 0.0008831024169921875 gtp[a] 0.9990234375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(8.0347e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0005, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(8.0347e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0005, device='cuda:0', dtype=torch.float16) qx2 tensor(0.7925, device='cuda:0', dtype=torch.float16) acp tensor(0.0006, device='cuda:0', dtype=torch.float16) r 0.2154394122505605
q_ai sum tensor(0.9995, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9990, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.9755165294700164

-------------------step: 2-------------------

directly accept a 6575

-------------------step: 3-------------------

x1 14451 x2 29878 a 14451
q[a] 0.95751953125 q[x1] 0.95751953125 q[x2] 0.035430908203125
gtp[x1] 0.9970703125 gtp[x2] 0.00235748291015625 gtp[a] 0.9970703125
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0398, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9971, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0398, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8003, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.21104936301555755
q_ai sum tensor(0.9570, device='cuda:0', dtype=torch.float16) q[a] 0.95751953125
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9570, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9971, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9570, device='cuda:0', dtype=torch.float16)
pa tensor(0.9971, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9570, device='cuda:0', dtype=torch.float16) acp tensor(1.0420, device='cuda:0', dtype=torch.float16) r 0.08999730082167978

-------------------step: 1-------------------

x1 278 x2 2 a 278
q[a] 0.9912109375 q[x1] 0.9912109375 q[x2] 0.008575439453125
gtp[x1] 0.9990234375 gtp[x2] 0.0009255409240722656 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0080, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0080, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9546, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6809484519820055
q_ai sum tensor(0.9912, device='cuda:0', dtype=torch.float16) q[a] 0.9912109375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9912, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9912, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9912, device='cuda:0', dtype=torch.float16) acp tensor(1.0078, device='cuda:0', dtype=torch.float16) r 0.8550755354151658

-------------------step: 2-------------------

x1 26044 x2 23474 a 23474
q[a] 0.425048828125 q[x1] 3.629922866821289e-05 q[x2] 0.425048828125
gtp[x1] 0.0 gtp[x2] 1.1444091796875e-05 gtp[a] 1.1444091796875e-05
px1 tensor(0., device='cuda:0', dtype=torch.float16) qx1 tensor(3.6299e-05, device='cuda:0') acp tensor(0., device='cuda:0') r 0.8410253174301214
pp sum tensor(0.9512, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5264, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.1444e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5264, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4250, device='cuda:0', dtype=torch.float16) q[a] 0.425048828125
pp sum tensor(0.9155, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3896, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(1.1444e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3896, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.5264, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7929844640114201
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9155, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 1847

-------------------step: 2-------------------

x1 19922 x2 20037 a 19922
q[a] 0.9375 q[x1] 0.9375 q[x2] 0.04595947265625
gtp[x1] 0.99755859375 gtp[x2] 6.80088996887207e-05 gtp[a] 0.99755859375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0610, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0610, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6914, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9183587137717483
q_ai sum tensor(0.9380, device='cuda:0', dtype=torch.float16) q[a] 0.9375
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9365, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9365, device='cuda:0', dtype=torch.float16)
pa tensor(0.9976, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9365, device='cuda:0', dtype=torch.float16) acp tensor(1.0654, device='cuda:0', dtype=torch.float16) r 0.3398018925445684

-------------------step: 3-------------------

directly accept a 310

-------------------step: 1-------------------

directly accept a 14328

-------------------step: 2-------------------

x1 29889 x2 1550 a 29889
q[a] 0.9970703125 q[x1] 0.9970703125 q[x2] 0.0003790855407714844
gtp[x1] 0.99853515625 gtp[x2] 7.474422454833984e-05 gtp[a] 0.99853515625
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0024, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0024, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1285, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.1309926989322564
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16) q[a] 0.9970703125
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9961, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9961, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9961, device='cuda:0', dtype=torch.float16) acp tensor(1.0029, device='cuda:0', dtype=torch.float16) r 0.2745899825091741

-------------------step: 3-------------------

x1 13 x2 450 a 13
q[a] 0.9189453125 q[x1] 0.9189453125 q[x2] 0.019683837890625
gtp[x1] 0.99267578125 gtp[x2] 0.0005407333374023438 gtp[a] 0.99267578125
pp sum tensor(0.9932, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0740, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9927, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0740, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2240, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.03286710683230454
q_ai sum tensor(0.9189, device='cuda:0', dtype=torch.float16) q[a] 0.9189453125
pp sum tensor(0.9927, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9185, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9927, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9185, device='cuda:0', dtype=torch.float16)
pa tensor(0.9927, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9185, device='cuda:0', dtype=torch.float16) acp tensor(1.0811, device='cuda:0', dtype=torch.float16) r 0.4108575713195506

-------------------step: 1-------------------

x1 2831 x2 16107 a 2831
q[a] 0.43115234375 q[x1] 0.43115234375 q[x2] 0.0020599365234375
gtp[x1] 0.92529296875 gtp[x2] 3.647804260253906e-05 gtp[a] 0.92529296875
pp sum tensor(0.9258, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4949, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9253, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4949, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0016, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.09645159109033508
q_ai sum tensor(0.4312, device='cuda:0', dtype=torch.float16) q[a] 0.43115234375
pp sum tensor(0.9253, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4307, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9253, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.4307, device='cuda:0', dtype=torch.float16)
pa tensor(0.9253, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.4307, device='cuda:0', dtype=torch.float16) acp tensor(2.1484, device='cuda:0', dtype=torch.float16) r 0.8892915178746311

-------------------step: 2-------------------

x1 263 x2 1906 a 263
q[a] 0.66796875 q[x1] 0.66796875 q[x2] 0.08355712890625
gtp[x1] 0.99560546875 gtp[x2] 0.0009965896606445312 gtp[a] 0.99560546875
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3276, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9956, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3276, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1680, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2593136963025324
q_ai sum tensor(0.6680, device='cuda:0', dtype=torch.float16) q[a] 0.66796875
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6680, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9956, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6680, device='cuda:0', dtype=torch.float16)
pa tensor(0.9956, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6680, device='cuda:0', dtype=torch.float16) acp tensor(1.4902, device='cuda:0', dtype=torch.float16) r 0.2554257612688735

-------------------step: 3-------------------

directly accept a 901

-------------------step: 1-------------------

x1 332 x2 545 a 332
q[a] 0.99658203125 q[x1] 0.99658203125 q[x2] 0.0027561187744140625
gtp[x1] 0.9990234375 gtp[x2] 0.00075531005859375 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0024, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0024, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8511, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9661959788892238
q_ai sum tensor(0.9966, device='cuda:0', dtype=torch.float16) q[a] 0.99658203125
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9966, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9966, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9966, device='cuda:0', dtype=torch.float16) acp tensor(1.0029, device='cuda:0', dtype=torch.float16) r 0.9806919805397528

-------------------step: 2-------------------

directly accept a 681

-------------------step: 3-------------------

x1 7271 x2 2 a 7271
q[a] 0.93115234375 q[x1] 0.93115234375 q[x2] 0.0173187255859375
gtp[x1] 0.99658203125 gtp[x2] 0.00039696693420410156 gtp[a] 0.99658203125
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0651, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0651, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2349, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.15328945148420114
q_ai sum tensor(0.9312, device='cuda:0', dtype=torch.float16) q[a] 0.93115234375
pp sum tensor(0.9966, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9312, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9966, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9312, device='cuda:0', dtype=torch.float16)
pa tensor(0.9966, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9312, device='cuda:0', dtype=torch.float16) acp tensor(1.0703, device='cuda:0', dtype=torch.float16) r 0.9200744680656473

-------------------step: 1-------------------

x1 26824 x2 298 a 298
q[a] 0.35205078125 q[x1] 0.06719970703125 q[x2] 0.35205078125
gtp[x1] 0.8193359375 gtp[x2] 0.1317138671875 gtp[a] 0.1317138671875
px1 tensor(0.8193, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0672, device='cuda:0') acp tensor(12.1926, device='cuda:0') r 0.4614947558224699

-------------------step: 2-------------------

x1 508 x2 881 a 508
q[a] 0.673828125 q[x1] 0.673828125 q[x2] 0.30859375
gtp[x1] 0.958984375 gtp[x2] 0.04022216796875 gtp[a] 0.958984375
pp sum tensor(0.9590, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2854, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9590, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2854, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6372, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7259876501803034
q_ai sum tensor(0.6738, device='cuda:0', dtype=torch.float16) q[a] 0.673828125
pp sum tensor(0.9590, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6738, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9590, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6738, device='cuda:0', dtype=torch.float16)
pa tensor(0.9590, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6738, device='cuda:0', dtype=torch.float16) acp tensor(1.4229, device='cuda:0', dtype=torch.float16) r 0.23129396794145307

-------------------step: 3-------------------

x1 6493 x2 1074 a 6493
q[a] 0.404541015625 q[x1] 0.404541015625 q[x2] 0.00415802001953125
gtp[x1] 1.2516975402832031e-06 gtp[x2] 5.960464477539063e-08 gtp[a] 1.2516975402832031e-06
pp sum tensor(0.9878, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5830, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.2517e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5830, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0028, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.355546525036317
q_ai sum tensor(0.4043, device='cuda:0', dtype=torch.float16) q[a] 0.404541015625
pp sum tensor(0.9834, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3999, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(1.2517e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3999, device='cuda:0', dtype=torch.float16)
pa tensor(1.2517e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3999, device='cuda:0', dtype=torch.float16) acp tensor(3.1590e-06, device='cuda:0', dtype=torch.float16) r 0.35167931929149854
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9834, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 446

-------------------step: 2-------------------

x1 304 x2 373 a 304
q[a] 0.99853515625 q[x1] 0.99853515625 q[x2] 7.241964340209961e-05
gtp[x1] 0.99755859375 gtp[x2] 5.960464477539063e-08 gtp[a] 0.99755859375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0006, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0006, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0445, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6541597827877825
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16) q[a] 0.99853515625
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9971, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16)
pa tensor(0.9976, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9971, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.5098487283027154

-------------------step: 3-------------------

directly accept a 278

-------------------step: 1-------------------

directly accept a 310

-------------------step: 2-------------------

x1 278 x2 22904 a 278
q[a] 0.978515625 q[x1] 0.978515625 q[x2] 0.0102081298828125
gtp[x1] 0.004528045654296875 gtp[x2] 0.9931640625 gtp[a] 0.004528045654296875
pp sum tensor(0.9873, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0091, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0045, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9829, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0091, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9829, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4646, device='cuda:0', dtype=torch.float16) acp tensor(2.1152, device='cuda:0', dtype=torch.float16) r 0.5296236816362225

-------------------step: 3-------------------

directly accept a 898

-------------------step: 1-------------------

x1 29889 x2 29892 a 29892
q[a] 0.66796875 q[x1] 0.1536865234375 q[x2] 0.66796875
gtp[x1] 0.0006456375122070312 gtp[x2] 0.9990234375 gtp[a] 0.9990234375
px1 tensor(0.0006, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1537, device='cuda:0') acp tensor(0.0042, device='cuda:0') r 0.010162713577439586
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3308, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3308, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6680, device='cuda:0', dtype=torch.float16) q[a] 0.66796875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6680, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9990, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6680, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.3311, device='cuda:0', dtype=torch.float16)
pa tensor(0.3311, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.3308, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.09509439555587962

-------------------step: 2-------------------

x1 263 x2 385 a 263
q[a] 0.74169921875 q[x1] 0.74169921875 q[x2] 0.24462890625
gtp[x1] 0.0007672309875488281 gtp[x2] 0.9990234375 gtp[a] 0.0007672309875488281
pp sum tensor(0.7554, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0134, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0008, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.7544, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0134, device='cuda:0', dtype=torch.float16)
px2 tensor(0.7544, device='cuda:0', dtype=torch.float16) qx2 tensor(0.7021, device='cuda:0', dtype=torch.float16) acp tensor(1.0742, device='cuda:0', dtype=torch.float16) r 0.0638557136063117

-------------------step: 3-------------------

x1 9849 x2 2 a 9849
q[a] 0.54833984375 q[x1] 0.54833984375 q[x2] 0.01416015625
gtp[x1] 7.152557373046875e-07 gtp[x2] 0.00011414289474487305 gtp[a] 7.152557373046875e-07
pp sum tensor(0.9893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4407, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(7.1526e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4407, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0172, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.12273179559899872
q_ai sum tensor(0.5483, device='cuda:0', dtype=torch.float16) q[a] 0.54833984375
pp sum tensor(0.9761, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5352, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(7.1526e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5352, device='cuda:0', dtype=torch.float16)
pa tensor(7.1526e-07, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.5352, device='cuda:0', dtype=torch.float16) acp tensor(1.3113e-06, device='cuda:0', dtype=torch.float16) r 0.7119805565809387
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9761, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 1700

-------------------step: 2-------------------

directly accept a 3068

-------------------step: 3-------------------

directly accept a 293

-------------------step: 1-------------------

directly accept a 1008

-------------------step: 2-------------------

directly accept a 5982

-------------------step: 3-------------------

directly accept a 373

-------------------step: 1-------------------

directly accept a 714

-------------------step: 2-------------------

directly accept a 808

-------------------step: 3-------------------

directly accept a 381

-------------------step: 1-------------------

directly accept a 310

-------------------step: 2-------------------

x1 278 x2 26901 a 278
q[a] 0.74560546875 q[x1] 0.74560546875 q[x2] 0.042083740234375
gtp[x1] 6.020069122314453e-06 gtp[x2] 1.7881393432617188e-07 gtp[a] 6.020069122314453e-06
pp sum tensor(0.8765, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1305, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(6.0201e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1305, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1234, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.20165839625581383
q_ai sum tensor(0.7456, device='cuda:0', dtype=torch.float16) q[a] 0.74560546875
pp sum tensor(0.5137, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3828, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(6.0201e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3828, device='cuda:0', dtype=torch.float16)
pa tensor(6.0201e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3828, device='cuda:0', dtype=torch.float16) acp tensor(1.5736e-05, device='cuda:0', dtype=torch.float16) r 0.3369289891789088
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5137, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 638

-------------------step: 2-------------------

directly accept a 10058

-------------------step: 3-------------------

directly accept a 29889

-------------------step: 1-------------------

x1 29871 x2 13 a 29871
q[a] 0.9970703125 q[x1] 0.9970703125 q[x2] 0.0002486705780029297
gtp[x1] 0.99755859375 gtp[x2] 2.3663043975830078e-05 gtp[a] 0.99755859375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0021, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0021, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0849, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.29376261164589257
q_ai sum tensor(0.9971, device='cuda:0', dtype=torch.float16) q[a] 0.9970703125
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9951, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9951, device='cuda:0', dtype=torch.float16)
pa tensor(0.9976, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9951, device='cuda:0', dtype=torch.float16) acp tensor(1.0029, device='cuda:0', dtype=torch.float16) r 0.4951205148828748

-------------------step: 2-------------------

directly accept a 29896

-------------------step: 3-------------------

x1 29900 x2 29889 a 29900
q[a] 0.418701171875 q[x1] 0.418701171875 q[x2] 0.044830322265625
gtp[x1] 7.152557373046875e-07 gtp[x2] 0.99951171875 gtp[a] 7.152557373046875e-07
pp sum tensor(0.9546, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5356, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(7.1526e-07, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9546, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5356, device='cuda:0', dtype=torch.float16)
px2 tensor(0.9546, device='cuda:0', dtype=torch.float16) qx2 tensor(0.0323, device='cuda:0', dtype=torch.float16) acp tensor(29.5625, device='cuda:0', dtype=torch.float16) r 0.748237978812137

-------------------step: 1-------------------

x1 29899 x2 2 a 29899
q[a] 0.96630859375 q[x1] 0.96630859375 q[x2] 0.0141143798828125
gtp[x1] 0.9990234375 gtp[x2] 0.0007915496826171875 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0324, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0324, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.4080, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4175601305279022
q_ai sum tensor(0.9668, device='cuda:0', dtype=torch.float16) q[a] 0.96630859375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9668, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9668, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9668, device='cuda:0', dtype=torch.float16) acp tensor(1.0332, device='cuda:0', dtype=torch.float16) r 0.5888209884897334

-------------------step: 2-------------------

directly accept a 26763

-------------------step: 3-------------------

directly accept a 7251

-------------------step: 1-------------------

x1 304 x2 701 a 304
q[a] 0.66650390625 q[x1] 0.66650390625 q[x2] 0.09381103515625
gtp[x1] 0.99755859375 gtp[x2] 3.933906555175781e-05 gtp[a] 0.99755859375
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3308, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3308, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1876, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7087659093057558
q_ai sum tensor(0.6665, device='cuda:0', dtype=torch.float16) q[a] 0.66650390625
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6665, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6665, device='cuda:0', dtype=torch.float16)
pa tensor(0.9976, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6665, device='cuda:0', dtype=torch.float16) acp tensor(1.4971, device='cuda:0', dtype=torch.float16) r 0.08141879316806355

-------------------step: 2-------------------

x1 278 x2 2 a 278
q[a] 0.99853515625 q[x1] 0.99853515625 q[x2] 0.0012445449829101562
gtp[x1] 0.9990234375 gtp[x2] 0.0008692741394042969 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0004, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0004, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9404, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.771461763654883
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16) q[a] 0.99853515625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.5003910247114199

-------------------step: 3-------------------

directly accept a 2246

-------------------step: 1-------------------

x1 18066 x2 3209 a 18066
q[a] 0.97509765625 q[x1] 0.97509765625 q[x2] 5.960464477539063e-08
gtp[x1] 0.9990234375 gtp[x2] 0.0 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0239, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0239, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(2.3246e-06, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.407327627379264
q_ai sum tensor(0.9751, device='cuda:0', dtype=torch.float16) q[a] 0.97509765625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9751, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9751, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9751, device='cuda:0', dtype=torch.float16) acp tensor(1.0244, device='cuda:0', dtype=torch.float16) r 0.4351142427786444

-------------------step: 2-------------------

directly accept a 292

-------------------step: 3-------------------

x1 29892 x2 541 a 541
q[a] 0.5830078125 q[x1] 0.39453125 q[x2] 0.5830078125
gtp[x1] 0.01690673828125 gtp[x2] 0.98291015625 gtp[a] 0.98291015625
px1 tensor(0.0169, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3945, device='cuda:0') acp tensor(0.0429, device='cuda:0') r 0.07421959759615904
pp sum tensor(0.9829, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4001, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9829, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4001, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5825, device='cuda:0', dtype=torch.float16) q[a] 0.5830078125
pp sum tensor(0.9829, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5825, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.9829, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.5825, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.4004, device='cuda:0', dtype=torch.float16)
pa tensor(0.4004, device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4001, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.6576620578888774

-------------------step: 1-------------------

directly accept a 20751

-------------------step: 2-------------------

directly accept a 292

-------------------step: 3-------------------

x1 29892 x2 2 a 29892
q[a] 1.0 q[x1] 1.0 q[x2] 9.912252426147461e-05
gtp[x1] 0.9990234375 gtp[x2] 0.0002865791320800781 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(1.3709e-06, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0002, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(1.3709e-06, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0002, device='cuda:0', dtype=torch.float16) qx2 tensor(0.8643, device='cuda:0', dtype=torch.float16) acp tensor(0.0002, device='cuda:0', dtype=torch.float16) r 0.6592012225449616
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9995, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9995, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9995, device='cuda:0', dtype=torch.float16) acp tensor(0.9995, device='cuda:0', dtype=torch.float16) r 0.8572284931198529

-------------------step: 1-------------------

directly accept a 7243

-------------------step: 2-------------------

directly accept a 272

-------------------step: 3-------------------

directly accept a 314

-------------------step: 1-------------------

directly accept a 8386

-------------------step: 2-------------------

directly accept a 310

-------------------step: 3-------------------

x1 26901 x2 22977 a 26901
q[a] 0.337646484375 q[x1] 0.337646484375 q[x2] 0.00018668174743652344
gtp[x1] 4.231929779052734e-06 gtp[x2] 0.0 gtp[a] 4.231929779052734e-06
pp sum tensor(0.9634, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6260, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(4.2319e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6260, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(9.5129e-05, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8833831561661589
q_ai sum tensor(0.3379, device='cuda:0', dtype=torch.float16) q[a] 0.337646484375
pp sum tensor(0.9448, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3193, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(4.2319e-06, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3193, device='cuda:0', dtype=torch.float16)
pa tensor(4.2319e-06, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.3193, device='cuda:0', dtype=torch.float16) acp tensor(1.3232e-05, device='cuda:0', dtype=torch.float16) r 0.06448334613326867
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9448, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 324

-------------------step: 2-------------------

directly accept a 21528

-------------------step: 3-------------------

directly accept a 322

-------------------step: 1-------------------

directly accept a 23474

-------------------step: 2-------------------

directly accept a 8724

-------------------step: 3-------------------

directly accept a 29889

-------------------step: 1-------------------

directly accept a 1854

-------------------step: 2-------------------

directly accept a 304

-------------------step: 3-------------------

directly accept a 1369

-------------------step: 1-------------------

directly accept a 7251

-------------------step: 2-------------------

directly accept a 446

-------------------step: 3-------------------

directly accept a 4688

-------------------step: 1-------------------

x1 278 x2 2 a 278
q[a] 1.0 q[x1] 1.0 q[x2] 9.316205978393555e-05
gtp[x1] 0.99853515625 gtp[x2] 0.0013246536254882812 gtp[a] 0.99853515625
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0., device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0012, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0., device='cuda:0', dtype=torch.float16)
px2 tensor(0.0012, device='cuda:0', dtype=torch.float16) qx2 tensor(0.9941, device='cuda:0', dtype=torch.float16) acp tensor(0.0012, device='cuda:0', dtype=torch.float16) r 0.7309288671022878
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.3239939136837505

-------------------step: 2-------------------

directly accept a 7250

-------------------step: 3-------------------

directly accept a 304

-------------------step: 1-------------------

directly accept a 278

-------------------step: 2-------------------

x1 298 x2 11660 a 11660
q[a] 0.224853515625 q[x1] 0.06646728515625 q[x2] 0.224853515625
gtp[x1] 7.867813110351562e-06 gtp[x2] 0.002796173095703125 gtp[a] 0.002796173095703125
px1 tensor(7.8678e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.0665, device='cuda:0') acp tensor(0.0001, device='cuda:0') r 0.2057819809413538
pp sum tensor(0.8545, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6294, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0028, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6294, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2249, device='cuda:0', dtype=torch.float16) q[a] 0.224853515625
pp sum tensor(0.8125, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1830, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0028, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1830, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6294, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4386728200334582
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8096, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 322

-------------------step: 2-------------------

directly accept a 11660

-------------------step: 3-------------------

directly accept a 7176

-------------------step: 1-------------------

directly accept a 393

-------------------step: 2-------------------

directly accept a 508

-------------------step: 3-------------------

directly accept a 6403

-------------------step: 1-------------------

directly accept a 297

-------------------step: 2-------------------

x1 278 x2 2 a 278
q[a] 1.0 q[x1] 1.0 q[x2] 0.0001233816146850586
gtp[x1] 0.9990234375 gtp[x2] 0.0011692047119140625 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(5.9605e-08, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0010, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(5.9605e-08, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0010, device='cuda:0', dtype=torch.float16) qx2 tensor(0.9912, device='cuda:0', dtype=torch.float16) acp tensor(0.0011, device='cuda:0', dtype=torch.float16) r 0.6757079099196535
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9990, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.49328019453077954

-------------------step: 3-------------------

x1 7250 x2 2462 a 7250
q[a] 0.490966796875 q[x1] 0.490966796875 q[x2] 0.475830078125
gtp[x1] 0.0 gtp[x2] 0.99951171875 gtp[a] 0.0
pp sum tensor(0.5234, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0329, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.5234, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0329, device='cuda:0', dtype=torch.float16)
px2 tensor(0.5234, device='cuda:0', dtype=torch.float16) qx2 tensor(0.4587, device='cuda:0', dtype=torch.float16) acp tensor(1.1406, device='cuda:0', dtype=torch.float16) r 0.1307499741935162

-------------------step: 1-------------------

x1 13 x2 2 a 13
q[a] 0.892578125 q[x1] 0.892578125 q[x2] 0.1065673828125
gtp[x1] 0.8173828125 gtp[x2] 0.1795654296875 gtp[a] 0.8173828125
pp sum tensor(0.8931, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0003, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8174, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0730, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0003, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0730, device='cuda:0', dtype=torch.float16) qx2 tensor(0.8853, device='cuda:0', dtype=torch.float16) acp tensor(0.0825, device='cuda:0', dtype=torch.float16) r 0.09393822024234189
q_ai sum tensor(0.8926, device='cuda:0', dtype=torch.float16) q[a] 0.892578125
pp sum tensor(0.8193, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8193, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8174, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8193, device='cuda:0', dtype=torch.float16)
pa tensor(0.8174, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8193, device='cuda:0', dtype=torch.float16) acp tensor(0.9976, device='cuda:0', dtype=torch.float16) r 0.10800332569834603

-------------------step: 2-------------------

directly accept a 13

-------------------step: 3-------------------

x1 12881 x2 1349 a 12881
q[a] 0.1298828125 q[x1] 0.1298828125 q[x2] 0.01306915283203125
gtp[x1] 0.00020813941955566406 gtp[x2] 4.64320182800293e-05 gtp[a] 0.00020813941955566406
pp sum tensor(0.8555, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7256, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0002, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7256, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0020, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3475359262873384
q_ai sum tensor(0.1299, device='cuda:0', dtype=torch.float16) q[a] 0.1298828125
pp sum tensor(0.8354, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1099, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0002, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1099, device='cuda:0', dtype=torch.float16)
pa tensor(0.0002, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.1099, device='cuda:0', dtype=torch.float16) acp tensor(0.0019, device='cuda:0', dtype=torch.float16) r 0.830984122524656
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8354, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 15837 x2 15997 a 15997
q[a] 0.625 q[x1] 0.367431640625 q[x2] 0.625
gtp[x1] 0.68408203125 gtp[x2] 0.313232421875 gtp[a] 0.313232421875
px1 tensor(0.6841, device='cuda:0', dtype=torch.float16) qx1 tensor(0.3674, device='cuda:0') acp tensor(1.8618, device='cuda:0') r 0.6946636150986405

-------------------step: 2-------------------

directly accept a 29892

-------------------step: 3-------------------

x1 26901 x2 278 a 26901
q[a] 0.95263671875 q[x1] 0.95263671875 q[x2] 0.0123748779296875
gtp[x1] 0.99072265625 gtp[x2] 0.0006928443908691406 gtp[a] 0.99072265625
pp sum tensor(0.9912, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0384, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9907, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0384, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2502, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.03874580334298239
q_ai sum tensor(0.9526, device='cuda:0', dtype=torch.float16) q[a] 0.95263671875
pp sum tensor(0.9907, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9521, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9907, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9521, device='cuda:0', dtype=torch.float16)
pa tensor(0.9907, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9521, device='cuda:0', dtype=torch.float16) acp tensor(1.0400, device='cuda:0', dtype=torch.float16) r 0.4793136261901412

-------------------step: 1-------------------

x1 338 x2 16688 a 338
q[a] 0.9326171875 q[x1] 0.9326171875 q[x2] 0.055145263671875
gtp[x1] 0.94189453125 gtp[x2] 0.056549072265625 gtp[a] 0.94189453125
pp sum tensor(0.9438, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0112, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9419, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0014, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0112, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0014, device='cuda:0', dtype=torch.float16) qx2 tensor(0.7617, device='cuda:0', dtype=torch.float16) acp tensor(0.0018, device='cuda:0', dtype=torch.float16) r 0.49412327476758044
q_ai sum tensor(0.9326, device='cuda:0', dtype=torch.float16) q[a] 0.9326171875
pp sum tensor(0.9419, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9307, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9419, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9307, device='cuda:0', dtype=torch.float16)
pa tensor(0.9419, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9307, device='cuda:0', dtype=torch.float16) acp tensor(1.0117, device='cuda:0', dtype=torch.float16) r 0.3565777896908049

-------------------step: 2-------------------

x1 263 x2 385 a 263
q[a] 0.9775390625 q[x1] 0.9775390625 q[x2] 0.02093505859375
gtp[x1] 0.99462890625 gtp[x2] 0.003818511962890625 gtp[a] 0.99462890625
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0182, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9946, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0182, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9058, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.44585226127947597
q_ai sum tensor(0.9775, device='cuda:0', dtype=torch.float16) q[a] 0.9775390625
pp sum tensor(0.9946, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9766, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9946, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9766, device='cuda:0', dtype=torch.float16)
pa tensor(0.9946, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9766, device='cuda:0', dtype=torch.float16) acp tensor(1.0186, device='cuda:0', dtype=torch.float16) r 0.7811646484398066

-------------------step: 3-------------------

x1 12551 x2 1818 a 1818
q[a] 0.2203369140625 q[x1] 0.1295166015625 q[x2] 0.2203369140625
gtp[x1] 0.00498199462890625 gtp[x2] 0.0286712646484375 gtp[a] 0.0286712646484375
px1 tensor(0.0050, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1295, device='cuda:0') acp tensor(0.0385, device='cuda:0') r 0.3424171365540304
pp sum tensor(0.9150, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6943, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0287, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.6943, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2203, device='cuda:0', dtype=torch.float16) q[a] 0.2203369140625
pp sum tensor(0.9004, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2058, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0287, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2058, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.6943, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7022627578114289
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8721, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 26811 x2 12551 a 26811
q[a] 0.5322265625 q[x1] 0.5322265625 q[x2] 0.045074462890625
gtp[x1] 1.6927719116210938e-05 gtp[x2] 4.172325134277344e-07 gtp[a] 1.6927719116210938e-05
pp sum tensor(0.7847, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2524, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(1.6928e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2524, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0513, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5800495818541697
q_ai sum tensor(0.5322, device='cuda:0', dtype=torch.float16) q[a] 0.5322265625
pp sum tensor(0.5400, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2876, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(1.6928e-05, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2876, device='cuda:0', dtype=torch.float16)
pa tensor(1.6928e-05, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2876, device='cuda:0', dtype=torch.float16) acp tensor(5.8830e-05, device='cuda:0', dtype=torch.float16) r 0.08778726957450456
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5400, device='cuda:0', dtype=torch.float16)

-------------------step: 2-------------------


-------------------step: 1-------------------

directly accept a 5613

-------------------step: 2-------------------

x1 26811 x2 1346 a 26811
q[a] 0.3193359375 q[x1] 0.3193359375 q[x2] 1.0371208190917969e-05
gtp[x1] 0.0016222000122070312 gtp[x2] 0.0 gtp[a] 0.0016222000122070312
pp sum tensor(0.8975, device='cuda:0', dtype=torch.float16) qp sum tensor(0.5781, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0016, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.5781, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(4.8876e-06, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.8953358977743909
q_ai sum tensor(0.3193, device='cuda:0', dtype=torch.float16) q[a] 0.3193359375
pp sum tensor(0.8496, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2715, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0016, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2715, device='cuda:0', dtype=torch.float16)
pa tensor(0.0016, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2715, device='cuda:0', dtype=torch.float16) acp tensor(0.0060, device='cuda:0', dtype=torch.float16) r 0.43887821637182034
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.8481, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

directly accept a 1049

-------------------step: 2-------------------

directly accept a 393

-------------------step: 3-------------------

x1 16688 x2 338 a 16688
q[a] 0.98828125 q[x1] 0.98828125 q[x2] 0.0024890899658203125
gtp[x1] 0.99755859375 gtp[x2] 0.0005517005920410156 gtp[a] 0.99755859375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0095, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0095, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.2114, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.11953469385673543
q_ai sum tensor(0.9883, device='cuda:0', dtype=torch.float16) q[a] 0.98828125
pp sum tensor(0.9976, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9883, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9976, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9883, device='cuda:0', dtype=torch.float16)
pa tensor(0.9976, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9883, device='cuda:0', dtype=torch.float16) acp tensor(1.0098, device='cuda:0', dtype=torch.float16) r 0.39649641990310824

-------------------step: 1-------------------

directly accept a 363

-------------------step: 2-------------------

x1 14332 x2 1432 a 14332
q[a] 0.8994140625 q[x1] 0.8994140625 q[x2] 0.0963134765625
gtp[x1] 0.99169921875 gtp[x2] 0.008056640625 gtp[a] 0.99169921875
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0920, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0920, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.8623, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6693604868586711
q_ai sum tensor(0.8989, device='cuda:0', dtype=torch.float16) q[a] 0.8994140625
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8989, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8989, device='cuda:0', dtype=torch.float16)
pa tensor(0.9917, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8989, device='cuda:0', dtype=torch.float16) acp tensor(1.1035, device='cuda:0', dtype=torch.float16) r 0.7420998577686266

-------------------step: 3-------------------

x1 29889 x2 1058 a 29889
q[a] 0.8212890625 q[x1] 0.8212890625 q[x2] 0.016265869140625
gtp[x1] 0.9951171875 gtp[x2] 0.00010669231414794922 gtp[a] 0.9951171875
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1737, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9951, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1737, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0750, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.9081164594134821
q_ai sum tensor(0.8213, device='cuda:0', dtype=torch.float16) q[a] 0.8212890625
pp sum tensor(0.9951, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8213, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9951, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8213, device='cuda:0', dtype=torch.float16)
pa tensor(0.9951, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8213, device='cuda:0', dtype=torch.float16) acp tensor(1.2119, device='cuda:0', dtype=torch.float16) r 0.8748206678685501

-------------------step: 1-------------------

x1 366 x2 372 a 366
q[a] 0.99853515625 q[x1] 0.99853515625 q[x2] 0.0009546279907226562
gtp[x1] 0.8251953125 gtp[x2] 0.00011813640594482422 gtp[a] 0.8251953125
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8252, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0008, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7803, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6810682866094384
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16) q[a] 0.99853515625
pp sum tensor(0.9956, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9946, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8252, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9946, device='cuda:0', dtype=torch.float16)
pa tensor(0.8252, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9946, device='cuda:0', dtype=torch.float16) acp tensor(0.8296, device='cuda:0', dtype=torch.float16) r 0.10787727043689965

-------------------step: 2-------------------

x1 29915 x2 2 a 29915
q[a] 0.99853515625 q[x1] 0.99853515625 q[x2] 0.0012254714965820312
gtp[x1] 0.9990234375 gtp[x2] 0.00030517578125 gtp[a] 0.9990234375
pp sum tensor(0.9995, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0010, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0010, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.9395, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.09634699041445838
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16) q[a] 0.99853515625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9980, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.8016597662705408

-------------------step: 3-------------------

directly accept a 276

-------------------step: 1-------------------

directly accept a 297

-------------------step: 2-------------------

directly accept a 4955

-------------------step: 3-------------------

x1 29892 x2 322 a 29892
q[a] 0.99755859375 q[x1] 0.99755859375 q[x2] 0.0007543563842773438
gtp[x1] 0.99853515625 gtp[x2] 1.2218952178955078e-05 gtp[a] 0.99853515625
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0015, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0015, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3293, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5134808266675546
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16) q[a] 0.99755859375
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9976, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9985, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9976, device='cuda:0', dtype=torch.float16)
pa tensor(0.9985, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9976, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.5875405396763943

-------------------step: 1-------------------

directly accept a 29892

-------------------step: 2-------------------

directly accept a 470

-------------------step: 3-------------------

directly accept a 925

-------------------step: 1-------------------

directly accept a 292

-------------------step: 2-------------------

directly accept a 373

-------------------step: 3-------------------

directly accept a 263

-------------------step: 1-------------------

x1 25695 x2 367 a 25695
q[a] 0.99365234375 q[x1] 0.99365234375 q[x2] 0.0009570121765136719
gtp[x1] 0.9990234375 gtp[x2] 2.980232238769531e-07 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0051, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0051, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1556, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6645329358502152
q_ai sum tensor(0.9941, device='cuda:0', dtype=torch.float16) q[a] 0.99365234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9941, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9941, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9941, device='cuda:0', dtype=torch.float16) acp tensor(1.0049, device='cuda:0', dtype=torch.float16) r 0.9994574182044583

-------------------step: 2-------------------

directly accept a 29892

-------------------step: 3-------------------

x1 6493 x2 727 a 727
q[a] 0.1585693359375 q[x1] 0.12939453125 q[x2] 0.1585693359375
gtp[x1] 5.9604644775390625e-06 gtp[x2] 2.7060508728027344e-05 gtp[a] 2.7060508728027344e-05
px1 tensor(5.9605e-06, device='cuda:0', dtype=torch.float16) qx1 tensor(0.1294, device='cuda:0') acp tensor(4.6064e-05, device='cuda:0') r 0.03459740250744381
pp sum tensor(0.9229, device='cuda:0', dtype=torch.float16) qp sum tensor(0.7637, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.7061e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.7637, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1584, device='cuda:0', dtype=torch.float16) q[a] 0.1585693359375
pp sum tensor(0.9087, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1444, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(2.7061e-05, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.1444, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.7637, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6709957638276511
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.9087, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

x1 21881 x2 12551 a 21881
q[a] 0.8984375 q[x1] 0.8984375 q[x2] 0.00281524658203125
gtp[x1] 0.998046875 gtp[x2] 4.112720489501953e-06 gtp[a] 0.998046875
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0999, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0999, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0250, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3137954225834181
q_ai sum tensor(0.8984, device='cuda:0', dtype=torch.float16) q[a] 0.8984375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8979, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8979, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8979, device='cuda:0', dtype=torch.float16) acp tensor(1.1113, device='cuda:0', dtype=torch.float16) r 0.4726810527690527

-------------------step: 2-------------------

directly accept a 26811

-------------------step: 3-------------------

directly accept a 895

-------------------step: 1-------------------

directly accept a 372

-------------------step: 2-------------------

directly accept a 599

-------------------step: 3-------------------

x1 29889 x2 7088 a 29889
q[a] 0.9443359375 q[x1] 0.9443359375 q[x2] 4.190206527709961e-05
gtp[x1] 0.998046875 gtp[x2] 0.0 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0537, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0537, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0007, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.030083490854615258
q_ai sum tensor(0.9443, device='cuda:0', dtype=torch.float16) q[a] 0.9443359375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9443, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9443, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9443, device='cuda:0', dtype=torch.float16) acp tensor(1.0566, device='cuda:0', dtype=torch.float16) r 0.22992695101182792

-------------------step: 1-------------------

x1 10712 x2 4966 a 10712
q[a] 0.61181640625 q[x1] 0.61181640625 q[x2] 0.337890625
gtp[x1] 0.99169921875 gtp[x2] 0.0031566619873046875 gtp[a] 0.99169921875
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3801, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3801, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.5322, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.7876336976906335
q_ai sum tensor(0.6118, device='cuda:0', dtype=torch.float16) q[a] 0.61181640625
pp sum tensor(0.9917, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6118, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9917, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6118, device='cuda:0', dtype=torch.float16)
pa tensor(0.9917, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6118, device='cuda:0', dtype=torch.float16) acp tensor(1.6211, device='cuda:0', dtype=torch.float16) r 0.9515378154751627

-------------------step: 2-------------------

x1 6907 x2 13622 a 6907
q[a] 0.99365234375 q[x1] 0.99365234375 q[x2] 0.000576019287109375
gtp[x1] 0.9990234375 gtp[x2] 6.496906280517578e-05 gtp[a] 0.9990234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0053, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0053, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0907, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4595431527640861
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16) q[a] 0.99365234375
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9937, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9937, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9937, device='cuda:0', dtype=torch.float16) acp tensor(1.0059, device='cuda:0', dtype=torch.float16) r 0.9011763534297278

-------------------step: 3-------------------

x1 4417 x2 6493 a 4417
q[a] 0.97021484375 q[x1] 0.97021484375 q[x2] 0.0111236572265625
gtp[x1] 0.998046875 gtp[x2] 0.001064300537109375 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0281, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0281, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3625, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.3958610063984985
q_ai sum tensor(0.9702, device='cuda:0', dtype=torch.float16) q[a] 0.97021484375
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9697, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9697, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9697, device='cuda:0', dtype=torch.float16) acp tensor(1.0293, device='cuda:0', dtype=torch.float16) r 0.08960883633160677

-------------------step: 1-------------------

directly accept a 304

-------------------step: 2-------------------

directly accept a 596

-------------------step: 3-------------------

directly accept a 9850

-------------------step: 1-------------------

directly accept a 1051

-------------------step: 2-------------------

x1 29889 x2 322 a 29889
q[a] 0.418701171875 q[x1] 0.418701171875 q[x2] 0.258056640625
gtp[x1] 0.0156707763671875 gtp[x2] 0.07244873046875 gtp[a] 0.0156707763671875
pp sum tensor(0.7217, device='cuda:0', dtype=torch.float16) qp sum tensor(0.3035, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.0157, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.3035, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1858, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.40553435750039923
q_ai sum tensor(0.4187, device='cuda:0', dtype=torch.float16) q[a] 0.418701171875
pp sum tensor(0.5747, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2717, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.0157, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2717, device='cuda:0', dtype=torch.float16)
pa tensor(0.0157, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.2717, device='cuda:0', dtype=torch.float16) acp tensor(0.0577, device='cuda:0', dtype=torch.float16) r 0.6402671632733399
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.5591, device='cuda:0', dtype=torch.float16)

-------------------step: 3-------------------


-------------------step: 1-------------------

x1 322 x2 2 a 322
q[a] 1.0 q[x1] 1.0 q[x2] 4.398822784423828e-05
gtp[x1] 0.998046875 gtp[x2] 0.0001291036605834961 gtp[a] 0.998046875
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(1.0729e-06, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(8.5115e-05, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(1.0729e-06, device='cuda:0', dtype=torch.float16)
px2 tensor(8.5115e-05, device='cuda:0', dtype=torch.float16) qx2 tensor(0.8467, device='cuda:0', dtype=torch.float16) acp tensor(0.0001, device='cuda:0', dtype=torch.float16) r 0.6394593694983257
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9985, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9985, device='cuda:0', dtype=torch.float16) acp tensor(0.9995, device='cuda:0', dtype=torch.float16) r 0.1708898026714486

-------------------step: 2-------------------

x1 306 x2 505 a 306
q[a] 0.99462890625 q[x1] 0.99462890625 q[x2] 9.196996688842773e-05
gtp[x1] 0.97900390625 gtp[x2] 2.8252601623535156e-05 gtp[a] 0.97900390625
pp sum tensor(0.9985, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0038, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9790, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0038, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.0177, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.4530794066366737
q_ai sum tensor(0.9946, device='cuda:0', dtype=torch.float16) q[a] 0.99462890625
pp sum tensor(0.9819, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9780, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9790, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9780, device='cuda:0', dtype=torch.float16)
pa tensor(0.9790, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9780, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.8049084328037196

-------------------step: 3-------------------

x1 4966 x2 10712 a 4966
q[a] 0.8486328125 q[x1] 0.8486328125 q[x2] 0.0675048828125
gtp[x1] 0.986328125 gtp[x2] 5.960464477539063e-08 gtp[a] 0.986328125
pp sum tensor(0.9946, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1459, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1459, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.3787, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2639909494133019
q_ai sum tensor(0.8486, device='cuda:0', dtype=torch.float16) q[a] 0.8486328125
pp sum tensor(0.9893, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8433, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9863, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8433, device='cuda:0', dtype=torch.float16)
pa tensor(0.9863, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8433, device='cuda:0', dtype=torch.float16) acp tensor(1.1699, device='cuda:0', dtype=torch.float16) r 0.699510082167923

-------------------step: 1-------------------

x1 12618 x2 1400 a 12618
q[a] 0.83642578125 q[x1] 0.83642578125 q[x2] 0.138671875
gtp[x1] 0.8984375 gtp[x2] 0.0279998779296875 gtp[a] 0.8984375
pp sum tensor(0.9619, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1252, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.8984, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1252, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7104, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.31096067548344875
q_ai sum tensor(0.8364, device='cuda:0', dtype=torch.float16) q[a] 0.83642578125
pp sum tensor(0.9556, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8306, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.8984, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8306, device='cuda:0', dtype=torch.float16)
pa tensor(0.8984, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8306, device='cuda:0', dtype=torch.float16) acp tensor(1.0820, device='cuda:0', dtype=torch.float16) r 0.9503786229052056

-------------------step: 2-------------------

x1 1400 x2 756 a 1400
q[a] 1.0 q[x1] 1.0 q[x2] 2.282857894897461e-05
gtp[x1] 0.9990234375 gtp[x2] 0.0008039474487304688 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(0., device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0008, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0., device='cuda:0', dtype=torch.float16)
px2 tensor(0.0008, device='cuda:0', dtype=torch.float16) qx2 tensor(0.5874, device='cuda:0', dtype=torch.float16) acp tensor(0.0013, device='cuda:0', dtype=torch.float16) r 0.2821127912418848
q_ai sum tensor(1., device='cuda:0', dtype=torch.float16) q[a] 1.0
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9990, device='cuda:0', dtype=torch.float16) acp tensor(1., device='cuda:0', dtype=torch.float16) r 0.2713551156974776

-------------------step: 3-------------------

x1 756 x2 4076 a 756
q[a] 0.85107421875 q[x1] 0.85107421875 q[x2] 0.018218994140625
gtp[x1] 0.998046875 gtp[x2] 1.4483928680419922e-05 gtp[a] 0.998046875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.1472, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.1472, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.1042, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.38901262546071635
q_ai sum tensor(0.8511, device='cuda:0', dtype=torch.float16) q[a] 0.85107421875
pp sum tensor(0.9980, device='cuda:0', dtype=torch.float16) qp sum tensor(0.8511, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9980, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.8511, device='cuda:0', dtype=torch.float16)
pa tensor(0.9980, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.8511, device='cuda:0', dtype=torch.float16) acp tensor(1.1729, device='cuda:0', dtype=torch.float16) r 0.2114996378837407

-------------------step: 1-------------------

x1 366 x2 2 a 366
q[a] 0.99951171875 q[x1] 0.99951171875 q[x2] 0.0001971721649169922
gtp[x1] 0.9990234375 gtp[x2] 0.0005354881286621094 gtp[a] 0.9990234375
pp sum tensor(1., device='cuda:0', dtype=torch.float16) qp sum tensor(1.4842e-05, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0003, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(1.4842e-05, device='cuda:0', dtype=torch.float16)
px2 tensor(0.0003, device='cuda:0', dtype=torch.float16) qx2 tensor(0.6782, device='cuda:0', dtype=torch.float16) acp tensor(0.0005, device='cuda:0', dtype=torch.float16) r 0.8491866884068925
q_ai sum tensor(0.9990, device='cuda:0', dtype=torch.float16) q[a] 0.99951171875
pp sum tensor(0.9990, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9990, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9980, device='cuda:0', dtype=torch.float16)
pa tensor(0.9990, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9980, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.49673645422758883

-------------------step: 2-------------------

directly accept a 304

-------------------step: 3-------------------

x1 6493 x2 26987 a 26987
q[a] 0.351318359375 q[x1] 0.216552734375 q[x2] 0.351318359375
gtp[x1] 0.0008788108825683594 gtp[x2] 0.0003838539123535156 gtp[a] 0.0003838539123535156
px1 tensor(0.0009, device='cuda:0', dtype=torch.float16) qx1 tensor(0.2166, device='cuda:0') acp tensor(0.0041, device='cuda:0') r 0.26627128798230404
pp sum tensor(0.8286, device='cuda:0', dtype=torch.float16) qp sum tensor(0.4771, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0004, device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.4771, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.3513, device='cuda:0', dtype=torch.float16) q[a] 0.351318359375
pp sum tensor(0.7388, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2615, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0.0004, device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.2615, device='cuda:0', dtype=torch.float16)
after ai a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
pa tensor(0., device='cuda:0', dtype=torch.float16) q_ia sum tensor(0.4771, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.5274056213879756
after ia a, gtp[x1] tensor(0., device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
gtp.sum() tensor(0.7383, device='cuda:0', dtype=torch.float16)

-------------------step: 1-------------------

directly accept a 577

-------------------step: 2-------------------

x1 29991 x2 29889 a 29991
q[a] 0.6396484375 q[x1] 0.6396484375 q[x2] 0.353271484375
gtp[x1] 0.90380859375 gtp[x2] 0.0894775390625 gtp[a] 0.90380859375
pp sum tensor(0.9082, device='cuda:0', dtype=torch.float16) qp sum tensor(0.2688, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9038, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.2688, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.6270, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.6332035980359586
q_ai sum tensor(0.6396, device='cuda:0', dtype=torch.float16) q[a] 0.6396484375
pp sum tensor(0.9072, device='cuda:0', dtype=torch.float16) qp sum tensor(0.6387, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9038, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.6387, device='cuda:0', dtype=torch.float16)
pa tensor(0.9038, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.6387, device='cuda:0', dtype=torch.float16) acp tensor(1.4150, device='cuda:0', dtype=torch.float16) r 0.637119190210326

-------------------step: 3-------------------

x1 2 x2 13 a 2
q[a] 0.99609375 q[x1] 0.99609375 q[x2] 0.0028858184814453125
gtp[x1] 0.990234375 gtp[x2] 0.002201080322265625 gtp[a] 0.990234375
pp sum tensor(0.9971, device='cuda:0', dtype=torch.float16) qp sum tensor(0.0011, device='cuda:0', dtype=torch.float16)
after ia i, gtp[x1] tensor(0.9902, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ia sum tensor(0.0011, device='cuda:0', dtype=torch.float16)
px2 tensor(0., device='cuda:0', dtype=torch.float16) qx2 tensor(0.7202, device='cuda:0', dtype=torch.float16) acp tensor(0., device='cuda:0', dtype=torch.float16) r 0.2679515491918447
q_ai sum tensor(0.9956, device='cuda:0', dtype=torch.float16) q[a] 0.99609375
pp sum tensor(0.9902, device='cuda:0', dtype=torch.float16) qp sum tensor(0.9893, device='cuda:0', dtype=torch.float16)
after ai i, gtp[x1] tensor(0.9902, device='cuda:0', dtype=torch.float16) gtp[x2] tensor(0., device='cuda:0', dtype=torch.float16)
q_ai sum tensor(0.9893, device='cuda:0', dtype=torch.float16)
pa tensor(0.9902, device='cuda:0', dtype=torch.float16) q_ai.sum tensor(0.9893, device='cuda:0', dtype=torch.float16) acp tensor(1.0010, device='cuda:0', dtype=torch.float16) r 0.18802424252788408

Output:
 Ah, Hawaii, a beautiful and cultural archipelago located in the north central Pacific Ocean. Known for its stunning beaches, lush rainforests, and towering waterfalls, the state offers travelers a unique and memorable experience.

One of the top cultural experiences to have when visiting Hawaii is exploring the island's rich history and traditions. The Pearl Harbor National Monument is a must-see for anyone interested in World War II history. Visitors can learn about the attack on Pearl Harbor on December 7, 1941, and pay their respects at the USS Arizona Memorial, a somber and humbling experience that honors the 1,177 sailors and Marines who lost their lives during the attack.

For a more cultural experience, visitors should also visit the Iolani Palace, the only former royal palace in the United States. This stunning palace was the official residence of the Hawaiian monarchs from 1845 to 1893, and serves as a fascinating look into Hawaii's history and the lives of its royal families. Guests can take a tour of the palace and learn about the state's rich past from knowledgeable and passionate guides.

Hawaii's natural beauty is simply stunning, with miles of pristine beaches, lush rainforests, and towering waterfalls. One of the top beaches to visit in Hawaii is Waikiki Beach, with its crystal-clear waters and soft, white sand. Visitors can stroll along the beach, grab a pastry and coffee from a local vendor, and watch the sun rise over the sparkling waters of the Pacific.

For a more adventurous experience, visitors can hike to the top of Diamond Head, an ancient volcanic crater located on the outskirts of Waikiki. The 1.6-mile hike to the top is challenging but thoroughly rewarding, with panoramic views of Honolulu and the ocean beyond. Be sure to start your hike early in the morning to avoid the hot and crowded conditions that can occur later in the day.

In summary, Hawaii is a cultural and natural wonderland that offers something for everyone. Whether you're interested in history, nature, or just relaxing on a beautiful beach, this tropical paradise has it all. I highly recommend adding it to your travel bucket list, and I hope this blog post has inspired you to do so!</s> 

