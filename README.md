
## Tasks 
1. loading tinyllama + llama2 (convert)-> Yixin 
 - more sizes
 - 70 inference multiple gpus 
 - tiny to 7b might not be good enouggh
2. gptfast algorithm -> Hanchi 

## Materials 
- /data/hanchi/Speculative-Gumbel-Sampling/checkpoints/TinyLlama/TinyLlama-1.1B-Chat-v1.0
- /home/hanchi/miniconda3/envs/gpt-fast
- /data/llama2

